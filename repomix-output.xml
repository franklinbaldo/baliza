This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/settings.local.json
.github/workflows/baliza_daily_run.yml
.github/workflows/code_quality.yml
.github/workflows/mkdocs.yml
.gitignore
.pre-commit-config.yaml
dbt_baliza/dbt_project.yml
dbt_baliza/macros/extract_organization_data.sql
dbt_baliza/models/bronze/bronze_pncp_raw.sql
dbt_baliza/models/bronze/bronze_pncp_source.yml
dbt_baliza/models/gold/mart_compras_beneficios.sql
dbt_baliza/models/gold/mart_procurement_analytics.sql
dbt_baliza/models/silver/silver_atas.sql
dbt_baliza/models/silver/silver_contratacoes.sql
dbt_baliza/models/silver/silver_contratos.sql
dbt_baliza/models/silver/silver_dim_organizacoes.sql
dbt_baliza/models/silver/silver_dim_unidades_orgao.sql
dbt_baliza/models/silver/silver_documentos.sql
dbt_baliza/models/silver/silver_fact_contratacoes.sql
dbt_baliza/models/silver/silver_fact_contratos.sql
dbt_baliza/models/silver/silver_itens_contratacao.sql
dbt_baliza/profiles.yml
docs/api_investigation/discover_modalidades.py
docs/api_investigation/endpoint_test_results_final.json
docs/api_investigation/endpoint_test_results_fixed.json
docs/api_investigation/endpoint_test_results.json
docs/api_investigation/ENDPOINT_TESTING_REPORT.md
docs/api_investigation/modalidades_discovered.json
docs/api_investigation/README.md
docs/api_investigation/test_endpoints_final.py
docs/api_investigation/test_endpoints_fixed.py
docs/api_investigation/test_endpoints.py
docs/archive/development/branch_analysis_final.md
docs/archive/development/branch_analysis_report.md
docs/archive/planning/etl_pipeline_plan.md
docs/archive/planning/plano_integrado_desenvolvimento.md
docs/archive/planning/task-table-design.md
docs/archive/README.md
docs/archive/technical/sharding.md
docs/gen_ref_pages.py
docs/mcp_guide.md
docs/openapi/api-pncp-consulta.json
docs/openapi/MANUAL-PNCP-CONSULSTAS-VERSAO-1.md
LICENSE
mkdocs.yml
pyproject.toml
README.md
scripts/export_to_parquet.py
scripts/test_contratacoes_proposta.py
scripts/test_instrumentos.py
scripts/test_modalidades.py
src/baliza/__init__.py
src/baliza/.gitignore
src/baliza/cli.py
src/baliza/config.py
src/baliza/enums.py
src/baliza/extractor.py
src/baliza/mcp_server.py
src/baliza/mcp.py
src/baliza/pncp_client.py
src/baliza/pncp_task_planner.py
src/baliza/pncp_writer.py
src/baliza/utils.py
tests/conftest.py
tests/README.md
TODO.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/code_quality.yml">
name: Code Quality

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]
  workflow_dispatch:

# Cancel previous runs if a new commit is pushed
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  code_quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better blame info

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Set up Python with uv
        run: |
          uv venv --python 3.11 .venv
          echo "VIRTUAL_ENV=.venv" >> $GITHUB_ENV
          echo ".venv/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          source $VIRTUAL_ENV/bin/activate
          uv sync --frozen-lockfile
          
      - name: Cache pre-commit hooks
        uses: actions/cache@v3
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-

      - name: Install pre-commit
        run: |
          source $VIRTUAL_ENV/bin/activate
          pre-commit install

      - name: Run Ruff linting
        run: |
          source $VIRTUAL_ENV/bin/activate
          echo "🔍 Running Ruff linter..."
          ruff check . --output-format=github
        continue-on-error: false

      - name: Run Ruff formatting check
        run: |
          source $VIRTUAL_ENV/bin/activate
          echo "🎨 Checking Ruff formatting..."
          ruff format --check --diff .
        continue-on-error: false

      - name: Run MyPy type checking
        run: |
          source $VIRTUAL_ENV/bin/activate
          echo "🏷️ Running MyPy type checking..."
          mypy src/ --show-error-codes --pretty
        continue-on-error: true  # Type errors shouldn't block PRs initially

      - name: Run security checks with Bandit
        run: |
          source $VIRTUAL_ENV/bin/activate
          echo "🔒 Running Bandit security checks..."
          bandit -r src/ -f json -o bandit-report.json || true
          bandit -r src/ -f txt
        continue-on-error: true

      - name: Upload Bandit report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bandit-security-report
          path: bandit-report.json
          retention-days: 30

      - name: Run tests with coverage
        run: |
          source $VIRTUAL_ENV/bin/activate
          echo "🧪 Running tests with coverage..."
          pytest tests/ \
            --cov=src \
            --cov-report=term-missing \
            --cov-report=xml \
            --cov-report=html \
            --junitxml=pytest-report.xml \
            -v
        continue-on-error: false

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            coverage.xml
            htmlcov/
            pytest-report.xml
          retention-days: 30

      - name: Upload coverage to Codecov
        if: always()
        uses: codecov/codecov-action@v3
        with:
          file: coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Check import sorting
        run: |
          source $VIRTUAL_ENV/bin/activate
          echo "📦 Checking import sorting..."
          ruff check --select I .
        continue-on-error: false

      - name: Check for TODO/FIXME comments
        run: |
          echo "📝 Checking for TODO/FIXME comments..."
          if grep -r "TODO\|FIXME\|XXX\|HACK" src/ tests/ --exclude-dir=.git --exclude-dir=__pycache__ --exclude="*.pyc"; then
            echo "⚠️ Found TODO/FIXME comments. Consider addressing them."
          else
            echo "✅ No TODO/FIXME comments found."
          fi
        continue-on-error: true

      - name: Check file permissions
        run: |
          echo "🔐 Checking file permissions..."
          find src/ tests/ -name "*.py" -executable -type f | while read file; do
            echo "⚠️ Python file has executable permission: $file"
          done
        continue-on-error: true

      - name: Validate YAML files
        run: |
          source $VIRTUAL_ENV/bin/activate
          echo "📋 Validating YAML files..."
          python -c "
          import yaml
          import sys
          import glob
          
          yaml_files = glob.glob('**/*.yml', recursive=True) + glob.glob('**/*.yaml', recursive=True)
          errors = 0
          
          for file in yaml_files:
              try:
                  with open(file, 'r') as f:
                      yaml.safe_load(f)
                  print(f'✅ {file}')
              except yaml.YAMLError as e:
                  print(f'❌ {file}: {e}')
                  errors += 1
          
          if errors > 0:
              print(f'Found {errors} YAML validation errors')
              sys.exit(1)
          else:
              print('All YAML files are valid')
          "

      - name: Check code complexity
        run: |
          source $VIRTUAL_ENV/bin/activate
          echo "🔢 Checking code complexity..."
          python -c "
          import ast
          import glob
          
          def get_complexity(node):
              complexity = 1
              for child in ast.walk(node):
                  if isinstance(child, (ast.If, ast.While, ast.For, ast.comprehension)):
                      complexity += 1
                  elif isinstance(child, ast.BoolOp):
                      complexity += len(child.values) - 1
              return complexity
          
          high_complexity = []
          
          for file in glob.glob('src/**/*.py', recursive=True):
              try:
                  with open(file, 'r') as f:
                      tree = ast.parse(f.read())
                  
                  for node in ast.walk(tree):
                      if isinstance(node, ast.FunctionDef):
                          complexity = get_complexity(node)
                          if complexity > 10:
                              high_complexity.append((file, node.name, complexity))
              except Exception as e:
                  print(f'Error parsing {file}: {e}')
          
          if high_complexity:
              print('⚠️ Functions with high complexity (>10):')
              for file, func, complexity in high_complexity:
                  print(f'  {file}:{func} - {complexity}')
          else:
              print('✅ No functions with high complexity found')
          "
        continue-on-error: true

  dependency_check:
    name: Dependency Security Check
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Set up Python with uv
        run: |
          uv venv --python 3.11 .venv
          echo "VIRTUAL_ENV=.venv" >> $GITHUB_ENV
          echo ".venv/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          source $VIRTUAL_ENV/bin/activate
          uv sync --frozen-lockfile

      - name: Run safety check
        run: |
          source $VIRTUAL_ENV/bin/activate
          # Install safety for dependency vulnerability checking
          uv add safety --dev
          echo "🛡️ Checking dependencies for known vulnerabilities..."
          safety check --json --output safety-report.json || true
          safety check
        continue-on-error: true

      - name: Upload safety report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: safety-security-report
          path: safety-report.json
          retention-days: 30

  documentation_check:
    name: Documentation Check
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check README exists and is substantial
        run: |
          echo "📖 Checking documentation..."
          if [ ! -f "README.md" ]; then
            echo "❌ README.md not found"
            exit 1
          fi
          
          lines=$(wc -l < README.md)
          if [ $lines -lt 20 ]; then
            echo "⚠️ README.md seems too short ($lines lines)"
          else
            echo "✅ README.md exists and has substantial content ($lines lines)"
          fi

      - name: Check for proper documentation structure
        run: |
          echo "📋 Checking documentation structure..."
          required_sections=("## " "### " "- " "```")
          missing_sections=()
          
          for section in "${required_sections[@]}"; do
            if ! grep -q "$section" README.md; then
              missing_sections+=("$section")
            fi
          done
          
          if [ ${#missing_sections[@]} -gt 0 ]; then
            echo "⚠️ README.md missing some documentation patterns:"
            printf '%s\n' "${missing_sections[@]}"
          else
            echo "✅ README.md has good documentation structure"
          fi

      - name: Check for broken internal links
        run: |
          echo "🔗 Checking for broken internal links..."
          # Extract markdown links and check if referenced files exist
          grep -oP '\[.*?\]\(\K[^)]+' README.md | grep -v '^http' | while read -r link; do
            if [ ! -f "$link" ] && [ ! -d "$link" ]; then
              echo "⚠️ Broken internal link: $link"
            fi
          done || echo "✅ No broken internal links found"

  quality_gate:
    name: Quality Gate
    needs: [code_quality, dependency_check, documentation_check]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Check quality gate status
        run: |
          echo "🚪 Quality Gate Summary"
          echo "======================"
          
          code_quality_result="${{ needs.code_quality.result }}"
          dependency_result="${{ needs.dependency_check.result }}"
          docs_result="${{ needs.documentation_check.result }}"
          
          echo "Code Quality: $code_quality_result"
          echo "Dependency Check: $dependency_result"
          echo "Documentation: $docs_result"
          
          # Quality gate passes if critical checks pass
          if [ "$code_quality_result" = "success" ]; then
            echo "✅ Quality gate PASSED"
            echo "QUALITY_GATE_STATUS=passed" >> $GITHUB_ENV
          else
            echo "❌ Quality gate FAILED"
            echo "QUALITY_GATE_STATUS=failed" >> $GITHUB_ENV
            exit 1
          fi

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const status = process.env.QUALITY_GATE_STATUS;
            const emoji = status === 'passed' ? '✅' : '❌';
            const message = status === 'passed' ? 'PASSED' : 'FAILED';
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `${emoji} Quality Gate ${message}\n\nCode quality checks have been completed. See the Actions tab for detailed results.`
            });
</file>

<file path=".pre-commit-config.yaml">
# Pre-commit configuration for Baliza
# See https://pre-commit.com for more information
repos:
  # Ruff for linting and formatting (replaces black, isort, flake8, etc.)
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.12.3
    hooks:
      # Run the linter
      - id: ruff
        args: [--fix]
        types_or: [python, pyi]
      # Run the formatter  
      - id: ruff-format
        types_or: [python, pyi]

  # Built-in pre-commit hooks
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.6.0
    hooks:
      # General file checks
      - id: trailing-whitespace
        exclude: '\.md$'
      - id: end-of-file-fixer
        exclude: '\.md$'
      - id: check-yaml
        args: [--allow-multiple-documents]
      - id: check-toml
      - id: check-json
      - id: check-xml
      - id: check-added-large-files
        args: [--maxkb=1000]
      - id: check-case-conflict
      - id: check-merge-conflict
      - id: check-executables-have-shebangs
      - id: check-shebang-scripts-are-executable
      
      # Python-specific checks
      - id: check-ast
      - id: check-builtin-literals
      - id: check-docstring-first
      - id: debug-statements
      - id: name-tests-test
        args: [--pytest-test-first]

  # Security checks with bandit
  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.9
    hooks:
      - id: bandit
        args: ['-c', 'pyproject.toml']
        additional_dependencies: ['bandit[toml]']
        exclude: '^tests/'

  # Type checking with mypy
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.16.1
    hooks:
      - id: mypy
        additional_dependencies: 
          - types-requests
          - types-PyYAML
        exclude: '^(tests|scripts)/'

  # SQL formatting for DBT files
  - repo: https://github.com/sqlfluff/sqlfluff
    rev: 3.5.0
    hooks:
      - id: sqlfluff-lint
        files: '\.(sql)$'
        additional_dependencies: ['dbt-duckdb', 'sqlfluff-templater-dbt']
      - id: sqlfluff-fix
        files: '\.(sql)$'
        additional_dependencies: ['dbt-duckdb', 'sqlfluff-templater-dbt']

  # Jupyter notebook cleaning
  - repo: https://github.com/nbQA-dev/nbQA
    rev: 1.9.1
    hooks:
      - id: nbqa-ruff
        args: [--fix]
      - id: nbqa-ruff-format

  # YAML formatting
  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: v4.0.0-alpha.8
    hooks:
      - id: prettier
        files: '\.(yaml|yml)$'

  # Dockerfile linting
  - repo: https://github.com/hadolint/hadolint
    rev: v2.12.0
    hooks:
      - id: hadolint-docker
        files: 'Dockerfile*'

  # Shell script linting
  - repo: https://github.com/shellcheck-py/shellcheck-py
    rev: v0.10.0.1
    hooks:
      - id: shellcheck
        files: '\.(sh|bash)$'

# Global configuration
default_language_version:
  python: python3.11

# Fail fast - stop running hooks after first failure
fail_fast: false

# Default stages to run hooks on
default_stages: [commit, push]

# Specific configurations for different stages
repos:
  # Only run expensive checks on push, not every commit
  - repo: local
    hooks:
      - id: pytest-check
        name: pytest-check
        entry: uv run pytest tests/ --maxfail=1 -q
        language: system
        stages: [push]
        pass_filenames: false
        always_run: true
      
      - id: coverage-check
        name: coverage-check
        entry: uv run pytest tests/ --cov=src --cov-report=term-missing --cov-fail-under=80
        language: system
        stages: [manual]
        pass_filenames: false
        always_run: true
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2024 [Your Name or Organization Here]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path=".github/workflows/mkdocs.yml">
name: "Deploy Documentation"

on:
  push:
    branches:
      - "main"

jobs:
  deploy:
    runs-on: "ubuntu-latest"
    steps:
      - uses: "actions/checkout@v3"
      - uses: "actions/setup-python@v4"
        with:
          python-version: "3.11"
      - run: "pip install uv"
      - run: "uv sync --system-site-packages"
      - run: "uv run mkdocs gh-deploy --force"
</file>

<file path="dbt_baliza/macros/extract_organization_data.sql">
{% macro extract_organization_data(json_field, prefix) %}
  {{ json_field }} ->> 'cnpj' AS {{ prefix }}_cnpj,
  {{ json_field }} ->> 'razaoSocial' AS {{ prefix }}_razao_social,
  {{ json_field }} ->> 'poderId' AS {{ prefix }}_poder_id,
  {{ json_field }} ->> 'esferaId' AS {{ prefix }}_esfera_id
{% endmacro %}

{% macro extract_unit_data(json_field, prefix) %}
  {{ json_field }} ->> 'ufNome' AS {{ prefix }}_uf_nome,
  {{ json_field }} ->> 'ufSigla' AS {{ prefix }}_uf_sigla,
  {{ json_field }} ->> 'codigoUnidade' AS {{ prefix }}_codigo_unidade,
  {{ json_field }} ->> 'nomeUnidade' AS {{ prefix }}_nome_unidade,
  {{ json_field }} ->> 'municipioNome' AS {{ prefix }}_municipio_nome,
  {{ json_field }} ->> 'codigoIbge' AS {{ prefix }}_codigo_ibge
{% endmacro %}

{% macro extract_legal_framework_data(json_field, prefix) %}
  CAST({{ json_field }} ->> 'codigo' AS INTEGER) AS {{ prefix }}_codigo,
  {{ json_field }} ->> 'nome' AS {{ prefix }}_nome,
  {{ json_field }} ->> 'descricao' AS {{ prefix }}_descricao
{% endmacro %}

{% macro extract_type_data(json_field, prefix) %}
  CAST({{ json_field }} ->> 'id' AS INTEGER) AS {{ prefix }}_id,
  {{ json_field }} ->> 'nome' AS {{ prefix }}_nome
{% endmacro %}
</file>

<file path="dbt_baliza/models/bronze/bronze_pncp_raw.sql">
{{
  config(
    materialized='incremental',
    unique_key='id',
    incremental_strategy='delete+insert'
  )
}}

SELECT
    id,
    extracted_at,
    endpoint_name,
    endpoint_url,
    data_date,
    run_id,
    total_records,
    total_pages,
    current_page,
    TRY_CAST(response_content AS JSON) AS response_json,
    -- Add endpoint category for easier downstream filtering
    CASE 
        WHEN endpoint_name IN ('atas_periodo', 'atas_atualizacao') THEN 'atas'
        WHEN endpoint_name IN ('contratos_publicacao', 'contratos_atualizacao') THEN 'contratos'
        WHEN endpoint_name IN ('contratacoes_publicacao', 'contratacoes_atualizacao', 'contratacoes_proposta') THEN 'contratacoes'
        ELSE 'other'
    END AS endpoint_category
FROM {{ source('pncp', 'pncp_raw_responses') }}
WHERE response_code = 200
  AND response_content IS NOT NULL
  AND response_content != ''
  AND TRY_CAST(response_content AS JSON) IS NOT NULL
{% if is_incremental() %}
  AND extracted_at > (SELECT MAX(extracted_at) FROM {{ this }})
{% endif %}
</file>

<file path="dbt_baliza/models/bronze/bronze_pncp_source.yml">
version: 2

sources:
  - name: pncp
    schema: psa
    description: "Raw data from the PNCP API"
    tables:
      - name: pncp_raw_responses
        description: "Stores raw JSON responses from the PNCP API."
        columns:
          - name: id
            description: "Unique identifier for the raw response."
            tests:
              - unique
              - not_null
          - name: extracted_at
            description: "Timestamp when the data was extracted."
          - name: endpoint_url
            description: "The URL of the API endpoint."
          - name: endpoint_name
            description: "The name of the API endpoint."
          - name: request_parameters
            description: "JSON object with the request parameters."
          - name: response_code
            description: "The HTTP response code."
          - name: response_content
            description: "The raw response content."
          - name: response_headers
            description: "JSON object with the response headers."
          - name: data_date
            description: "The date of the data being extracted."
          - name: run_id
            description: "The unique identifier for the extraction run."
          - name: total_records
            description: "The total number of records for the request."
          - name: total_pages
            description: "The total number of pages for the request."
          - name: current_page
            description: "The current page number."
          - name: page_size
            description: "The page size of the request."
</file>

<file path="dbt_baliza/models/gold/mart_compras_beneficios.sql">
-- dbt_baliza/models/gold/mart_compras_beneficios.sql

{{
  config(
    materialized='table',
    schema='gold'
  )
}}

WITH contratacoes AS (
  SELECT
    numero_controle_pncp,
    modalidade_nome,
    srp,
    valor_total_estimado,
    data_publicacao_pncp
  FROM {{ ref('silver_contratacoes') }}
),

itens AS (
  SELECT
    numero_controle_pncp,
    tipo_beneficio_id,
    tipo_beneficio_nome,
    valor_total AS valor_total_item
  FROM {{ ref('silver_itens_contratacao') }}
),

-- Aggregate item data to get total value per benefit type for each procurement
beneficios_agregados AS (
  SELECT
    numero_controle_pncp,

    SUM(CASE WHEN tipo_beneficio_id IN (1, 2, 3) THEN valor_total_item ELSE 0 END) AS valor_total_com_beneficio,
    SUM(CASE WHEN tipo_beneficio_id NOT IN (1, 2, 3) THEN valor_total_item ELSE 0 END) AS valor_total_sem_beneficio,

    COUNT(CASE WHEN tipo_beneficio_id IN (1, 2, 3) THEN 1 END) AS qtd_itens_com_beneficio,
    COUNT(CASE WHEN tipo_beneficio_id NOT IN (1, 2, 3) THEN 1 END) AS qtd_itens_sem_beneficio,
    COUNT(*) AS qtd_total_itens

  FROM itens
  GROUP BY 1
),

-- Final mart model
final AS (
  SELECT
    c.numero_controle_pncp,
    c.modalidade_nome,
    c.srp,
    c.data_publicacao_pncp,

    COALESCE(b.qtd_total_itens, 0) AS quantidade_total_itens,
    COALESCE(b.qtd_itens_com_beneficio, 0) AS quantidade_itens_com_beneficio,
    COALESCE(b.qtd_itens_sem_beneficio, 0) AS quantidade_itens_sem_beneficio,

    c.valor_total_estimado,
    COALESCE(b.valor_total_com_beneficio, 0) AS valor_total_com_beneficio,
    COALESCE(b.valor_total_sem_beneficio, 0) AS valor_total_sem_beneficio,

    -- Calculated metrics
    CASE
      WHEN COALESCE(b.qtd_total_itens, 0) > 0
      THEN (COALESCE(b.qtd_itens_com_beneficio, 0) * 1.0 / b.qtd_total_itens)
      ELSE 0
    END AS percentual_itens_com_beneficio,

    CASE
      WHEN c.valor_total_estimado > 0
      THEN (COALESCE(b.valor_total_com_beneficio, 0) / c.valor_total_estimado)
      ELSE 0
    END AS percentual_valor_com_beneficio

  FROM contratacoes c
  LEFT JOIN beneficios_agregados b
    ON c.numero_controle_pncp = b.numero_controle_pncp
)

SELECT * FROM final
</file>

<file path="dbt_baliza/models/gold/mart_procurement_analytics.sql">
{{
  config(
    materialized='table',
    description='Analytics mart combining procurement and contract data for business intelligence'
  )
}}

WITH procurement_summary AS (
  SELECT
    p.numero_controle_pncp,
    p.ano_compra,
    p.data_publicacao_pncp,
    p.modalidade_id,
    p.modalidade_nome,
    p.modalidade_descricao,
    p.valor_total_estimado,
    p.valor_total_homologado,
    p.faixa_valor_estimado,
    p.situacao_compra_id,
    p.situacao_compra_descricao,
    p.srp,
    p.existe_resultado,
    p.objeto_compra,
    p.org_key,
    p.unit_key,
    
    -- Organization info
    org.cnpj AS org_cnpj,
    org.razao_social AS org_razao_social,
    org.poder_nome AS org_poder,
    org.esfera_nome AS org_esfera,
    
    -- Unit info
    unit.nome_unidade AS unit_nome,
    unit.uf_sigla AS unit_uf,
    unit.regiao AS unit_regiao,
    unit.municipio_nome AS unit_municipio
    
  FROM {{ ref('silver_fact_contratacoes') }} p
  LEFT JOIN {{ ref('silver_dim_organizacoes') }} org
    ON p.org_key = org.org_key
  LEFT JOIN {{ ref('silver_dim_unidades_orgao') }} unit
    ON p.unit_key = unit.unit_key
),

contract_summary AS (
  SELECT
    c.numero_controle_pncp_compra,
    COUNT(*) AS total_contratos,
    SUM(c.valor_global) AS valor_total_contratos,
    MIN(c.data_assinatura) AS primeira_assinatura,
    MAX(c.data_assinatura) AS ultima_assinatura,
    AVG(c.duracao_vigencia_dias) AS duracao_media_vigencia,
    COUNT(DISTINCT c.ni_fornecedor) AS fornecedores_distintos,
    
    -- Contract status flags
    SUM(CASE WHEN c.receita = true THEN 1 ELSE 0 END) AS contratos_com_receita,
    SUM(CASE WHEN c.numero_retificacao > 0 THEN 1 ELSE 0 END) AS contratos_retificados
    
  FROM {{ ref('silver_fact_contratos') }} c
  WHERE c.numero_controle_pncp_compra IS NOT NULL
  GROUP BY c.numero_controle_pncp_compra
)

SELECT
  -- Procurement identifiers
  p.numero_controle_pncp,
  p.ano_compra,
  p.data_publicacao_pncp,
  
  -- Organization information
  p.org_cnpj,
  p.org_razao_social,
  p.org_poder,
  p.org_esfera,
  p.unit_nome,
  p.unit_uf,
  p.unit_regiao,
  p.unit_municipio,
  
  -- Procurement details
  p.modalidade_id,
  p.modalidade_nome,
  p.modalidade_descricao,
  p.objeto_compra,
  p.situacao_compra_id,
  p.situacao_compra_descricao,
  p.srp,
  p.existe_resultado,
  
  -- Financial information
  p.valor_total_estimado,
  p.valor_total_homologado,
  p.faixa_valor_estimado,
  
  -- Contract information
  COALESCE(c.total_contratos, 0) AS total_contratos,
  COALESCE(c.valor_total_contratos, 0) AS valor_total_contratos,
  c.primeira_assinatura,
  c.ultima_assinatura,
  c.duracao_media_vigencia,
  COALESCE(c.fornecedores_distintos, 0) AS fornecedores_distintos,
  COALESCE(c.contratos_com_receita, 0) AS contratos_com_receita,
  COALESCE(c.contratos_retificados, 0) AS contratos_retificados,
  
  -- Performance metrics
  CASE 
    WHEN p.valor_total_estimado > 0 AND c.valor_total_contratos > 0 THEN
      ROUND((c.valor_total_contratos / p.valor_total_estimado) * 100, 2)
    ELSE NULL
  END AS percentual_execucao_financeira,
  
  CASE 
    WHEN p.valor_total_homologado > 0 AND p.valor_total_estimado > 0 THEN
      ROUND((p.valor_total_homologado / p.valor_total_estimado) * 100, 2)
    ELSE NULL
  END AS percentual_economia_homologacao,
  
  -- Time metrics
  CASE 
    WHEN p.data_publicacao_pncp IS NOT NULL AND c.primeira_assinatura IS NOT NULL THEN
      c.primeira_assinatura - p.data_publicacao_pncp
    ELSE NULL
  END AS dias_publicacao_primeira_assinatura,
  
  -- Categories for analysis
  CASE 
    WHEN p.modalidade_id IN (6, 4) THEN 'Competitiva'
    WHEN p.modalidade_id IN (8, 9) THEN 'Não Competitiva'
    WHEN p.modalidade_id IN (1, 3, 10, 11, 12) THEN 'Outros'
    ELSE 'Não Classificada'
  END AS categoria_modalidade,
  
  CASE 
    WHEN p.org_esfera = 'Federal' THEN 'Federal'
    WHEN p.org_esfera = 'Estadual' THEN 'Estadual'
    WHEN p.org_esfera = 'Municipal' THEN 'Municipal'
    ELSE 'Outros'
  END AS categoria_esfera,
  
  CASE 
    WHEN p.org_poder = 'Executivo' THEN 'Executivo'
    WHEN p.org_poder = 'Legislativo' THEN 'Legislativo'
    WHEN p.org_poder = 'Judiciário' THEN 'Judiciário'
    WHEN p.org_poder = 'Ministério Público' THEN 'Ministério Público'
    ELSE 'Outros'
  END AS categoria_poder,
  
  -- Quality indicators
  CASE 
    WHEN p.existe_resultado = true AND COALESCE(c.total_contratos, 0) = 0 THEN 'Resultado sem contratos'
    WHEN p.existe_resultado = false AND COALESCE(c.total_contratos, 0) > 0 THEN 'Contratos sem resultado'
    WHEN p.valor_total_estimado > 0 AND p.valor_total_homologado > p.valor_total_estimado THEN 'Homologação acima do estimado'
    ELSE 'OK'
  END AS indicador_qualidade,
  
  -- Metadata
  CURRENT_TIMESTAMP AS created_at

FROM procurement_summary p
LEFT JOIN contract_summary c
  ON p.numero_controle_pncp = c.numero_controle_pncp_compra

ORDER BY p.ano_compra DESC, p.data_publicacao_pncp DESC
</file>

<file path="dbt_baliza/models/silver/silver_dim_organizacoes.sql">
{{
  config(
    materialized='table',
    description='Dimension table for organizations (órgãos and entidades)'
  )
}}

WITH org_from_contracts AS (
  SELECT DISTINCT
    {{ extract_organization_data('orgao_entidade_json', 'org') }}
  FROM {{ ref('silver_contratos') }}
  WHERE orgao_entidade_json IS NOT NULL
),

org_from_procurements AS (
  SELECT DISTINCT
    {{ extract_organization_data('orgao_entidade_json', 'org') }}
  FROM {{ ref('silver_contratacoes') }}
  WHERE orgao_entidade_json IS NOT NULL
),

subrog_from_contracts AS (
  SELECT DISTINCT
    {{ extract_organization_data('orgao_subrogado_json', 'org') }}
  FROM {{ ref('silver_contratos') }}
  WHERE orgao_subrogado_json IS NOT NULL
),

subrog_from_procurements AS (
  SELECT DISTINCT
    {{ extract_organization_data('orgao_subrogado_json', 'org') }}
  FROM {{ ref('silver_contratacoes') }}
  WHERE orgao_subrogado_json IS NOT NULL
),

all_organizations AS (
  SELECT * FROM org_from_contracts
  UNION ALL
  SELECT * FROM org_from_procurements
  UNION ALL
  SELECT * FROM subrog_from_contracts
  UNION ALL
  SELECT * FROM subrog_from_procurements
),

deduplicated_organizations AS (
  SELECT DISTINCT
    org_cnpj,
    org_razao_social,
    org_poder_id,
    org_esfera_id
  FROM all_organizations
  WHERE org_cnpj IS NOT NULL
)

SELECT
  -- Surrogate key
  MD5(org_cnpj) AS org_key,
  
  -- Natural key
  org_cnpj AS cnpj,
  
  -- Organization details
  org_razao_social AS razao_social,
  org_poder_id AS poder_id,
  org_esfera_id AS esfera_id,
  
  -- Derived attributes
  CASE 
    WHEN org_poder_id = 'E' THEN 'Executivo'
    WHEN org_poder_id = 'L' THEN 'Legislativo'
    WHEN org_poder_id = 'J' THEN 'Judiciário'
    WHEN org_poder_id = 'M' THEN 'Ministério Público'
    ELSE 'Outros'
  END AS poder_nome,
  
  CASE 
    WHEN org_esfera_id = 'F' THEN 'Federal'
    WHEN org_esfera_id = 'E' THEN 'Estadual'
    WHEN org_esfera_id = 'M' THEN 'Municipal'
    ELSE 'Outros'
  END AS esfera_nome,
  
  -- Metadata
  CURRENT_TIMESTAMP AS created_at,
  CURRENT_TIMESTAMP AS updated_at

FROM deduplicated_organizations
ORDER BY org_cnpj
</file>

<file path="dbt_baliza/models/silver/silver_dim_unidades_orgao.sql">
{{
  config(
    materialized='table',
    description='Dimension table for organizational units (unidades do órgão)'
  )
}}

WITH units_from_contracts AS (
  SELECT DISTINCT
    {{ extract_organization_data('orgao_entidade_json', 'org') }},
    {{ extract_unit_data('unidade_orgao_json', 'unit') }}
  FROM {{ ref('silver_contratos') }}
  WHERE orgao_entidade_json IS NOT NULL
    AND unidade_orgao_json IS NOT NULL
),

units_from_procurements AS (
  SELECT DISTINCT
    {{ extract_organization_data('orgao_entidade_json', 'org') }},
    {{ extract_unit_data('unidade_orgao_json', 'unit') }}
  FROM {{ ref('silver_contratacoes') }}
  WHERE orgao_entidade_json IS NOT NULL
    AND unidade_orgao_json IS NOT NULL
),

subrog_units_from_contracts AS (
  SELECT DISTINCT
    {{ extract_organization_data('orgao_subrogado_json', 'org') }},
    {{ extract_unit_data('unidade_subrogada_json', 'unit') }}
  FROM {{ ref('silver_contratos') }}
  WHERE orgao_subrogado_json IS NOT NULL
    AND unidade_subrogada_json IS NOT NULL
),

subrog_units_from_procurements AS (
  SELECT DISTINCT
    {{ extract_organization_data('orgao_subrogado_json', 'org') }},
    {{ extract_unit_data('unidade_subrogada_json', 'unit') }}
  FROM {{ ref('silver_contratacoes') }}
  WHERE orgao_subrogado_json IS NOT NULL
    AND unidade_subrogada_json IS NOT NULL
),

all_units AS (
  SELECT * FROM units_from_contracts
  UNION ALL
  SELECT * FROM units_from_procurements
  UNION ALL
  SELECT * FROM subrog_units_from_contracts
  UNION ALL
  SELECT * FROM subrog_units_from_procurements
),

deduplicated_units AS (
  SELECT DISTINCT
    org_cnpj,
    unit_codigo_unidade,
    unit_nome_unidade,
    unit_uf_nome,
    unit_uf_sigla,
    unit_municipio_nome,
    unit_codigo_ibge
  FROM all_units
  WHERE org_cnpj IS NOT NULL
    AND unit_codigo_unidade IS NOT NULL
)

SELECT
  -- Surrogate key
  MD5(org_cnpj || '|' || unit_codigo_unidade) AS unit_key,
  
  -- Natural keys
  org_cnpj AS cnpj_orgao,
  unit_codigo_unidade AS codigo_unidade,
  
  -- Unit details
  unit_nome_unidade AS nome_unidade,
  unit_uf_nome AS uf_nome,
  unit_uf_sigla AS uf_sigla,
  unit_municipio_nome AS municipio_nome,
  unit_codigo_ibge AS codigo_ibge,
  
  -- Derived attributes
  CASE 
    WHEN unit_uf_sigla IN ('AC', 'AL', 'AP', 'AM', 'BA', 'CE', 'DF', 'ES', 'GO', 'MA', 'MT', 'MS', 'MG', 'PA', 'PB', 'PR', 'PE', 'PI', 'RJ', 'RN', 'RS', 'RO', 'RR', 'SC', 'SP', 'SE', 'TO') THEN unit_uf_sigla
    ELSE 'OUTROS'
  END AS uf_sigla_normalizada,
  
  CASE 
    WHEN unit_uf_sigla IN ('AC', 'AM', 'AP', 'PA', 'RO', 'RR', 'TO') THEN 'Norte'
    WHEN unit_uf_sigla IN ('AL', 'BA', 'CE', 'MA', 'PB', 'PE', 'PI', 'RN', 'SE') THEN 'Nordeste'
    WHEN unit_uf_sigla IN ('GO', 'MT', 'MS', 'DF') THEN 'Centro-Oeste'
    WHEN unit_uf_sigla IN ('ES', 'MG', 'RJ', 'SP') THEN 'Sudeste'
    WHEN unit_uf_sigla IN ('PR', 'RS', 'SC') THEN 'Sul'
    ELSE 'Outros'
  END AS regiao,
  
  -- Metadata
  CURRENT_TIMESTAMP AS created_at,
  CURRENT_TIMESTAMP AS updated_at

FROM deduplicated_units
ORDER BY org_cnpj, unit_codigo_unidade
</file>

<file path="dbt_baliza/models/silver/silver_documentos.sql">
-- dbt_baliza/models/silver/silver_documentos.sql

{{
  config(
    materialized='incremental',
    unique_key='documento_key',
    incremental_strategy='delete+insert'
  )
}}

WITH source_contratacoes AS (
  SELECT
    numero_controle_pncp,
    procurement_json,
    data_inclusao
  FROM {{ ref('silver_contratacoes') }}
  {% if is_incremental() %}
  WHERE data_inclusao > (SELECT MAX(data_inclusao_referencia) FROM {{ this }} WHERE tipo_referencia = 'contratacao')
  {% endif %}
),

-- Adicionar outras fontes (atas, contratos) aqui no futuro
-- source_atas AS ( ... ),
-- source_contratos AS ( ... ),

unpacked_docs AS (
  -- Documentos de Contratações
  SELECT
    numero_controle_pncp,
    'contratacao' AS tipo_referencia,
    data_inclusao AS data_inclusao_referencia,
    json_extract(doc, '$') AS doc_data
  FROM source_contratacoes,
  unnest(json_extract(procurement_json, '$.documentos')) AS doc

  -- UNION ALL para outras fontes no futuro
),

final AS (
  SELECT
    -- Surrogate key for the document
    doc_data ->> 'id' AS documento_key,

    -- Foreign key and reference type
    numero_controle_pncp,
    tipo_referencia,
    data_inclusao_referencia,

    -- Document details
    CAST(doc_data ->> 'tipoDocumentoId' AS INTEGER) AS tipo_documento_id,
    CASE CAST(doc_data ->> 'tipoDocumentoId' AS INTEGER)
      WHEN 1 THEN 'Aviso de Contratação Direta'
      WHEN 2 THEN 'Edital'
      WHEN 3 THEN 'Minuta do Contrato'
      WHEN 4 THEN 'Termo de Referência'
      WHEN 5 THEN 'Anteprojeto'
      WHEN 6 THEN 'Projeto Básico'
      WHEN 7 THEN 'Estudo Técnico Preliminar'
      WHEN 8 THEN 'Projeto Executivo'
      WHEN 9 THEN 'Mapa de Riscos'
      WHEN 10 THEN 'DFD'
      WHEN 11 THEN 'Ata de Registro de Preço'
      WHEN 12 THEN 'Contrato'
      WHEN 13 THEN 'Termo de Rescisão'
      WHEN 14 THEN 'Termo Aditivo'
      WHEN 15 THEN 'Termo de Apostilamento'
      WHEN 16 THEN 'Outros'
      WHEN 17 THEN 'Nota de Empenho'
      WHEN 18 THEN 'Relatório Final de Contrato'
      ELSE 'Não especificado'
    END AS tipo_documento_nome,
    doc_data ->> 'titulo' AS titulo,
    doc_data ->> 'url' AS url,
    TRY_CAST(doc_data ->> 'data' AS TIMESTAMP) AS data_documento,

    -- Timestamps
    TRY_CAST(doc_data ->> 'dataInclusao' AS TIMESTAMP) AS data_inclusao,
    TRY_CAST(doc_data ->> 'dataAtualizacao' AS TIMESTAMP) AS data_atualizacao

  FROM unpacked_docs
)

SELECT * FROM final
</file>

<file path="dbt_baliza/models/silver/silver_fact_contratacoes.sql">
{{
  config(
    materialized='table',
    description='Fact table for procurements (contratações)',
    indexes=[
      {'columns': ['numero_controle_pncp'], 'unique': True},
      {'columns': ['data_publicacao_pncp']},
      {'columns': ['ano_compra']},
      {'columns': ['modalidade_id']},
      {'columns': ['org_key']},
      {'columns': ['unit_key']}
    ]
  )
}}

WITH procurements_with_keys AS (
  SELECT
    p.*,
    
    -- Organization keys
    org.org_key,
    unit.unit_key,
    
    -- Subrogated organization keys
    subrog_org.org_key AS subrog_org_key,
    subrog_unit.unit_key AS subrog_unit_key
    
  FROM {{ ref('silver_contratacoes') }} p
  
  -- Main organization
  LEFT JOIN {{ ref('silver_dim_organizacoes') }} org
    ON p.orgao_entidade_json ->> 'cnpj' = org.cnpj
  
  -- Main unit
  LEFT JOIN {{ ref('silver_dim_unidades_orgao') }} unit
    ON p.orgao_entidade_json ->> 'cnpj' = unit.cnpj_orgao
    AND CAST(p.unidade_orgao_json ->> 'codigoUnidade' AS VARCHAR) = unit.codigo_unidade
  
  -- Subrogated organization
  LEFT JOIN {{ ref('silver_dim_organizacoes') }} subrog_org
    ON p.orgao_subrogado_json ->> 'cnpj' = subrog_org.cnpj
  
  -- Subrogated unit
  LEFT JOIN {{ ref('silver_dim_unidades_orgao') }} subrog_unit
    ON p.orgao_subrogado_json ->> 'cnpj' = subrog_unit.cnpj_orgao
    AND CAST(p.unidade_subrogada_json ->> 'codigoUnidade' AS VARCHAR) = subrog_unit.codigo_unidade

  WHERE p.orgao_entidade_json IS NOT NULL
    AND p.unidade_orgao_json IS NOT NULL
)

SELECT
  -- Surrogate key
  MD5(numero_controle_pncp) AS procurement_key,
  
  -- Natural key
  numero_controle_pncp,
  
  -- Procurement identifiers
  numero_compra,
  ano_compra,
  sequencial_compra,
  
  -- Dates
  data_publicacao_pncp,
  data_abertura_proposta,
  data_encerramento_proposta,
  data_inclusao,
  data_atualizacao,
  data_atualizacao_global,
  
  -- Duration calculations
  CASE 
    WHEN data_abertura_proposta IS NOT NULL AND data_encerramento_proposta IS NOT NULL
    THEN DATE_DIFF('day', data_abertura_proposta, data_encerramento_proposta)
    ELSE NULL
  END AS duracao_proposta_dias,
  
  -- Amounts
  valor_total_estimado,
  valor_total_homologado,
  
  -- Procurement details
  objeto_compra,
  informacao_complementar,
  processo,
  link_sistema_origem,
  link_processo_eletronico,
  justificativa_presencial,
  
  -- Procurement method and mode
  modalidade_id,
  modalidade_nome,
  modo_disputa_id,
  modo_disputa_nome,
  
  -- Instrument and framework
  tipo_instrumento_convocatorio_codigo,
  tipo_instrumento_convocatorio_nome,
  
  -- Status and flags
  situacao_compra_id,
  situacao_compra_nome,
  srp,
  existe_resultado,
  
  -- User information
  usuario_nome,
  
  -- Foreign keys
  org_key,
  unit_key,
  subrog_org_key,
  subrog_unit_key,
  
  -- Legal framework information (extracted from JSON)
  amparo_legal_json ->> 'codigo' AS amparo_legal_codigo,
  amparo_legal_json ->> 'nome' AS amparo_legal_nome,
  amparo_legal_json ->> 'descricao' AS amparo_legal_descricao,
  
  -- Derived attributes
  CASE 
    WHEN modalidade_id = 1 THEN 'Leilão Eletrônico'
    WHEN modalidade_id = 3 THEN 'Concurso'
    WHEN modalidade_id = 4 THEN 'Concorrência Eletrônica'
    WHEN modalidade_id = 6 THEN 'Pregão Eletrônico'
    WHEN modalidade_id = 8 THEN 'Dispensa'
    WHEN modalidade_id = 9 THEN 'Inexigibilidade'
    WHEN modalidade_id = 10 THEN 'Credenciamento'
    WHEN modalidade_id = 11 THEN 'Seleção'
    WHEN modalidade_id = 12 THEN 'Consulta'
    WHEN modalidade_id = 13 THEN 'Registro de Preço'
    WHEN modalidade_id = 14 THEN 'Outros'
    ELSE 'Não informado'
  END AS modalidade_descricao,
  
  CASE 
    WHEN valor_total_estimado IS NOT NULL AND valor_total_estimado > 0 THEN
      CASE 
        WHEN valor_total_estimado <= 17600 THEN 'Até R$ 17.600'
        WHEN valor_total_estimado <= 88000 THEN 'R$ 17.601 a R$ 88.000'
        WHEN valor_total_estimado <= 176000 THEN 'R$ 88.001 a R$ 176.000'
        WHEN valor_total_estimado <= 1408000 THEN 'R$ 176.001 a R$ 1.408.000'
        WHEN valor_total_estimado <= 3300000 THEN 'R$ 1.408.001 a R$ 3.300.000'
        ELSE 'Acima de R$ 3.300.000'
      END
    ELSE 'Não informado'
  END AS faixa_valor_estimado,
  
  CASE 
    WHEN situacao_compra_id = '1' THEN 'Planejada'
    WHEN situacao_compra_id = '2' THEN 'Publicada'
    WHEN situacao_compra_id = '3' THEN 'Homologada'
    WHEN situacao_compra_id = '4' THEN 'Deserta/Fracassada'
    ELSE 'Não informado'
  END AS situacao_compra_descricao,
  
  CASE 
    WHEN data_abertura_proposta IS NOT NULL AND data_encerramento_proposta IS NOT NULL THEN
      CASE 
        WHEN DATE_DIFF('day', data_abertura_proposta, data_encerramento_proposta) <= 7 THEN 'Até 7 dias'
        WHEN DATE_DIFF('day', data_abertura_proposta, data_encerramento_proposta) <= 15 THEN '8 a 15 dias'
        WHEN DATE_DIFF('day', data_abertura_proposta, data_encerramento_proposta) <= 30 THEN '16 a 30 dias'
        WHEN DATE_DIFF('day', data_abertura_proposta, data_encerramento_proposta) <= 60 THEN '31 a 60 dias'
        ELSE 'Mais de 60 dias'
      END
    ELSE 'Não informado'
  END AS faixa_duracao_proposta,
  
  -- Data quality flags
  CASE 
    WHEN numero_controle_pncp IS NULL THEN 'Número de controle ausente'
    WHEN modalidade_id IS NULL THEN 'Modalidade ausente'
    WHEN valor_total_estimado IS NULL OR valor_total_estimado <= 0 THEN 'Valor estimado inválido'
    WHEN data_publicacao_pncp IS NULL THEN 'Data de publicação ausente'
    WHEN objeto_compra IS NULL THEN 'Objeto da compra ausente'
    ELSE 'OK'
  END AS quality_flag,
  
  -- Metadata
  endpoint_name,
  data_date,
  extracted_at,
  run_id,
  
  -- JSON fallback
  procurement_json,
  fontes_orcamentarias_json,
  
  -- Audit
  CURRENT_TIMESTAMP AS created_at,
  CURRENT_TIMESTAMP AS updated_at

FROM procurements_with_keys
ORDER BY numero_controle_pncp
</file>

<file path="dbt_baliza/models/silver/silver_fact_contratos.sql">
{{
  config(
    materialized='table',
    description='Fact table for contracts (contratos/empenhos)',
    indexes=[
      {'columns': ['numero_controle_pncp'], 'unique': True},
      {'columns': ['data_assinatura']},
      {'columns': ['ano_contrato']},
      {'columns': ['org_key']},
      {'columns': ['unit_key']}
    ]
  )
}}

WITH contracts_with_keys AS (
  SELECT
    c.*,
    
    -- Organization keys
    org.org_key,
    unit.unit_key,
    
    -- Subrogated organization keys
    subrog_org.org_key AS subrog_org_key,
    subrog_unit.unit_key AS subrog_unit_key
    
  FROM {{ ref('silver_contratos') }} c
  
  -- Main organization
  LEFT JOIN {{ ref('silver_dim_organizacoes') }} org
    ON c.orgao_entidade_json ->> 'cnpj' = org.cnpj
  
  -- Main unit
  LEFT JOIN {{ ref('silver_dim_unidades_orgao') }} unit
    ON c.orgao_entidade_json ->> 'cnpj' = unit.cnpj_orgao
    AND CAST(c.unidade_orgao_json ->> 'codigoUnidade' AS VARCHAR) = CAST(unit.codigo_unidade AS VARCHAR)
  
  -- Subrogated organization
  LEFT JOIN {{ ref('silver_dim_organizacoes') }} subrog_org
    ON c.orgao_subrogado_json ->> 'cnpj' = subrog_org.cnpj
  
  -- Subrogated unit
  LEFT JOIN {{ ref('silver_dim_unidades_orgao') }} subrog_unit
    ON c.orgao_subrogado_json ->> 'cnpj' = subrog_unit.cnpj_orgao
    AND CAST(c.unidade_subrogada_json ->> 'codigoUnidade' AS VARCHAR) = CAST(subrog_unit.codigo_unidade AS VARCHAR)
)

SELECT
  -- Surrogate key
  MD5(numero_controle_pncp) AS contract_key,
  
  -- Natural key
  numero_controle_pncp,
  
  -- Contract identifiers
  numero_controle_pncp_compra,
  numero_contrato_empenho,
  ano_contrato,
  sequencial_contrato,
  
  -- Dates
  data_assinatura,
  data_vigencia_inicio,
  data_vigencia_fim,
  data_publicacao_pncp,
  data_atualizacao,
  data_atualizacao_global,
  
  -- Duration calculations
  CASE 
    WHEN data_vigencia_inicio IS NOT NULL AND data_vigencia_fim IS NOT NULL
    THEN data_vigencia_fim - data_vigencia_inicio
    ELSE NULL
  END AS duracao_vigencia_dias,
  
  -- Amounts
  valor_inicial,
  valor_global,
  valor_parcela,
  valor_acumulado,
  
  -- Supplier information
  ni_fornecedor,
  tipo_pessoa,
  nome_razao_social_fornecedor,
  ni_fornecedor_subcontratado,
  nome_fornecedor_subcontratado,
  tipo_pessoa_subcontratada,
  
  -- Contract details
  objeto_contrato,
  informacao_complementar,
  processo,
  numero_parcelas,
  numero_retificacao,
  receita,
  
  -- Additional identifiers
  codigo_pais_fornecedor,
  identificador_cipi,
  url_cipi,
  usuario_nome,
  
  -- Foreign keys
  org_key,
  unit_key,
  subrog_org_key,
  subrog_unit_key,
  
  -- Type information (extracted from JSON)
  tipo_contrato_json ->> 'id' AS tipo_contrato_id,
  tipo_contrato_json ->> 'nome' AS tipo_contrato_nome,
  categoria_processo_json ->> 'id' AS categoria_processo_id,
  categoria_processo_json ->> 'nome' AS categoria_processo_nome,
  
  -- Derived attributes
  CASE 
    WHEN tipo_pessoa = 'PJ' THEN 'Pessoa Jurídica'
    WHEN tipo_pessoa = 'PF' THEN 'Pessoa Física'
    WHEN tipo_pessoa = 'PE' THEN 'Pessoa Estrangeira'
    ELSE 'Outros'
  END AS tipo_pessoa_descricao,
  
  CASE 
    WHEN valor_global IS NOT NULL AND valor_global > 0 THEN
      CASE 
        WHEN valor_global <= 17600 THEN 'Até R$ 17.600'
        WHEN valor_global <= 88000 THEN 'R$ 17.601 a R$ 88.000'
        WHEN valor_global <= 176000 THEN 'R$ 88.001 a R$ 176.000'
        WHEN valor_global <= 1408000 THEN 'R$ 176.001 a R$ 1.408.000'
        WHEN valor_global <= 3300000 THEN 'R$ 1.408.001 a R$ 3.300.000'
        ELSE 'Acima de R$ 3.300.000'
      END
    ELSE 'Não informado'
  END AS faixa_valor_global,
  
  CASE 
    WHEN data_vigencia_inicio IS NOT NULL AND data_vigencia_fim IS NOT NULL THEN
      CASE 
        WHEN data_vigencia_fim - data_vigencia_inicio <= 90 THEN 'Até 90 dias'
        WHEN data_vigencia_fim - data_vigencia_inicio <= 365 THEN '91 a 365 dias'
        WHEN data_vigencia_fim - data_vigencia_inicio <= 730 THEN '1 a 2 anos'
        WHEN data_vigencia_fim - data_vigencia_inicio <= 1825 THEN '2 a 5 anos'
        ELSE 'Mais de 5 anos'
      END
    ELSE 'Não informado'
  END AS faixa_duracao_vigencia,
  
  -- Data quality flags
  CASE 
    WHEN numero_controle_pncp IS NULL THEN 'Número de controle ausente'
    WHEN valor_global IS NULL OR valor_global <= 0 THEN 'Valor global inválido'
    WHEN data_assinatura IS NULL THEN 'Data de assinatura ausente'
    WHEN ni_fornecedor IS NULL THEN 'NI do fornecedor ausente'
    ELSE 'OK'
  END AS quality_flag,
  
  -- Metadata
  endpoint_name,
  data_date,
  extracted_at,
  run_id,
  
  -- JSON fallback
  contract_json,
  
  -- Audit
  CURRENT_TIMESTAMP AS created_at,
  CURRENT_TIMESTAMP AS updated_at

FROM contracts_with_keys
ORDER BY numero_controle_pncp
</file>

<file path="dbt_baliza/models/silver/silver_itens_contratacao.sql">
-- dbt_baliza/models/silver/silver_itens_contratacao.sql

{{
  config(
    materialized='incremental',
    unique_key='item_key',
    incremental_strategy='delete+insert'
  )
}}

WITH source_contratacoes AS (
  SELECT
    procurement_json,
    numero_controle_pncp
  FROM {{ ref('silver_contratacoes') }}
  {% if is_incremental() %}
  -- this filter will be applied on an incremental run
  WHERE data_inclusao > (SELECT MAX(data_inclusao) FROM {{ this }})
  {% endif %}
),

-- Unnest the items from the procurement JSON data
unpacked_items AS (
  SELECT
    numero_controle_pncp,
    json_extract(item, '$') AS item_data,
    -- ROW_NUMBER() OVER (PARTITION BY numero_controle_pncp ORDER BY 1) AS item_sequence
  FROM source_contratacoes,
  unnest(json_extract(procurement_json, '$.itens')) AS item
),

-- Structure and clean the item data
final AS (
  SELECT
    -- Surrogate key for the item
    numero_controle_pncp || '-' || (item_data ->> 'numeroItem') AS item_key,

    -- Foreign key to the parent procurement
    numero_controle_pncp,

    -- Item details
    CAST(item_data ->> 'numeroItem' AS INTEGER) AS numero_item,
    item_data ->> 'descricao' AS descricao_item,
    CAST(item_data ->> 'quantidade' AS DOUBLE) AS quantidade,
    CAST(item_data ->> 'valorUnitarioEstimado' AS DOUBLE) AS valor_unitario_estimado,
    CAST(item_data ->> 'valorTotal' AS DOUBLE) AS valor_total,
    item_data ->> 'unidadeMedida' AS unidade_medida,

    -- Item classification
    item_data ->> 'tipoBeneficioId' AS tipo_beneficio_id,
    CASE CAST(item_data ->> 'tipoBeneficioId' AS INTEGER)
        WHEN 1 THEN 'Participação exclusiva para ME/EPP'
        WHEN 2 THEN 'Subcontratação para ME/EPP'
        WHEN 3 THEN 'Cota reservada para ME/EPP'
        WHEN 4 THEN 'Sem benefício'
        WHEN 5 THEN 'Não se aplica'
        ELSE 'Não especificado'
    END AS tipo_beneficio_nome,

    -- Item status
    item_data ->> 'situacaoCompraItemId' AS situacao_compra_item_id,
    CASE CAST(item_data ->> 'situacaoCompraItemId' AS INTEGER)
        WHEN 1 THEN 'Em Andamento'
        WHEN 2 THEN 'Homologado'
        WHEN 3 THEN 'Anulado/Revogado/Cancelado'
        WHEN 4 THEN 'Deserto'
        WHEN 5 THEN 'Fracassado'
        ELSE 'Não especificado'
    END AS situacao_compra_item_nome,

    -- Timestamps
    TRY_CAST(item_data ->> 'dataInclusao' AS TIMESTAMP) AS data_inclusao,
    TRY_CAST(item_data ->> 'dataAtualizacao' AS TIMESTAMP) AS data_atualizacao

  FROM unpacked_items
)

SELECT * FROM final
</file>

<file path="docs/api_investigation/discover_modalidades.py">
#!/usr/bin/env python3
"""
Script para descobrir todas as modalidades de contratação disponíveis
"""

import asyncio
import httpx
from datetime import date, timedelta

async def test_modalidade(modalidade_id: int) -> dict:
    """Testa uma modalidade específica."""
    test_date = (date.today() - timedelta(days=7)).strftime("%Y%m%d")
    
    params = {
        "dataInicial": test_date,
        "dataFinal": test_date,
        "codigoModalidadeContratacao": modalidade_id,
        "pagina": 1,
        "tamanhoPagina": 10,
    }
    
    url = "https://pncp.gov.br/api/consulta/v1/contratacoes/publicacao"
    
    async with httpx.AsyncClient(timeout=10.0) as client:
        try:
            response = await client.get(url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                return {
                    "modalidade_id": modalidade_id,
                    "success": True,
                    "total_records": data.get("totalRegistros", 0),
                    "has_data": data.get("totalRegistros", 0) > 0,
                }
            else:
                return {
                    "modalidade_id": modalidade_id,
                    "success": False,
                    "status_code": response.status_code,
                    "error": response.text[:200],
                }
        except Exception as e:
            return {
                "modalidade_id": modalidade_id,
                "success": False,
                "error": str(e),
            }

async def discover_modalidades():
    """Descobre todas as modalidades válidas."""
    print("🔍 Descobrindo modalidades de contratação...")
    
    # Testa modalidades de 1 a 20 (cobertura inicial)
    modalidades_to_test = range(1, 21)
    
    results = []
    valid_modalidades = []
    
    for modalidade_id in modalidades_to_test:
        print(f"   Testando modalidade {modalidade_id}...")
        result = await test_modalidade(modalidade_id)
        results.append(result)
        
        if result["success"]:
            if result.get("has_data", False):
                print(f"   ✅ Modalidade {modalidade_id}: {result['total_records']} registros")
                valid_modalidades.append(modalidade_id)
            else:
                print(f"   ⚠️  Modalidade {modalidade_id}: Válida mas sem dados para esta data")
                valid_modalidades.append(modalidade_id)
        else:
            if result.get("status_code") == 422:
                print(f"   ❌ Modalidade {modalidade_id}: Inválida (422)")
            else:
                print(f"   💥 Modalidade {modalidade_id}: Erro {result.get('status_code', 'unknown')}")
        
        # Delay para ser respeitoso com a API
        await asyncio.sleep(0.5)
    
    print(f"\n📋 RESUMO:")
    print(f"✅ Modalidades válidas encontradas: {valid_modalidades}")
    print(f"📊 Total de modalidades válidas: {len(valid_modalidades)}")
    
    # Salva os resultados
    import json
    with open("modalidades_discovered.json", "w") as f:
        json.dump({
            "valid_modalidades": valid_modalidades,
            "test_results": results,
        }, f, indent=2)
    
    print(f"💾 Resultados salvos em: modalidades_discovered.json")
    
    return valid_modalidades

if __name__ == "__main__":
    asyncio.run(discover_modalidades())
</file>

<file path="docs/api_investigation/endpoint_test_results_final.json">
[
  {
    "endpoint": "contratos_publicacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratos?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "total_records": 8368,
    "total_pages": 837,
    "has_data": true,
    "sample_record": {
      "codigoPaisFornecedor": "BRA",
      "numeroControlePncpCompra": "02362976000130-1-000007/2025",
      "nomeRazaoSocialFornecedor": "GREMIO RECREATIVO CULTURAL BLOCO CARNAVALESCO INIMIGOS DA SEGUNDA",
      "anoContrato": 2025,
      "tipoContrato": {
        "id": 1,
        "nome": "Contrato (termo inicial)"
      },
      "numeroContratoEmpenho": "153/2025-FCI",
      "dataAssinatura": "2025-07-04",
      "dataVigenciaInicio": "2025-07-04",
      "dataVigenciaFim": "2025-12-31",
      "niFornecedor": "12573806000158",
      "tipoPessoa": "PJ",
      "orgaoEntidade": {
        "cnpj": "02362976000130",
        "razaoSocial": "FUNDACAO CULTURAL DE ITAJAI",
        "poderId": "E",
        "esferaId": "M"
      },
      "categoriaProcesso": {
        "id": 8,
        "nome": "Servi\u00e7os"
      },
      "dataPublicacaoPncp": "2025-07-10T00:00:12",
      "dataAtualizacao": "2025-07-10T00:00:13",
      "sequencialContrato": 184,
      "unidadeOrgao": {
        "ufNome": "Santa Catarina",
        "codigoIbge": "4208203",
        "codigoUnidade": "33",
        "nomeUnidade": "Funda\u00e7\u00e3o Cultural de Itaja\u00ed - FCI",
        "ufSigla": "SC",
        "municipioNome": "Itaja\u00ed"
      },
      "informacaoComplementar": null,
      "processo": "CR-007/2025-FCI",
      "unidadeSubRogada": null,
      "orgaoSubRogado": null,
      "niFornecedorSubContratado": null,
      "nomeFornecedorSubContratado": null,
      "numeroControlePNCP": "02362976000130-2-000184/2025",
      "receita": false,
      "numeroParcelas": 2,
      "numeroRetificacao": 0,
      "tipoPessoaSubContratada": null,
      "objetoContrato": "O presente edital tem por objeto o credenciamento de artistas, grupos e coletivos culturais para a realiza\u00e7\u00e3o de apresenta\u00e7\u00f5es art\u00edsticas e interven\u00e7\u00f5es culturais no munic\u00edpio de Itaja\u00ed.",
      "valorInicial": 20000.0,
      "valorParcela": 20000.0,
      "valorGlobal": 20000.0,
      "valorAcumulado": null,
      "dataAtualizacaoGlobal": "2025-07-10T00:00:13",
      "identificadorCipi": null,
      "urlCipi": null,
      "usuarioNome": "P\u00fablica Tecnologia Ltda."
    }
  },
  {
    "endpoint": "contratos_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratos/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "total_records": 9621,
    "total_pages": 963,
    "has_data": true,
    "sample_record": {
      "codigoPaisFornecedor": "BRA",
      "numeroControlePncpCompra": "03112386000111-1-000051/2023",
      "numeroControlePNCP": "03112386000111-2-000082/2024",
      "anoContrato": 2024,
      "tipoContrato": {
        "id": 8,
        "nome": "Outros"
      },
      "numeroContratoEmpenho": "00001",
      "dataAssinatura": "2024-03-11",
      "dataVigenciaInicio": "2024-03-11",
      "dataVigenciaFim": "2029-03-11",
      "niFornecedor": "46191353000117",
      "tipoPessoa": "PJ",
      "orgaoEntidade": {
        "cnpj": "03112386000111",
        "poderId": "E",
        "esferaId": "F",
        "razaoSocial": "AGENCIA NACIONAL DE VIGILANCIA SANITARIA"
      },
      "categoriaProcesso": {
        "id": 1,
        "nome": "Cess\u00e3o"
      },
      "dataPublicacaoPncp": "2025-02-24T07:27:10",
      "dataAtualizacao": "2025-07-10T11:34:04",
      "sequencialContrato": 82,
      "unidadeOrgao": {
        "ufNome": "Distrito Federal",
        "codigoUnidade": "253002",
        "nomeUnidade": "AGENCIA NACIONAL DE VIGILANCIA SANITARIA - DF",
        "ufSigla": "DF",
        "municipioNome": "Bras\u00edlia",
        "codigoIbge": "5300108"
      },
      "informacaoComplementar": "",
      "processo": "25351.924246/2022-33",
      "unidadeSubRogada": null,
      "orgaoSubRogado": null,
      "nomeRazaoSocialFornecedor": "PORTOS RS - AUTORIDADE PORTUARIA DOS PORTOS DO RIO GRANDE DO SUL S.A.",
      "niFornecedorSubContratado": null,
      "nomeFornecedorSubContratado": null,
      "receita": false,
      "numeroParcelas": 60,
      "numeroRetificacao": 1,
      "tipoPessoaSubContratada": null,
      "objetoContrato": "CESS\u00c3O N\u00c3O ONEROSA DE USO DE \u00c1REA NO PORTO VELHO, NA CIDADE DE RIO GRANDE/RS",
      "valorInicial": 1.0,
      "valorParcela": 0.0167,
      "valorGlobal": 1.0,
      "valorAcumulado": null,
      "dataAtualizacaoGlobal": "2025-07-10T11:34:04",
      "identificadorCipi": null,
      "urlCipi": null,
      "usuarioNome": "Contratos.gov.br"
    }
  },
  {
    "endpoint": "atas_periodo",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/atas?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "total_records": 410326,
    "total_pages": 41033,
    "has_data": true,
    "sample_record": {
      "numeroControlePNCPAta": "18457226000181-1-000015/2023-000001",
      "numeroAtaRegistroPreco": "NPERP 003/2023",
      "anoAta": 2023,
      "numeroControlePNCPCompra": "18457226000181-1-000015/2023",
      "cancelado": false,
      "dataCancelamento": null,
      "dataAssinatura": "2023-06-16",
      "vigenciaInicio": "2023-07-07",
      "vigenciaFim": "2026-10-07",
      "dataPublicacaoPncp": "2023-07-06",
      "dataInclusao": "2023-07-06",
      "dataAtualizacao": "2023-07-06",
      "dataAtualizacaoGlobal": "2023-07-06",
      "usuario": "Licita + Brasil",
      "objetoContratacao": "A presente licita\u00e7\u00e3o tem por objeto a futura e eventual contrata\u00e7\u00e3o de empresa especializada visando a presta\u00e7\u00e3o de servi\u00e7o de an\u00e1lises t\u00e9cnicas com amostragem e ensaios para o cumprimento do Programa de Automonitoramento da Licen\u00e7a Ambiental Simplificada N\u00ba 1924/2021 do empreendimento do Munic\u00edpio de Santa Vit\u00f3ria \u2013 Canaliza\u00e7\u00e3o do C\u00f3rrego Santa Vit\u00f3ria \u2013 que consta no item 2 [qualidade do ar com Di\u00f3xido de Enxofre (SO2), Part\u00edculas Totais em Suspens\u00e3o (PTS), Mon\u00f3xido de Carbono (co) e Oz\u00f4nio (O3)], item 3 (monitoramento da frota com colora\u00e7\u00e3o) e item 4 (ru\u00eddos) do Anexo II do Parecer T\u00e9cnico de Licen\u00e7a Ambiental Simplificada (LAS) n\u00ba 30321878, com as an\u00e1lises e entrega dos relat\u00f3rios semestrais e anuais, para o per\u00edodo de 36 meses, acompanhados dos certificados de calibra\u00e7\u00e3o dos equipamentos de amostragem quando necess\u00e1rio, ART\u2019s emitidas pelos profissionais respons\u00e1veis, demonstrando o atendimento aos padr\u00f5es definidos nas normas vigentes para cada monitoramento, e incluindo as despesas necess\u00e1rias \u00e0s coletas das amostras para cumprimento do servi\u00e7o, conforme especifica\u00e7\u00f5es do Termo de Refer\u00eancia.",
      "cnpjOrgao": "18457226000181",
      "nomeOrgao": "MUNICIPIO DE SANTA VITORIA",
      "cnpjOrgaoSubrogado": null,
      "nomeOrgaoSubrogado": null,
      "codigoUnidadeOrgao": "1",
      "nomeUnidadeOrgao": "MUNICIPIO DE SANTA VITORIA",
      "codigoUnidadeOrgaoSubrogado": null,
      "nomeUnidadeOrgaoSubrogado": null
    }
  },
  {
    "endpoint": "atas_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/atas/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "total_records": 2344,
    "total_pages": 235,
    "has_data": true,
    "sample_record": {
      "numeroControlePNCPAta": "01409580000138-1-000115/2023-000001",
      "numeroAtaRegistroPreco": "00061",
      "anoAta": 2023,
      "numeroControlePNCPCompra": "01409580000138-1-000115/2023",
      "cancelado": false,
      "dataCancelamento": null,
      "dataAssinatura": "2023-08-16",
      "vigenciaInicio": "2023-08-21",
      "vigenciaFim": "2025-08-21",
      "dataPublicacaoPncp": "2023-08-18",
      "dataInclusao": "2023-08-18",
      "dataAtualizacao": "2024-09-02",
      "dataAtualizacaoGlobal": "2025-07-10",
      "usuario": "Contratos.gov.br",
      "objetoContratacao": "A presente licita\u00e7\u00e3o tem por objeto o Registro de Pre\u00e7os para a eventual e futura contrata\u00e7\u00e3o de empresa especializada na presta\u00e7\u00e3o de servi\u00e7os de execu\u00e7\u00e3o de manuten\u00e7\u00e3o de vias e revitaliza\u00e7\u00e3o de capa asf\u00e1ltica, incluindo remendo profundo, reciclagem de base, base de solo estabilizado granulometricamente, fresagem, refor\u00e7o da pavimenta\u00e7\u00e3o com geogrelha, whitetopping (pavimento de concreto), pintura de liga\u00e7\u00e3o, concreto betuminoso usinado a quente \u2013 CBUQ.",
      "cnpjOrgao": "01409580000138",
      "nomeOrgao": "ESTADO DE GOIAS",
      "cnpjOrgaoSubrogado": null,
      "nomeOrgaoSubrogado": null,
      "codigoUnidadeOrgao": "926748",
      "nomeUnidadeOrgao": "SECRETARIA MUNICIPAL DE ADMINISTRA\u00c7\u00c3O - GO",
      "codigoUnidadeOrgaoSubrogado": null,
      "nomeUnidadeOrgaoSubrogado": null
    }
  },
  {
    "endpoint": "contratacoes_publicacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/publicacao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710&codigoModalidadeContratacao=5",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710",
      "codigoModalidadeContratacao": 5
    },
    "total_records": 17,
    "total_pages": 2,
    "has_data": true,
    "sample_record": {
      "numeroControlePNCP": "87613659000100-1-000247/2025",
      "srp": false,
      "orgaoEntidade": {
        "cnpj": "87613659000100",
        "poderId": "N",
        "esferaId": "M",
        "razaoSocial": "MUNICIPIO DE PORTO LUCENA"
      },
      "anoCompra": 2025,
      "sequencialCompra": 247,
      "dataInclusao": "2025-07-10T09:35:24",
      "dataPublicacaoPncp": "2025-07-10T09:35:24",
      "dataAtualizacao": "2025-07-10T16:51:44",
      "numeroCompra": "1",
      "unidadeOrgao": {
        "ufNome": "Rio Grande do Sul",
        "codigoUnidade": "1",
        "nomeUnidade": "MUNICIPIO DE PORTO LUCENA/RS",
        "ufSigla": "RS",
        "municipioNome": "Porto Lucena",
        "codigoIbge": "4315008"
      },
      "amparoLegal": {
        "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
        "nome": "Lei 14.133/2021, Art. 28, II ",
        "codigo": 2
      },
      "dataAberturaProposta": "2025-08-01T08:00:00",
      "dataEncerramentoProposta": "2025-08-01T08:59:00",
      "informacaoComplementar": "",
      "processo": "258",
      "objetoCompra": "Contrata\u00e7\u00e3o de empresa objetivando o  fornecimento de materiais e presta\u00e7\u00e3o de servi\u00e7os para a execu\u00e7\u00e3o de reforma no Servi\u00e7o de Conviv\u00eancia e Fortalecimento de V\u00ednculos, junto ao CRAS, no munic\u00edpio de Porto Lucena/RS, com recursos do Piso Ga\u00facho Especial do Programa Avan\u00e7ar SUAS Reconstru\u00e7\u00e3o 2024, conforme memorial descritivo, planilha or\u00e7ament\u00e1ria, cronograma f\u00edsico-financeiro, Detalhamento detalhado do BDI e Encargos Sociais e planta baixa anexos ao Edital.",
      "linkSistemaOrigem": "HTTPS://PORTOLUCENA.RS.GOV.BR/SITE/LICITACOES",
      "justificativaPresencial": "",
      "unidadeSubRogada": null,
      "orgaoSubRogado": null,
      "valorTotalHomologado": null,
      "modoDisputaId": 1,
      "modalidadeId": 5,
      "linkProcessoEletronico": null,
      "dataAtualizacaoGlobal": "2025-07-10T16:51:44",
      "valorTotalEstimado": 256162.95,
      "modalidadeNome": "Concorr\u00eancia - Presencial",
      "modoDisputaNome": "Aberto",
      "tipoInstrumentoConvocatorioCodigo": 1,
      "tipoInstrumentoConvocatorioNome": "Edital",
      "fontesOrcamentarias": [],
      "situacaoCompraId": 1,
      "situacaoCompraNome": "Divulgada no PNCP",
      "usuarioNome": "Abase Sistemas"
    }
  },
  {
    "endpoint": "contratacoes_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710&codigoModalidadeContratacao=5",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710",
      "codigoModalidadeContratacao": 5
    },
    "total_records": 26,
    "total_pages": 3,
    "has_data": true,
    "sample_record": {
      "numeroControlePNCP": "67662437000161-1-000045/2025",
      "srp": false,
      "orgaoEntidade": {
        "cnpj": "67662437000161",
        "poderId": "N",
        "esferaId": "M",
        "razaoSocial": "MUNICIPIO DE EUCLIDES DA CUNHA PAULISTA"
      },
      "anoCompra": 2025,
      "sequencialCompra": 45,
      "dataInclusao": "2025-07-08T13:59:26",
      "dataPublicacaoPncp": "2025-07-08T13:59:26",
      "dataAtualizacao": "2025-07-08T13:59:26",
      "numeroCompra": "4 | Processo 315",
      "unidadeOrgao": {
        "ufNome": "S\u00e3o Paulo",
        "codigoUnidade": "0000",
        "nomeUnidade": "PREFEITURA MUNICIPAL",
        "ufSigla": "SP",
        "municipioNome": "Euclides da Cunha Paulista",
        "codigoIbge": "3515350"
      },
      "amparoLegal": {
        "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
        "nome": "Lei 14.133/2021, Art. 28, II ",
        "codigo": 2
      },
      "dataAberturaProposta": "2025-07-08T08:00:00",
      "dataEncerramentoProposta": "2025-08-05T08:30:00",
      "informacaoComplementar": " ",
      "processo": "4",
      "objetoCompra": "CONTRATACAO DE EMPRESA ESPECIALIZADA PARA EXECUCAO DE OBRA DA REDE DE DISTRIBUICAO ELETRICA DO NOVO CDHU NO MUNICIPIO DE EUCLIDES DA CUNHA PAULISTA.",
      "linkSistemaOrigem": " ",
      "justificativaPresencial": "atender as necessidades da departamento de obras e engenharia",
      "unidadeSubRogada": null,
      "orgaoSubRogado": null,
      "valorTotalHomologado": null,
      "modoDisputaId": 6,
      "modalidadeId": 5,
      "linkProcessoEletronico": null,
      "dataAtualizacaoGlobal": "2025-07-10T08:11:26",
      "valorTotalEstimado": 192319.79,
      "modalidadeNome": "Concorr\u00eancia - Presencial",
      "modoDisputaNome": "Fechado-Aberto",
      "tipoInstrumentoConvocatorioCodigo": 1,
      "tipoInstrumentoConvocatorioNome": "Edital",
      "fontesOrcamentarias": [],
      "situacaoCompraId": 1,
      "situacaoCompraNome": "Divulgada no PNCP",
      "usuarioNome": "Governan\u00e7abrasil Tecnologia e Gest\u00e3o em Servi\u00e7os"
    }
  },
  {
    "endpoint": "pca_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/pca/atualizacao?tamanhoPagina=10&pagina=1&dataInicio=20250101&dataFim=20250131",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicio": "20250101",
      "dataFim": "20250131"
    },
    "total_records": 212868,
    "total_pages": 21287,
    "has_data": true,
    "sample_record": {
      "itens": [
        {
          "descricaoItem": "CADEIRA DIGITADOR",
          "nomeClassificacaoCatalogo": "Material",
          "quantidadeEstimada": 5.0,
          "pdmCodigo": null,
          "dataInclusao": "2025-01-15T07:46:12",
          "numeroItem": 1,
          "dataAtualizacao": "2025-01-15T07:46:12",
          "valorTotal": 5000.0,
          "pdmDescricao": null,
          "codigoItem": "1",
          "unidadeRequisitante": null,
          "grupoContratacaoCodigo": null,
          "grupoContratacaoNome": null,
          "classificacaoSuperiorCodigo": "7110",
          "classificacaoSuperiorNome": "MOBILI\u00c1RIO PARA ESCRIT\u00d3RIO",
          "unidadeFornecimento": "LEGISLATIVO",
          "valorUnitario": 1000.0,
          "valorOrcamentoExercicio": 31987000.0,
          "dataDesejada": "2025-03-29",
          "categoriaItemPcaNome": "Material",
          "classificacaoCatalogoId": 1
        },
        {
          "descricaoItem": "INSTALACAO - PERSIANAS VERTICAIS/HORIZONTAIS",
          "nomeClassificacaoCatalogo": "Servi\u00e7o",
          "quantidadeEstimada": 1.0,
          "pdmCodigo": null,
          "dataInclusao": "2025-01-15T07:46:12",
          "numeroItem": 2,
          "dataAtualizacao": "2025-01-15T07:46:12",
          "valorTotal": 10900.0,
          "pdmDescricao": null,
          "codigoItem": "1",
          "unidadeRequisitante": null,
          "grupoContratacaoCodigo": null,
          "grupoContratacaoNome": null,
          "classificacaoSuperiorCodigo": "5469",
          "classificacaoSuperiorNome": "OUTROS SERVI\u00c7OS DE INSTALA\u00c7\u00c3O",
          "unidadeFornecimento": "LEGISLATIVO",
          "valorUnitario": 10900.0,
          "valorOrcamentoExercicio": 31987000.0,
          "dataDesejada": "2025-03-29",
          "categoriaItemPcaNome": "Servi\u00e7o",
          "classificacaoCatalogoId": 2
        },
        {
          "descricaoItem": "CARIMBO",
          "nomeClassificacaoCatalogo": "Material",
          "quantidadeEstimada": 10.0,
          "pdmCodigo": null,
          "dataInclusao": "2025-01-15T07:46:12",
          "numeroItem": 3,
          "dataAtualizacao": "2025-01-15T07:46:12",
          "valorTotal": 339.9,
          "pdmDescricao": null,
          "codigoItem": "1",
          "unidadeRequisitante": null,
          "grupoContratacaoCodigo": null,
          "grupoContratacaoNome": null,
          "classificacaoSuperiorCodigo": "7520",
          "classificacaoSuperiorNome": "ACESS\u00d3RIOS E DISPOSITIVOS PARA ESCRIT\u00d3RIO",
          "unidadeFornecimento": "LEGISLATIVO",
          "valorUnitario": 33.99,
          "valorOrcamentoExercicio": 31987000.0,
          "dataDesejada": "2025-03-29",
          "categoriaItemPcaNome": "Material",
          "classificacaoCatalogoId": 1
        },
        {
          "descricaoItem": "FONE OUVIDO",
          "nomeClassificacaoCatalogo": "Material",
          "quantidadeEstimada": 8.0,
          "pdmCodigo": null,
          "dataInclusao": "2025-01-15T07:46:12",
          "numeroItem": 4,
          "dataAtualizacao": "2025-01-15T07:46:12",
          "valorTotal": 1070.0,
          "pdmDescricao": null,
          "codigoItem": "1",
          "unidadeRequisitante": null,
          "grupoContratacaoCodigo": null,
          "grupoContratacaoNome": null,
          "classificacaoSuperiorCodigo": "5965",
          "classificacaoSuperiorNome": "FONES, MICROFONES E ALTO-FALANTES",
          "unidadeFornecimento": "LEGISLATIVO",
          "valorUnitario": 133.75,
          "valorOrcamentoExercicio": 31987000.0,
          "dataDesejada": "2025-03-29",
          "categoriaItemPcaNome": "Material",
          "classificacaoCatalogoId": 1
        },
        {
          "descricaoItem": "DESCANSO P\u00c9S",
          "nomeClassificacaoCatalogo": "Material",
          "quantidadeEstimada": 3.0,
          "pdmCodigo": null,
          "dataInclusao": "2025-01-15T07:46:12",
          "numeroItem": 5,
          "dataAtualizacao": "2025-01-15T07:46:12",
          "valorTotal": 168.0,
          "pdmDescricao": null,
          "codigoItem": "1",
          "unidadeRequisitante": null,
          "grupoContratacaoCodigo": null,
          "grupoContratacaoNome": null,
          "classificacaoSuperiorCodigo": "7195",
          "classificacaoSuperiorNome": "MOBILI\u00c1RIOS DIVERSOS E ACESS\u00d3RIOS",
          "unidadeFornecimento": "LEGISLATIVO",
          "valorUnitario": 56.0,
          "valorOrcamentoExercicio": 31987000.0,
          "dataDesejada": "2025-03-29",
          "categoriaItemPcaNome": "Material",
          "classificacaoCatalogoId": 1
        },
        {
          "descricaoItem": "MOUSE PAD",
          "nomeClassificacaoCatalogo": "Material",
          "quantidadeEstimada": 3.0,
          "pdmCodigo": null,
          "dataInclusao": "2025-01-15T07:46:12",
          "numeroItem": 6,
          "dataAtualizacao": "2025-01-15T07:46:12",
          "valorTotal": 120.0,
          "pdmDescricao": null,
          "codigoItem": "1",
          "unidadeRequisitante": null,
          "grupoContratacaoCodigo": null,
          "grupoContratacaoNome": null,
          "classificacaoSuperiorCodigo": "7090",
          "classificacaoSuperiorNome": "SUPRIMENTOS DE INFORM\u00c1TICA - TIC",
          "unidadeFornecimento": "LEGISLATIVO",
          "valorUnitario": 40.0,
          "valorOrcamentoExercicio": 31987000.0,
          "dataDesejada": "2025-03-29",
          "categoriaItemPcaNome": "Material",
          "classificacaoCatalogoId": 1
        },
        {
          "descricaoItem": "MOUSE COMPUTADOR",
          "nomeClassificacaoCatalogo": "Material",
          "quantidadeEstimada": 11.0,
          "pdmCodigo": null,
          "dataInclusao": "2025-01-15T07:46:12",
          "numeroItem": 7,
          "dataAtualizacao": "2025-01-15T07:46:12",
          "valorTotal": 770.0,
          "pdmDescricao": null,
          "codigoItem": "1",
          "unidadeRequisitante": null,
          "grupoContratacaoCodigo": null,
          "grupoContratacaoNome": null,
          "classificacaoSuperiorCodigo": "7060",
          "classificacaoSuperiorNome": "PE\u00c7AS E ACESS\u00d3RIOS PARA COMPUTADORES",
          "unidadeFornecimento": "LEGISLATIVO",
          "valorUnitario": 70.0,
          "valorOrcamentoExercicio": 31987000.0,
          "dataDesejada": "2025-03-29",
          "categoriaItemPcaNome": "Material",
          "classificacaoCatalogoId": 1
        },
        {
          "descricaoItem": "INSTALACAO / MANUTENCAO DE VIDRO TEMPERADO/ LAMINADO/CRISTALACRILICO/EM PORTA / JANELA / BOX",
          "nomeClassificacaoCatalogo": "Servi\u00e7o",
          "quantidadeEstimada": 1.0,
          "pdmCodigo": null,
          "dataInclusao": "2025-01-15T07:46:12",
          "numeroItem": 8,
          "dataAtualizacao": "2025-01-15T07:46:12",
          "valorTotal": 5000.0,
          "pdmDescricao": null,
          "codigoItem": "1",
          "unidadeRequisitante": null,
          "grupoContratacaoCodigo": null,
          "grupoContratacaoNome": null,
          "classificacaoSuperiorCodigo": "5471",
          "classificacaoSuperiorNome": "SERVI\u00c7OS DE INSTALA\u00c7\u00c3O DE VIDROS",
          "unidadeFornecimento": "LEGISLATIVO",
          "valorUnitario": 5000.0,
          "valorOrcamentoExercicio": 31987000.0,
          "dataDesejada": "2025-03-29",
          "categoriaItemPcaNome": "Servi\u00e7o",
          "classificacaoCatalogoId": 2
        }
      ],
      "codigoUnidade": "2",
      "nomeUnidade": "Departamento Legislativo-DEL",
      "anoPca": 2025,
      "orgaoEntidadeRazaoSocial": "BRAGANCA PAULISTA CAMARA MUNICIPAL",
      "orgaoEntidadeCnpj": "47015532000166",
      "idPcaPncp": "47015532000166-0-000002/2025",
      "dataPublicacaoPNCP": "2025-01-15T07:46:12",
      "dataAtualizacaoGlobalPCA": "2025-01-15T07:46:12"
    }
  },
  {
    "endpoint": "instrumentoscobranca_inclusao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/instrumentoscobranca/inclusao?tamanhoPagina=10&pagina=1&dataInicial=20250301&dataFinal=20250331",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250301",
      "dataFinal": "20250331"
    },
    "total_records": 3658,
    "total_pages": 366,
    "has_data": true,
    "sample_record": {
      "cnpj": "03277610000125",
      "ano": 2025,
      "sequencialContrato": 129,
      "sequencialInstrumentoCobranca": 1,
      "tipoInstrumentoCobranca": {
        "id": 1,
        "nome": "Nota Fiscal Eletr\u00f4nica (NF-e)",
        "descricao": "Documento de exist\u00eancia apenas digital, emitido e armazenado eletronicamente, com o intuito de documentar, para fins fiscais, uma opera\u00e7\u00e3o de circula\u00e7\u00e3o de mercadorias ou uma presta\u00e7\u00e3o de servi\u00e7os, ocorrida entre as partes. Sua validade jur\u00eddica \u00e9 garantida pela assinatura digital do remetente (garantia de autoria e de integridade) e a Autoriza\u00e7\u00e3o de uso fornecida pelo Fisco, antes da ocorr\u00eancia do fato gerador.",
        "dataInclusao": "2025-02-07T14:51:49",
        "dataAtualizacao": "2025-02-07T14:53:31",
        "statusAtivo": true
      },
      "numeroInstrumentoCobranca": "1020",
      "dataEmissaoDocumento": "2025-01-20",
      "observacao": null,
      "chaveNFe": "15250126174873000104550030000010201651717123",
      "fonteNFe": 1,
      "dataConsultaNFe": "2025-03-21T07:21:57",
      "statusResponseNFe": "200",
      "jsonResponseNFe": "{\"notaFiscalDTO\":{\"id\":247180205,\"codigoOrgaoSuperiorDestinatario\":\"52000\",\"orgaoSuperiorDestinatario\":\"Minist\u00e9rio da Defesa\",\"codigoOrgaoDestinatario\":\"52000\",\"orgaoDestinatario\":\"Minist\u00e9rio da Defesa - Unidades com v\u00ednculo direto\",\"nomeFornecedor\":\"MELLUZZI DISTRIBUIDORA DE MEDICAMENTOS LTDA\",\"cnpjFornecedor\":\"26.174.873/0001-04\",\"municipioFornecedor\":\"ANANINDEUA\",\"chaveNotaFiscal\":\"15250126174873000104550030000010201651717123\",\"valorNotaFiscal\":\"4.920,00\",\"tipoEventoMaisRecente\":\"Autoriza\u00e7\u00e3o de Uso\",\"dataTipoEventoMaisRecente\":\"20/01/2025 14:30:57\",\"dataEmissao\":\"20/01/2025\",\"numero\":1020,\"serie\":3},\"itensNotaFiscal\":[{\"numeroProduto\":\"1\",\"descricaoProdutoServico\":\"ATADURA DE CREPOM 20CMX1,8M 13F NAO ESTERIL TEXCARE\",\"codigoNcmSh\":\"30051090\",\"ncmSh\":\"Outros pensos adesivos, artigos an\u00e1logos, com camada adesiva\",\"cfop\":\"6102\",\"quantidade\":\"6.000,00\",\"unidade\":\"UN\",\"valorUnitario\":\"0,82\",\"valor\":\"4.920,00\"}],\"eventosNotaFiscal\":[]}",
      "notaFiscalEletronica": {
        "instrumentoCobrancaId": 1,
        "chave": "15250126174873000104550030000010201651717123",
        "nfTransparenciaID": 247180205,
        "numero": 1020,
        "serie": 3,
        "dataEmissao": "20/01/2025",
        "niEmitente": "26.174.873/0001-04",
        "nomeEmitente": "MELLUZZI DISTRIBUIDORA DE MEDICAMENTOS LTDA",
        "nomeMunicipioEmitente": "ANANINDEUA",
        "codigoOrgaoDestinatario": "52000",
        "nomeOrgaoDestinatario": "Minist\u00e9rio da Defesa - Unidades com v\u00ednculo direto",
        "codigoOrgaoSuperiorDestinatario": "52000",
        "nomeOrgaoSuperiorDestinatario": "Minist\u00e9rio da Defesa",
        "valorNotaFiscal": "4.920,00",
        "tipoEventoMaisRecente": "Autoriza\u00e7\u00e3o de Uso",
        "dataTipoEventoMaisRecente": "20/01/2025 14:30:57",
        "dataInclusao": "2025-03-21T07:21:57",
        "dataAtualizacao": "2025-03-21T07:21:57",
        "itens": [
          {
            "numeroItem": "1",
            "descricaoProdutoServico": "ATADURA DE CREPOM 20CMX1,8M 13F NAO ESTERIL TEXCARE",
            "codigoNCM": "30051090",
            "descricaoNCM": "Outros pensos adesivos, artigos an\u00e1logos, com camada adesiva",
            "cfop": "6102",
            "quantidade": "6.000,00",
            "unidade": "UN",
            "valorUnitario": "0,82",
            "valorTotal": "4.920,00"
          }
        ],
        "eventos": []
      },
      "dataInclusao": "2025-03-21T07:21:57",
      "dataAtualizacao": "2025-03-21T07:21:57",
      "recuperarContratoDTO": {
        "codigoPaisFornecedor": "BRA",
        "numeroControlePncpCompra": "03277610000125-1-000293/2024",
        "nomeRazaoSocialFornecedor": "MELLUZZI DISTRIBUIDORA DE MEDICAMENTOS LTDA",
        "anoContrato": 2025,
        "tipoContrato": {
          "id": 7,
          "nome": "Empenho"
        },
        "numeroContratoEmpenho": "2025NE000048",
        "dataAssinatura": "2025-01-13",
        "dataVigenciaInicio": "2025-01-13",
        "dataVigenciaFim": "2025-12-31",
        "niFornecedor": "26174873000104",
        "tipoPessoa": "PJ",
        "orgaoEntidade": {
          "cnpj": "03277610000125",
          "razaoSocial": "MINISTERIO DA DEFESA",
          "poderId": "E",
          "esferaId": "F"
        },
        "categoriaProcesso": {
          "id": 2,
          "nome": "Compras"
        },
        "dataPublicacaoPncp": "2025-02-20T07:44:04",
        "dataAtualizacao": "2025-02-24T08:55:10",
        "sequencialContrato": 129,
        "unidadeOrgao": {
          "ufNome": "Distrito Federal",
          "codigoIbge": "5300108",
          "codigoUnidade": "112408",
          "nomeUnidade": "HOSPITAL DAS FORCAS ARMADAS",
          "ufSigla": "DF",
          "municipioNome": "Bras\u00edlia"
        },
        "informacaoComplementar": "11240805900362024 - UASG Minuta: 112408",
        "processo": "60550.000487/2025-92",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "niFornecedorSubContratado": null,
        "nomeFornecedorSubContratado": null,
        "numeroControlePNCP": "03277610000125-2-000129/2025",
        "receita": false,
        "numeroParcelas": 1,
        "numeroRetificacao": 1,
        "tipoPessoaSubContratada": null,
        "objetoContrato": "PREG\u00c3O 90036/2024 HFA PAM 3/2025 SCAMMH HFA (ID 7693426)\r\nAQUISI\u00c7\u00c3O DE MATERIAL HOSPITALAR\r\nAPLICA\u00c7\u00c3O: SCAMMH HFA / A AQUISI\u00c7\u00c3O VINCULA-SE AO PROCESSO SEI N\u00ba 60550.037396/2023-41.",
        "valorInicial": 4920.0,
        "valorParcela": 4920.0,
        "valorGlobal": 4920.0,
        "valorAcumulado": null,
        "dataAtualizacaoGlobal": "2025-03-21T07:21:57",
        "identificadorCipi": null,
        "urlCipi": null,
        "usuarioNome": "Contratos.gov.br"
      }
    }
  },
  {
    "endpoint": "contratacoes_proposta",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/proposta?tamanhoPagina=10&pagina=1&dataFinal=20250816&codigoModalidadeContratacao=5",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataFinal": "20250816",
      "codigoModalidadeContratacao": 5
    },
    "total_records": 169,
    "total_pages": 17,
    "has_data": true,
    "sample_record": {
      "numeroControlePNCP": "42498600000171-1-001371/2025",
      "srp": false,
      "orgaoEntidade": {
        "cnpj": "42498600000171",
        "poderId": "N",
        "esferaId": "E",
        "razaoSocial": "ESTADO DO RIO DE JANEIRO"
      },
      "anoCompra": 2025,
      "sequencialCompra": 1371,
      "dataInclusao": "2025-03-24T15:55:31",
      "dataPublicacaoPncp": "2025-03-24T15:55:31",
      "dataAtualizacao": "2025-05-26T10:22:56",
      "numeroCompra": "2",
      "unidadeOrgao": {
        "ufNome": "Rio de Janeiro",
        "codigoUnidade": "927648",
        "nomeUnidade": "JUNTA COMERCIAL DO ESTADO DO RIO DE JANEIRO",
        "ufSigla": "RJ",
        "municipioNome": "Rio de Janeiro",
        "codigoIbge": "3304557"
      },
      "amparoLegal": {
        "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
        "nome": "Lei 14.133/2021, Art. 28, II ",
        "codigo": 2
      },
      "dataAberturaProposta": "2025-05-27T08:00:00",
      "dataEncerramentoProposta": "2025-07-18T10:00:00",
      "informacaoComplementar": "",
      "processo": "220005/000593/25",
      "objetoCompra": "Contrata\u00e7\u00e3o de servi\u00e7os t\u00e9cnicos especializados para execu\u00e7\u00e3o da etapa de cenografia e equipamentos do projeto intitulado como \u201cConceito do Centro de Mem\u00f3ria do Registro Empresarial\u201d, com execu\u00e7\u00e3o, implemento, operacionaliza\u00e7\u00e3o, fornecimento de materiais e equipamentos e demais a\u00e7\u00f5es necess\u00e1rias visando \u00e0 entrega do objeto constante do  projeto, em atendimento \u00e0s necessidades da Junta Comercial do Estado do Rio de Janeiro.",
      "linkSistemaOrigem": null,
      "justificativaPresencial": "Decreto n\u00ba 10.024/2019, Art. 1\u00ba, \u00a7 4\u00ba, combinado com o Decreto Estadual n\u00ba 48.865/2023, Arts. 4\u00ba e 9\u00ba.",
      "unidadeSubRogada": null,
      "orgaoSubRogado": null,
      "valorTotalHomologado": null,
      "modoDisputaId": 6,
      "modalidadeId": 5,
      "linkProcessoEletronico": null,
      "dataAtualizacaoGlobal": "2025-05-26T10:22:56",
      "valorTotalEstimado": 0.0,
      "modalidadeNome": "Concorr\u00eancia - Presencial",
      "modoDisputaNome": "Fechado-Aberto",
      "tipoInstrumentoConvocatorioCodigo": 1,
      "tipoInstrumentoConvocatorioNome": "Edital",
      "fontesOrcamentarias": [],
      "situacaoCompraId": 3,
      "situacaoCompraNome": "Anulada",
      "usuarioNome": "Compras.gov.br"
    }
  }
]
</file>

<file path="docs/api_investigation/endpoint_test_results_fixed.json">
[
  {
    "endpoint": "contratos_publicacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratos?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "test_date": "2025-07-10",
    "date_strategy": "recent_past",
    "total_records": 8368,
    "total_pages": 837,
    "has_data": true,
    "data_sample": [
      {
        "codigoPaisFornecedor": "BRA",
        "numeroControlePncpCompra": "02362976000130-1-000007/2025",
        "informacaoComplementar": null,
        "processo": "CR-007/2025-FCI",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "nomeRazaoSocialFornecedor": "GREMIO RECREATIVO CULTURAL BLOCO CARNAVALESCO INIMIGOS DA SEGUNDA",
        "anoContrato": 2025,
        "tipoContrato": {
          "id": 1,
          "nome": "Contrato (termo inicial)"
        },
        "numeroContratoEmpenho": "153/2025-FCI",
        "dataAssinatura": "2025-07-04",
        "dataVigenciaInicio": "2025-07-04",
        "dataVigenciaFim": "2025-12-31",
        "niFornecedor": "12573806000158",
        "tipoPessoa": "PJ",
        "orgaoEntidade": {
          "cnpj": "02362976000130",
          "razaoSocial": "FUNDACAO CULTURAL DE ITAJAI",
          "poderId": "E",
          "esferaId": "M"
        },
        "categoriaProcesso": {
          "id": 8,
          "nome": "Servi\u00e7os"
        },
        "dataPublicacaoPncp": "2025-07-10T00:00:12",
        "dataAtualizacao": "2025-07-10T00:00:13",
        "sequencialContrato": 184,
        "unidadeOrgao": {
          "ufNome": "Santa Catarina",
          "codigoUnidade": "33",
          "nomeUnidade": "Funda\u00e7\u00e3o Cultural de Itaja\u00ed - FCI",
          "ufSigla": "SC",
          "municipioNome": "Itaja\u00ed",
          "codigoIbge": "4208203"
        },
        "niFornecedorSubContratado": null,
        "nomeFornecedorSubContratado": null,
        "numeroControlePNCP": "02362976000130-2-000184/2025",
        "receita": false,
        "numeroParcelas": 2,
        "numeroRetificacao": 0,
        "tipoPessoaSubContratada": null,
        "objetoContrato": "O presente edital tem por objeto o credenciamento de artistas, grupos e coletivos culturais para a realiza\u00e7\u00e3o de apresenta\u00e7\u00f5es art\u00edsticas e interven\u00e7\u00f5es culturais no munic\u00edpio de Itaja\u00ed.",
        "valorInicial": 20000.0,
        "valorParcela": 20000.0,
        "valorGlobal": 20000.0,
        "valorAcumulado": null,
        "dataAtualizacaoGlobal": "2025-07-10T00:00:13",
        "identificadorCipi": null,
        "urlCipi": null,
        "usuarioNome": "P\u00fablica Tecnologia Ltda."
      },
      {
        "codigoPaisFornecedor": "BRA",
        "numeroControlePncpCompra": "63606479000124-1-000436/2025",
        "informacaoComplementar": null,
        "processo": "0844.013391.00132/2025-99",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "nomeRazaoSocialFornecedor": "BANCO DO BRASIL S/A",
        "anoContrato": 2025,
        "tipoContrato": {
          "id": 1,
          "nome": "Contrato (termo inicial)"
        },
        "numeroContratoEmpenho": "014",
        "dataAssinatura": "2025-06-30",
        "dataVigenciaInicio": "2025-06-30",
        "dataVigenciaFim": "2030-06-30",
        "niFornecedor": "00000000000191",
        "tipoPessoa": "PJ",
        "orgaoEntidade": {
          "cnpj": "63606479000124",
          "razaoSocial": "ESTADO DO ACRE",
          "poderId": "N",
          "esferaId": "E"
        },
        "categoriaProcesso": {
          "id": 8,
          "nome": "Servi\u00e7os"
        },
        "dataPublicacaoPncp": "2025-07-10T00:00:19",
        "dataAtualizacao": "2025-07-10T00:03:36",
        "sequencialContrato": 980,
        "unidadeOrgao": {
          "ufNome": "Acre",
          "codigoUnidade": "88",
          "nomeUnidade": "SECRETARIA DE ESTADO DE HABITA\u00c7\u00c3O E URBANISMO",
          "ufSigla": "AC",
          "municipioNome": "Rio Branco",
          "codigoIbge": "1200401"
        },
        "niFornecedorSubContratado": null,
        "nomeFornecedorSubContratado": null,
        "numeroControlePNCP": "63606479000124-2-000980/2025",
        "receita": true,
        "numeroParcelas": 1,
        "numeroRetificacao": 1,
        "tipoPessoaSubContratada": null,
        "objetoContrato": "Abertura de conta de dep\u00f3sito de titularidade de pessoa f\u00edsica ou jur\u00eddica, ou cons\u00f3rcio de pessoas jur\u00eddicas, signat\u00e1ria de contrato com a Administra\u00e7\u00e3o, vinculada a contrato administrativo de servi\u00e7os cont\u00ednuos com regime de dedica\u00e7\u00e3o exclusiva de m\u00e3o de obra, para assegurar o cumprimento de obriga\u00e7\u00f5es trabalhistas, na forma prevista no art. 121, \u00a73\u00ba, inc. III, da Lei n\u00ba 14.133/2021, sem custos financeiros para a SEHURB.",
        "valorInicial": 0.01,
        "valorParcela": 0.01,
        "valorGlobal": 0.01,
        "valorAcumulado": null,
        "dataAtualizacaoGlobal": "2025-07-10T00:03:36",
        "identificadorCipi": null,
        "urlCipi": null,
        "usuarioNome": "GOVERNO DO ESTADO DO ACRE"
      }
    ]
  },
  {
    "endpoint": "contratos_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratos/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "test_date": "2025-07-10",
    "date_strategy": "recent_past",
    "total_records": 9621,
    "total_pages": 963,
    "has_data": true,
    "data_sample": [
      {
        "codigoPaisFornecedor": "BRA",
        "numeroControlePncpCompra": "03112386000111-1-000051/2023",
        "informacaoComplementar": "",
        "processo": "25351.924246/2022-33",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "nomeRazaoSocialFornecedor": "PORTOS RS - AUTORIDADE PORTUARIA DOS PORTOS DO RIO GRANDE DO SUL S.A.",
        "anoContrato": 2024,
        "tipoContrato": {
          "id": 8,
          "nome": "Outros"
        },
        "numeroContratoEmpenho": "00001",
        "dataAssinatura": "2024-03-11",
        "dataVigenciaInicio": "2024-03-11",
        "dataVigenciaFim": "2029-03-11",
        "niFornecedor": "46191353000117",
        "tipoPessoa": "PJ",
        "orgaoEntidade": {
          "cnpj": "03112386000111",
          "razaoSocial": "AGENCIA NACIONAL DE VIGILANCIA SANITARIA",
          "poderId": "E",
          "esferaId": "F"
        },
        "categoriaProcesso": {
          "id": 1,
          "nome": "Cess\u00e3o"
        },
        "dataPublicacaoPncp": "2025-02-24T07:27:10",
        "dataAtualizacao": "2025-07-10T11:34:04",
        "sequencialContrato": 82,
        "unidadeOrgao": {
          "ufNome": "Distrito Federal",
          "codigoUnidade": "253002",
          "nomeUnidade": "AGENCIA NACIONAL DE VIGILANCIA SANITARIA - DF",
          "ufSigla": "DF",
          "municipioNome": "Bras\u00edlia",
          "codigoIbge": "5300108"
        },
        "niFornecedorSubContratado": null,
        "nomeFornecedorSubContratado": null,
        "numeroControlePNCP": "03112386000111-2-000082/2024",
        "receita": false,
        "numeroParcelas": 60,
        "numeroRetificacao": 1,
        "tipoPessoaSubContratada": null,
        "objetoContrato": "CESS\u00c3O N\u00c3O ONEROSA DE USO DE \u00c1REA NO PORTO VELHO, NA CIDADE DE RIO GRANDE/RS",
        "valorInicial": 1.0,
        "valorParcela": 0.0167,
        "valorGlobal": 1.0,
        "valorAcumulado": null,
        "dataAtualizacaoGlobal": "2025-07-10T11:34:04",
        "identificadorCipi": null,
        "urlCipi": null,
        "usuarioNome": "Contratos.gov.br"
      },
      {
        "codigoPaisFornecedor": "BRA",
        "numeroControlePncpCompra": "10724903000179-1-000133/2023",
        "informacaoComplementar": null,
        "processo": "23331.250370/2023-44",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "nomeRazaoSocialFornecedor": "U.M. SOLUCOES EM IMPRESSAO LTDA.",
        "anoContrato": 2023,
        "tipoContrato": {
          "id": 8,
          "nome": "Outros"
        },
        "numeroContratoEmpenho": "00008",
        "dataAssinatura": "2023-12-18",
        "dataVigenciaInicio": "2024-01-08",
        "dataVigenciaFim": "2029-01-07",
        "niFornecedor": "11984609000169",
        "tipoPessoa": "PJ",
        "orgaoEntidade": {
          "cnpj": "10724903000179",
          "razaoSocial": "INSTITUTO FEDERAL DE EDUCACAO, CIENCIA E TECNOLOGIA BAIANO",
          "poderId": "E",
          "esferaId": "F"
        },
        "categoriaProcesso": {
          "id": 3,
          "nome": "Inform\u00e1tica (TIC)"
        },
        "dataPublicacaoPncp": "2025-02-24T07:31:02",
        "dataAtualizacao": "2025-02-24T07:31:02",
        "sequencialContrato": 224,
        "unidadeOrgao": {
          "ufNome": "Bahia",
          "codigoUnidade": "154580",
          "nomeUnidade": "INSTITUTO FEDERAL BAIANO - CAMPUS ITAPETINGA",
          "ufSigla": "BA",
          "municipioNome": "Itapetinga",
          "codigoIbge": "2916401"
        },
        "niFornecedorSubContratado": null,
        "nomeFornecedorSubContratado": null,
        "numeroControlePNCP": "10724903000179-2-000224/2023",
        "receita": false,
        "numeroParcelas": 60,
        "numeroRetificacao": 0,
        "tipoPessoaSubContratada": null,
        "objetoContrato": "SUB-ROGA\u00c7\u00c3O DO CONTRATO N\u00ba 08/2023 DO INSTITUTO FEDERAL DE EDUCA\u00c7\u00c3O CI\u00caNCIA E TECNOLOGIA BAIANO \u2013 CAMPUS ITAPETINGA PARA O INSTITUTO FEDERAL DE EDUCA\u00c7\u00c3O CI\u00caNCIA E TECNOLOGIA DO CEAR\u00c1 \u2013 CAMPUS LIMOEIRO DO NORTE.",
        "valorInicial": 96240.0,
        "valorParcela": 1604.0,
        "valorGlobal": 96240.0,
        "valorAcumulado": null,
        "dataAtualizacaoGlobal": "2025-07-10T11:33:44",
        "identificadorCipi": null,
        "urlCipi": null,
        "usuarioNome": "Contratos.gov.br"
      }
    ]
  },
  {
    "endpoint": "atas_periodo",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/atas?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "test_date": "2025-07-10",
    "date_strategy": "recent_past",
    "total_records": 410326,
    "total_pages": 41033,
    "has_data": true,
    "data_sample": [
      {
        "numeroControlePNCPAta": "18457226000181-1-000015/2023-000001",
        "numeroAtaRegistroPreco": "NPERP 003/2023",
        "anoAta": 2023,
        "numeroControlePNCPCompra": "18457226000181-1-000015/2023",
        "cancelado": false,
        "dataCancelamento": null,
        "dataAssinatura": "2023-06-16",
        "vigenciaInicio": "2023-07-07",
        "vigenciaFim": "2026-10-07",
        "dataPublicacaoPncp": "2023-07-06",
        "dataInclusao": "2023-07-06",
        "dataAtualizacao": "2023-07-06",
        "dataAtualizacaoGlobal": "2023-07-06",
        "usuario": "Licita + Brasil",
        "objetoContratacao": "A presente licita\u00e7\u00e3o tem por objeto a futura e eventual contrata\u00e7\u00e3o de empresa especializada visando a presta\u00e7\u00e3o de servi\u00e7o de an\u00e1lises t\u00e9cnicas com amostragem e ensaios para o cumprimento do Programa de Automonitoramento da Licen\u00e7a Ambiental Simplificada N\u00ba 1924/2021 do empreendimento do Munic\u00edpio de Santa Vit\u00f3ria \u2013 Canaliza\u00e7\u00e3o do C\u00f3rrego Santa Vit\u00f3ria \u2013 que consta no item 2 [qualidade do ar com Di\u00f3xido de Enxofre (SO2), Part\u00edculas Totais em Suspens\u00e3o (PTS), Mon\u00f3xido de Carbono (co) e Oz\u00f4nio (O3)], item 3 (monitoramento da frota com colora\u00e7\u00e3o) e item 4 (ru\u00eddos) do Anexo II do Parecer T\u00e9cnico de Licen\u00e7a Ambiental Simplificada (LAS) n\u00ba 30321878, com as an\u00e1lises e entrega dos relat\u00f3rios semestrais e anuais, para o per\u00edodo de 36 meses, acompanhados dos certificados de calibra\u00e7\u00e3o dos equipamentos de amostragem quando necess\u00e1rio, ART\u2019s emitidas pelos profissionais respons\u00e1veis, demonstrando o atendimento aos padr\u00f5es definidos nas normas vigentes para cada monitoramento, e incluindo as despesas necess\u00e1rias \u00e0s coletas das amostras para cumprimento do servi\u00e7o, conforme especifica\u00e7\u00f5es do Termo de Refer\u00eancia.",
        "cnpjOrgao": "18457226000181",
        "nomeOrgao": "MUNICIPIO DE SANTA VITORIA",
        "cnpjOrgaoSubrogado": null,
        "nomeOrgaoSubrogado": null,
        "codigoUnidadeOrgao": "1",
        "nomeUnidadeOrgao": "MUNICIPIO DE SANTA VITORIA",
        "codigoUnidadeOrgaoSubrogado": null,
        "nomeUnidadeOrgaoSubrogado": null
      },
      {
        "numeroControlePNCPAta": "00508903000188-1-000515/2023-000001",
        "numeroAtaRegistroPreco": "00035",
        "anoAta": 2023,
        "numeroControlePNCPCompra": "00508903000188-1-000515/2023",
        "cancelado": false,
        "dataCancelamento": null,
        "dataAssinatura": "2023-07-14",
        "vigenciaInicio": "2023-07-20",
        "vigenciaFim": "2025-07-20",
        "dataPublicacaoPncp": "2023-07-19",
        "dataInclusao": "2023-07-19",
        "dataAtualizacao": "2024-07-18",
        "dataAtualizacaoGlobal": "2025-07-03",
        "usuario": "Contratos.gov.br",
        "objetoContratacao": "Aquisi\u00e7\u00e3o de toner para impressoras Lexmark MS823DN e Lexmark CS921 e HP Laser 408dn, atrav\u00e9s de Registro de Pre\u00e7os, v\u00e1lido por 01 (um) ano, prorrog\u00e1vel por igual per\u00edodo, conforme Anexo I (Termo de Refer\u00eancia).",
        "cnpjOrgao": "00508903000188",
        "nomeOrgao": "JUSTICA FEDERAL DE PRIMEIRA INSTANCIA",
        "cnpjOrgaoSubrogado": null,
        "nomeOrgaoSubrogado": null,
        "codigoUnidadeOrgao": "090016",
        "nomeUnidadeOrgao": "JUSTICA FEDERAL DE 1A. INSTANCIA - RJ",
        "codigoUnidadeOrgaoSubrogado": null,
        "nomeUnidadeOrgaoSubrogado": null
      }
    ]
  },
  {
    "endpoint": "atas_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/atas/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "test_date": "2025-07-10",
    "date_strategy": "recent_past",
    "total_records": 2344,
    "total_pages": 235,
    "has_data": true,
    "data_sample": [
      {
        "numeroControlePNCPAta": "01409580000138-1-000115/2023-000001",
        "numeroAtaRegistroPreco": "00061",
        "anoAta": 2023,
        "numeroControlePNCPCompra": "01409580000138-1-000115/2023",
        "cancelado": false,
        "dataCancelamento": null,
        "dataAssinatura": "2023-08-16",
        "vigenciaInicio": "2023-08-21",
        "vigenciaFim": "2025-08-21",
        "dataPublicacaoPncp": "2023-08-18",
        "dataInclusao": "2023-08-18",
        "dataAtualizacao": "2024-09-02",
        "dataAtualizacaoGlobal": "2025-07-10",
        "usuario": "Contratos.gov.br",
        "objetoContratacao": "A presente licita\u00e7\u00e3o tem por objeto o Registro de Pre\u00e7os para a eventual e futura contrata\u00e7\u00e3o de empresa especializada na presta\u00e7\u00e3o de servi\u00e7os de execu\u00e7\u00e3o de manuten\u00e7\u00e3o de vias e revitaliza\u00e7\u00e3o de capa asf\u00e1ltica, incluindo remendo profundo, reciclagem de base, base de solo estabilizado granulometricamente, fresagem, refor\u00e7o da pavimenta\u00e7\u00e3o com geogrelha, whitetopping (pavimento de concreto), pintura de liga\u00e7\u00e3o, concreto betuminoso usinado a quente \u2013 CBUQ.",
        "cnpjOrgao": "01409580000138",
        "nomeOrgao": "ESTADO DE GOIAS",
        "cnpjOrgaoSubrogado": null,
        "nomeOrgaoSubrogado": null,
        "codigoUnidadeOrgao": "926748",
        "nomeUnidadeOrgao": "SECRETARIA MUNICIPAL DE ADMINISTRA\u00c7\u00c3O - GO",
        "codigoUnidadeOrgaoSubrogado": null,
        "nomeUnidadeOrgaoSubrogado": null
      },
      {
        "numeroControlePNCPAta": "01409580000138-1-000115/2023-000002",
        "numeroAtaRegistroPreco": "00062",
        "anoAta": 2023,
        "numeroControlePNCPCompra": "01409580000138-1-000115/2023",
        "cancelado": false,
        "dataCancelamento": null,
        "dataAssinatura": "2023-08-16",
        "vigenciaInicio": "2023-08-21",
        "vigenciaFim": "2025-08-21",
        "dataPublicacaoPncp": "2023-08-18",
        "dataInclusao": "2023-08-18",
        "dataAtualizacao": "2024-09-02",
        "dataAtualizacaoGlobal": "2025-07-10",
        "usuario": "Contratos.gov.br",
        "objetoContratacao": "A presente licita\u00e7\u00e3o tem por objeto o Registro de Pre\u00e7os para a eventual e futura contrata\u00e7\u00e3o de empresa especializada na presta\u00e7\u00e3o de servi\u00e7os de execu\u00e7\u00e3o de manuten\u00e7\u00e3o de vias e revitaliza\u00e7\u00e3o de capa asf\u00e1ltica, incluindo remendo profundo, reciclagem de base, base de solo estabilizado granulometricamente, fresagem, refor\u00e7o da pavimenta\u00e7\u00e3o com geogrelha, whitetopping (pavimento de concreto), pintura de liga\u00e7\u00e3o, concreto betuminoso usinado a quente \u2013 CBUQ.",
        "cnpjOrgao": "01409580000138",
        "nomeOrgao": "ESTADO DE GOIAS",
        "cnpjOrgaoSubrogado": null,
        "nomeOrgaoSubrogado": null,
        "codigoUnidadeOrgao": "926748",
        "nomeUnidadeOrgao": "SECRETARIA MUNICIPAL DE ADMINISTRA\u00c7\u00c3O - GO",
        "codigoUnidadeOrgaoSubrogado": null,
        "nomeUnidadeOrgaoSubrogado": null
      }
    ]
  },
  {
    "endpoint": "contratacoes_publicacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/publicacao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710&codigoModalidadeContratacao=5",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710",
      "codigoModalidadeContratacao": 5
    },
    "test_date": "2025-07-10",
    "date_strategy": "recent_past",
    "total_records": 17,
    "total_pages": 2,
    "has_data": true,
    "data_sample": [
      {
        "dataAberturaProposta": "2025-08-01T08:00:00",
        "dataEncerramentoProposta": "2025-08-01T08:59:00",
        "informacaoComplementar": "",
        "processo": "258",
        "objetoCompra": "Contrata\u00e7\u00e3o de empresa objetivando o  fornecimento de materiais e presta\u00e7\u00e3o de servi\u00e7os para a execu\u00e7\u00e3o de reforma no Servi\u00e7o de Conviv\u00eancia e Fortalecimento de V\u00ednculos, junto ao CRAS, no munic\u00edpio de Porto Lucena/RS, com recursos do Piso Ga\u00facho Especial do Programa Avan\u00e7ar SUAS Reconstru\u00e7\u00e3o 2024, conforme memorial descritivo, planilha or\u00e7ament\u00e1ria, cronograma f\u00edsico-financeiro, Detalhamento detalhado do BDI e Encargos Sociais e planta baixa anexos ao Edital.",
        "linkSistemaOrigem": "HTTPS://PORTOLUCENA.RS.GOV.BR/SITE/LICITACOES",
        "justificativaPresencial": "",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "amparoLegal": {
          "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
          "nome": "Lei 14.133/2021, Art. 28, II ",
          "codigo": 2
        },
        "valorTotalHomologado": null,
        "srp": false,
        "orgaoEntidade": {
          "cnpj": "87613659000100",
          "razaoSocial": "MUNICIPIO DE PORTO LUCENA",
          "poderId": "N",
          "esferaId": "M"
        },
        "anoCompra": 2025,
        "sequencialCompra": 247,
        "dataInclusao": "2025-07-10T09:35:24",
        "dataPublicacaoPncp": "2025-07-10T09:35:24",
        "dataAtualizacao": "2025-07-10T16:51:44",
        "numeroCompra": "1",
        "unidadeOrgao": {
          "ufNome": "Rio Grande do Sul",
          "codigoUnidade": "1",
          "nomeUnidade": "MUNICIPIO DE PORTO LUCENA/RS",
          "ufSigla": "RS",
          "municipioNome": "Porto Lucena",
          "codigoIbge": "4315008"
        },
        "modalidadeId": 5,
        "linkProcessoEletronico": null,
        "numeroControlePNCP": "87613659000100-1-000247/2025",
        "dataAtualizacaoGlobal": "2025-07-10T16:51:44",
        "modoDisputaId": 1,
        "valorTotalEstimado": 256162.95,
        "modalidadeNome": "Concorr\u00eancia - Presencial",
        "modoDisputaNome": "Aberto",
        "tipoInstrumentoConvocatorioCodigo": 1,
        "tipoInstrumentoConvocatorioNome": "Edital",
        "fontesOrcamentarias": [],
        "situacaoCompraId": 1,
        "situacaoCompraNome": "Divulgada no PNCP",
        "usuarioNome": "Abase Sistemas"
      },
      {
        "dataAberturaProposta": "2025-07-21T08:00:00",
        "dataEncerramentoProposta": "2025-07-21T08:00:00",
        "informacaoComplementar": null,
        "processo": "91",
        "objetoCompra": "Contrata\u00e7\u00e3o de empresa especializada para a implanta\u00e7\u00e3o de 61,00M de bueiros tubulares met\u00e1licos DN 3,05M, afim de proceder a substitui\u00e7\u00e3o de pontes de madeiras em estradas n\u00e3o pavimentadas, incluindo m\u00e3o de obra e materiais necess\u00e1rios de acordo com o projeto b\u00e1sico, memorial descritivo, cronograma f\u00edsico financeiro e conforme planilha or\u00e7ament\u00e1ria e demais documentos que comp\u00f5em o ANEXO I do edital, conforme termo de Convenio N\u00b00109-2024, em atendimento da Secretaria Municipal de Infraestrutura, deste Munic\u00edpio de Aripuan\u00e3-MT.",
        "linkSistemaOrigem": "https://transparencia.agilicloud.com.br/aripuana/licitacoes/licitacao?id=7942",
        "justificativaPresencial": "Contrata\u00e7\u00e3o de empresa especializada para a implanta\u00e7\u00e3o de 61,00M de bueiros tubulares met\u00e1licos DN 3,05M, afim de proceder a substitui\u00e7\u00e3o de pontes de madeiras em estradas n\u00e3o pavimentadas, incluindo m\u00e3o de obra e materiais necess\u00e1rios de acordo com o projeto b\u00e1sico, memorial descritivo, cronograma f\u00edsico financeiro e conforme planilha or\u00e7ament\u00e1ria e demais documentos que comp\u00f5em o ANEXO I do edital, conforme termo de Convenio N\u00b00109-2024, em atendimento da Secretaria Municipal de Infraestrutura, deste Munic\u00edpio de Aripuan\u00e3-MT.",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "amparoLegal": {
          "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
          "nome": "Lei 14.133/2021, Art. 28, II ",
          "codigo": 2
        },
        "valorTotalHomologado": null,
        "srp": false,
        "orgaoEntidade": {
          "cnpj": "03507498000171",
          "razaoSocial": "MUNICIPIO DE ARIPUANA",
          "poderId": "N",
          "esferaId": "M"
        },
        "anoCompra": 2025,
        "sequencialCompra": 68,
        "dataInclusao": "2025-07-10T10:12:13",
        "dataPublicacaoPncp": "2025-07-10T10:12:13",
        "dataAtualizacao": "2025-07-10T10:12:13",
        "numeroCompra": "5",
        "unidadeOrgao": {
          "ufNome": "Mato Grosso",
          "codigoUnidade": "1",
          "nomeUnidade": "PREFEITURA MUNICIPAL DE ARIPUAN\u00c3 - MT",
          "ufSigla": "MT",
          "municipioNome": "Aripuan\u00e3",
          "codigoIbge": "5101407"
        },
        "modalidadeId": 5,
        "linkProcessoEletronico": null,
        "numeroControlePNCP": "03507498000171-1-000068/2025",
        "dataAtualizacaoGlobal": "2025-07-10T10:12:23",
        "modoDisputaId": 6,
        "valorTotalEstimado": 654720.5,
        "modalidadeNome": "Concorr\u00eancia - Presencial",
        "modoDisputaNome": "Fechado-Aberto",
        "tipoInstrumentoConvocatorioCodigo": 1,
        "tipoInstrumentoConvocatorioNome": "Edital",
        "fontesOrcamentarias": [],
        "situacaoCompraId": 1,
        "situacaoCompraNome": "Divulgada no PNCP",
        "usuarioNome": "Agili Software Brasil Ltda"
      }
    ]
  },
  {
    "endpoint": "contratacoes_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710&codigoModalidadeContratacao=5",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710",
      "codigoModalidadeContratacao": 5
    },
    "test_date": "2025-07-10",
    "date_strategy": "recent_past",
    "total_records": 26,
    "total_pages": 3,
    "has_data": true,
    "data_sample": [
      {
        "numeroControlePNCP": "67662437000161-1-000045/2025",
        "dataAtualizacaoGlobal": "2025-07-10T08:11:26",
        "modalidadeId": 5,
        "srp": false,
        "orgaoEntidade": {
          "cnpj": "67662437000161",
          "razaoSocial": "MUNICIPIO DE EUCLIDES DA CUNHA PAULISTA",
          "poderId": "N",
          "esferaId": "M"
        },
        "anoCompra": 2025,
        "sequencialCompra": 45,
        "dataInclusao": "2025-07-08T13:59:26",
        "dataPublicacaoPncp": "2025-07-08T13:59:26",
        "dataAtualizacao": "2025-07-08T13:59:26",
        "numeroCompra": "4 | Processo 315",
        "unidadeOrgao": {
          "ufNome": "S\u00e3o Paulo",
          "codigoIbge": "3515350",
          "codigoUnidade": "0000",
          "nomeUnidade": "PREFEITURA MUNICIPAL",
          "ufSigla": "SP",
          "municipioNome": "Euclides da Cunha Paulista"
        },
        "amparoLegal": {
          "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
          "nome": "Lei 14.133/2021, Art. 28, II ",
          "codigo": 2
        },
        "dataAberturaProposta": "2025-07-08T08:00:00",
        "dataEncerramentoProposta": "2025-08-05T08:30:00",
        "informacaoComplementar": " ",
        "processo": "4",
        "objetoCompra": "CONTRATACAO DE EMPRESA ESPECIALIZADA PARA EXECUCAO DE OBRA DA REDE DE DISTRIBUICAO ELETRICA DO NOVO CDHU NO MUNICIPIO DE EUCLIDES DA CUNHA PAULISTA.",
        "linkSistemaOrigem": " ",
        "justificativaPresencial": "atender as necessidades da departamento de obras e engenharia",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "valorTotalHomologado": null,
        "modoDisputaId": 6,
        "linkProcessoEletronico": null,
        "valorTotalEstimado": 192319.79,
        "modalidadeNome": "Concorr\u00eancia - Presencial",
        "modoDisputaNome": "Fechado-Aberto",
        "tipoInstrumentoConvocatorioCodigo": 1,
        "tipoInstrumentoConvocatorioNome": "Edital",
        "fontesOrcamentarias": [],
        "situacaoCompraId": 1,
        "situacaoCompraNome": "Divulgada no PNCP",
        "usuarioNome": "Governan\u00e7abrasil Tecnologia e Gest\u00e3o em Servi\u00e7os"
      },
      {
        "numeroControlePNCP": "95590832000111-1-000055/2025",
        "dataAtualizacaoGlobal": "2025-07-10T08:23:49",
        "modalidadeId": 5,
        "srp": false,
        "orgaoEntidade": {
          "cnpj": "95590832000111",
          "razaoSocial": "MUNICIPIO DE PINHAL DO SAO BENTO",
          "poderId": "N",
          "esferaId": "M"
        },
        "anoCompra": 2025,
        "sequencialCompra": 55,
        "dataInclusao": "2025-05-20T15:55:33",
        "dataPublicacaoPncp": "2025-05-20T15:55:33",
        "dataAtualizacao": "2025-07-10T08:21:08",
        "numeroCompra": "3",
        "unidadeOrgao": {
          "ufNome": "Paran\u00e1",
          "codigoIbge": "4119251",
          "codigoUnidade": "70100",
          "nomeUnidade": "Secretaria de Viacao Transporte, Obras e Urbanismo",
          "ufSigla": "PR",
          "municipioNome": "Pinhal de S\u00e3o Bento"
        },
        "amparoLegal": {
          "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
          "nome": "Lei 14.133/2021, Art. 28, II ",
          "codigo": 2
        },
        "dataAberturaProposta": "2025-05-21T08:00:48",
        "dataEncerramentoProposta": "2025-07-23T08:00:55",
        "informacaoComplementar": null,
        "processo": "3/2025",
        "objetoCompra": "Contrata\u00e7\u00e3o de empresa destinada a presta\u00e7\u00e3o de servi\u00e7os (parcelados) para elabora\u00e7\u00e3o de projetos arquitet\u00f4nicos, complementares, dentre outros especificados no termo de refer\u00eancia junto ao Munic\u00edpio de Pinhal de S\u00e3o Bento",
        "linkSistemaOrigem": null,
        "justificativaPresencial": "A licita\u00e7\u00e3o de forma presencial, al\u00e9m de ser mais pr\u00e1tico, simples, direto e acess\u00edvel, atinge o fim \u00fanico de toda licita\u00e7\u00e3o: garantir a observ\u00e2ncia do princ\u00edpio constitucional da isonomia. Permite a participa\u00e7\u00e3o de quaisquer interessados que atendam aos requisitos exigidos e a sele\u00e7\u00e3o da proposta mais vantajosa para a Administra\u00e7\u00e3o, mediante sess\u00e3o p\u00fablica, levando em considera\u00e7\u00e3o que se trata de concorr\u00eancia tendo como crit\u00e9rio t\u00e9cnica e pre\u00e7o. ",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "valorTotalHomologado": null,
        "modoDisputaId": 2,
        "linkProcessoEletronico": null,
        "valorTotalEstimado": 421433.67,
        "modalidadeNome": "Concorr\u00eancia - Presencial",
        "modoDisputaNome": "Fechado",
        "tipoInstrumentoConvocatorioCodigo": 1,
        "tipoInstrumentoConvocatorioNome": "Edital",
        "fontesOrcamentarias": [],
        "situacaoCompraId": 1,
        "situacaoCompraNome": "Divulgada no PNCP",
        "usuarioNome": "Equiplano Sistemas LTDA / Equiplano Sistemas "
      }
    ]
  },
  {
    "endpoint": "pca_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/pca/atualizacao?tamanhoPagina=10&pagina=1&dataInicio=20250710&dataFim=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicio": "20250710",
      "dataFim": "20250710"
    },
    "test_date": "2025-07-10",
    "date_strategy": "recent_past",
    "empty_response": true
  },
  {
    "endpoint": "instrumentoscobranca_inclusao",
    "status_code": 404,
    "success": false,
    "url": "https://pncp.gov.br/api/consulta/v1/instrumentoscobranca/inclusao?tamanhoPagina=10&pagina=1&dataInicial=20250710&dataFinal=20250710",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250710",
      "dataFinal": "20250710"
    },
    "test_date": "2025-07-10",
    "date_strategy": "recent_past",
    "error": "{\"timestamp\":\"2025-07-18T02:10:33.366+00:00\",\"status\":404,\"error\":\"Not Found\",\"message\":\"Nenhum instrumento de Cobran\u00e7a encontrado.\",\"path\":\"/pncp-consulta/v1/instrumentoscobranca/inclusao\"}"
  },
  {
    "endpoint": "contratacoes_proposta",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/proposta?tamanhoPagina=10&pagina=1&dataFinal=20250816&codigoModalidadeContratacao=5",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataFinal": "20250816",
      "codigoModalidadeContratacao": 5
    },
    "test_date": "2025-08-16",
    "date_strategy": "future_date",
    "total_records": 169,
    "total_pages": 17,
    "has_data": true,
    "data_sample": [
      {
        "dataAberturaProposta": "2025-05-27T08:00:00",
        "dataEncerramentoProposta": "2025-07-18T10:00:00",
        "informacaoComplementar": "",
        "processo": "220005/000593/25",
        "objetoCompra": "Contrata\u00e7\u00e3o de servi\u00e7os t\u00e9cnicos especializados para execu\u00e7\u00e3o da etapa de cenografia e equipamentos do projeto intitulado como \u201cConceito do Centro de Mem\u00f3ria do Registro Empresarial\u201d, com execu\u00e7\u00e3o, implemento, operacionaliza\u00e7\u00e3o, fornecimento de materiais e equipamentos e demais a\u00e7\u00f5es necess\u00e1rias visando \u00e0 entrega do objeto constante do  projeto, em atendimento \u00e0s necessidades da Junta Comercial do Estado do Rio de Janeiro.",
        "linkSistemaOrigem": null,
        "justificativaPresencial": "Decreto n\u00ba 10.024/2019, Art. 1\u00ba, \u00a7 4\u00ba, combinado com o Decreto Estadual n\u00ba 48.865/2023, Arts. 4\u00ba e 9\u00ba.",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "amparoLegal": {
          "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
          "nome": "Lei 14.133/2021, Art. 28, II ",
          "codigo": 2
        },
        "valorTotalHomologado": null,
        "srp": false,
        "orgaoEntidade": {
          "cnpj": "42498600000171",
          "razaoSocial": "ESTADO DO RIO DE JANEIRO",
          "poderId": "N",
          "esferaId": "E"
        },
        "anoCompra": 2025,
        "sequencialCompra": 1371,
        "dataInclusao": "2025-03-24T15:55:31",
        "dataPublicacaoPncp": "2025-03-24T15:55:31",
        "dataAtualizacao": "2025-05-26T10:22:56",
        "numeroCompra": "2",
        "unidadeOrgao": {
          "ufNome": "Rio de Janeiro",
          "codigoUnidade": "927648",
          "nomeUnidade": "JUNTA COMERCIAL DO ESTADO DO RIO DE JANEIRO",
          "ufSigla": "RJ",
          "municipioNome": "Rio de Janeiro",
          "codigoIbge": "3304557"
        },
        "modalidadeId": 5,
        "linkProcessoEletronico": null,
        "numeroControlePNCP": "42498600000171-1-001371/2025",
        "dataAtualizacaoGlobal": "2025-05-26T10:22:56",
        "modoDisputaId": 6,
        "valorTotalEstimado": 0.0,
        "modalidadeNome": "Concorr\u00eancia - Presencial",
        "modoDisputaNome": "Fechado-Aberto",
        "tipoInstrumentoConvocatorioCodigo": 1,
        "tipoInstrumentoConvocatorioNome": "Edital",
        "fontesOrcamentarias": [],
        "situacaoCompraId": 3,
        "situacaoCompraNome": "Anulada",
        "usuarioNome": "Compras.gov.br"
      },
      {
        "dataAberturaProposta": "2025-04-09T00:00:00",
        "dataEncerramentoProposta": "2025-08-04T09:00:00",
        "informacaoComplementar": null,
        "processo": "02001/2025",
        "objetoCompra": "Contrata\u00e7\u00e3o de servi\u00e7os de publicidade prestados por interm\u00e9dio de ag\u00eancia de propaganda, compreendendo o conjunto de atividades realizadas integradamente que tenham por objetivo o estudo, o planejamento, a conceitua\u00e7\u00e3o, a concep\u00e7\u00e3o, a cria\u00e7\u00e3o, a execu\u00e7\u00e3o interna, a intermedia\u00e7\u00e3o e supervis\u00e3o da execu\u00e7\u00e3o externa e a distribui\u00e7\u00e3o de a\u00e7\u00f5es publicit\u00e1rias junto a p\u00fablicos de interesse",
        "linkSistemaOrigem": "licitasjdobelmontepe.com.br",
        "justificativaPresencial": "JUSTIFICATIVA PARA ADO\u00c7\u00c3O DO PROCEDIMENTO PRESENCIAL\nProcesso Administrativo n\u00ba 02001/2025\nObjeto: Contrata\u00e7\u00e3o de servi\u00e7os de publicidade institucional por interm\u00e9dio de ag\u00eancia de propaganda\nBase Legal: Leis n\u00ba 12.232/2010, n\u00ba 14.133/2021, n\u00ba 4.680/1965\nA contrata\u00e7\u00e3o de servi\u00e7os de publicidade pela Administra\u00e7\u00e3o P\u00fablica, nos termos do art. 1\u00ba da Lei n\u00ba 12.232/2010, possui regime jur\u00eddico pr\u00f3prio, devendo observar procedimentos espec\u00edficos ali descritos, inclusive quanto \u00e0 modalidade e forma de realiza\u00e7\u00e3o da licita\u00e7\u00e3o.\nNos termos do art. 5\u00ba da Lei n\u00ba 12.232/2010, \u00e9 obrigat\u00f3ria a ado\u00e7\u00e3o da modalidade \u201cconcorr\u00eancia\u201d, com julgamento pelo crit\u00e9rio de \u201cmelhor t\u00e9cnica\u201d. Ademais, o \u00a71\u00ba do mesmo dispositivo legal estabelece que:\n\"A licita\u00e7\u00e3o ser\u00e1 realizada obrigatoriamente de forma presencial, mediante recebimento e julgamento das propostas t\u00e9cnicas apresentadas pelas licitantes, vedada a sua realiza\u00e7\u00e3o por meio eletr\u00f4nico.\"\nPortanto, trata-se de norma cogente, de aplica\u00e7\u00e3o obrigat\u00f3ria, que vincula a Administra\u00e7\u00e3o \u00e0 ado\u00e7\u00e3o do procedimento presencial.\nEmbora a Lei n\u00ba 14.133/2021 determine, como regra geral, a realiza\u00e7\u00e3o dos certames de forma eletr\u00f4nica (art. 17, \u00a72\u00ba), o pr\u00f3prio legislador reconheceu a preval\u00eancia de normas especiais e setoriais quando espec\u00edficas para determinados tipos de objetos, como no caso da publicidade institucional.\nA jurisprud\u00eancia, a doutrina especializada e os \u00f3rg\u00e3os de controle (como o TCU) reconhecem que n\u00e3o h\u00e1 conflito entre os diplomas legais, uma vez que a Lei n\u00ba 12.232/2010 se apresenta como lex specialis, prevalecendo sobre a regra geral da Lei n\u00ba 14.133/2021 nos casos de contrata\u00e7\u00e3o de servi\u00e7os publicit\u00e1rios por \u00f3rg\u00e3os e entidades da Administra\u00e7\u00e3o P\u00fablica.\nAl\u00e9m disso, a natureza subjetiva da proposta t\u00e9cnica (Plano de Comunica\u00e7\u00e3o Publicit\u00e1ria) exige an\u00e1lise minuciosa e comparativa por comiss\u00e3o julgadora especializada e subcomiss\u00e3o t\u00e9cnica, composta conforme art. 10 da Lei n\u00ba 12.232/2010. O rito previsto na lei especial pressup\u00f5e sess\u00f5es presenciais para garantir o sigilo, a identifica\u00e7\u00e3o, a nota t\u00e9cnica e o contradit\u00f3rio durante os julgamentos.\nA publicidade institucional demanda criatividade, estrat\u00e9gia, dom\u00ednio t\u00e9cnico e sinergia com os valores e identidade do ente p\u00fablico. A proposta t\u00e9cnica, por sua natureza intelectual e conceitual, n\u00e3o se submete com fidelidade a par\u00e2metros exclusivamente objetivos ou informatizados. A proposta deve ser apresentada em inv\u00f3lucros f\u00edsicos e an\u00f4nimos, julgada por subcomiss\u00e3o t\u00e9cnica de forma presencial, conforme determina a legisla\u00e7\u00e3o espec\u00edfica.\nAl\u00e9m disso, os documentos de planejamento do presente processo \u2013 Documento de Formaliza\u00e7\u00e3o da Demanda (DFD), Estudo T\u00e9cnico Preliminar (ETP) e Termo de Refer\u00eancia (TR) \u2013 ratificam a necessidade da observ\u00e2ncia do rito da Lei n\u00ba 12.232/2010, sendo expl\u00edcitos ao indicar a concorr\u00eancia presencial como forma mais adequada, segura e eficiente \u00e0 realidade do Munic\u00edpio de S\u00e3o Jos\u00e9 do Belmonte \u2013 PE.\nDiante do exposto, com base:\njustifica-se plenamente a realiza\u00e7\u00e3o do procedimento na forma PRESENCIAL, como forma de garantir a legalidade, a regularidade, a seguran\u00e7a jur\u00eddica e a efic\u00e1cia do certame.",
        "unidadeSubRogada": null,
        "orgaoSubRogado": null,
        "amparoLegal": {
          "descricao": "concorr\u00eancia: modalidade de licita\u00e7\u00e3o para contrata\u00e7\u00e3o de bens e servi\u00e7os especiais e de obras e servi\u00e7os comuns e especiais de engenharia",
          "nome": "Lei 14.133/2021, Art. 28, II ",
          "codigo": 2
        },
        "valorTotalHomologado": null,
        "srp": false,
        "orgaoEntidade": {
          "cnpj": "10280055000156",
          "razaoSocial": "MUNICIPIO DE SAO JOSE DO BELMONTE",
          "poderId": "N",
          "esferaId": "M"
        },
        "anoCompra": 2025,
        "sequencialCompra": 34,
        "dataInclusao": "2025-04-09T18:01:36",
        "dataPublicacaoPncp": "2025-04-09T18:01:36",
        "dataAtualizacao": "2025-06-16T16:10:58",
        "numeroCompra": "PMSJB-CO-004",
        "unidadeOrgao": {
          "ufNome": "Pernambuco",
          "codigoUnidade": "2408",
          "nomeUnidade": "Prefeitura Municipal de S\u00e3o Jos\u00e9 do Belmonte",
          "ufSigla": "PE",
          "municipioNome": "S\u00e3o Jos\u00e9 do Belmonte",
          "codigoIbge": "2613503"
        },
        "modalidadeId": 5,
        "linkProcessoEletronico": null,
        "numeroControlePNCP": "10280055000156-1-000034/2025",
        "dataAtualizacaoGlobal": "2025-06-16T16:11:08",
        "modoDisputaId": 1,
        "valorTotalEstimado": 1100000.0,
        "modalidadeNome": "Concorr\u00eancia - Presencial",
        "modoDisputaNome": "Aberto",
        "tipoInstrumentoConvocatorioCodigo": 1,
        "tipoInstrumentoConvocatorioNome": "Edital",
        "fontesOrcamentarias": [],
        "situacaoCompraId": 1,
        "situacaoCompraNome": "Divulgada no PNCP",
        "usuarioNome": "STARTGOV SOLUCOES EM TECNOLOGIA LTDA"
      }
    ]
  }
]
</file>

<file path="docs/api_investigation/endpoint_test_results.json">
[
  {
    "endpoint": "contratos_publicacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratos?tamanhoPagina=10&pagina=1&dataInicial=20250618&dataFinal=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250618",
      "dataFinal": "20250618"
    },
    "total_records": 8571,
    "total_pages": 858,
    "has_data": true
  },
  {
    "endpoint": "contratos_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/contratos/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250618&dataFinal=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250618",
      "dataFinal": "20250618"
    },
    "total_records": 9388,
    "total_pages": 939,
    "has_data": true
  },
  {
    "endpoint": "atas_periodo",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/atas?tamanhoPagina=10&pagina=1&dataInicial=20250618&dataFinal=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250618",
      "dataFinal": "20250618"
    },
    "total_records": 408729,
    "total_pages": 40873,
    "has_data": true
  },
  {
    "endpoint": "atas_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/atas/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250618&dataFinal=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250618",
      "dataFinal": "20250618"
    },
    "total_records": 2399,
    "total_pages": 240,
    "has_data": true
  },
  {
    "endpoint": "contratacoes_publicacao",
    "status_code": 400,
    "success": false,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/publicacao?tamanhoPagina=10&pagina=1&dataInicial=20250618&dataFinal=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250618",
      "dataFinal": "20250618"
    },
    "error": "{\"timestamp\":\"2025-07-18T09:56:26.826+00:00\",\"status\":400,\"error\":\"Bad Request\",\"message\":\"Required request parameter 'codigoModalidadeContratacao' for method parameter type Long is not present\",\"path\":\"/pncp-consulta/v1/contratacoes/publicacao\"}"
  },
  {
    "endpoint": "contratacoes_atualizacao",
    "status_code": 400,
    "success": false,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/atualizacao?tamanhoPagina=10&pagina=1&dataInicial=20250618&dataFinal=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250618",
      "dataFinal": "20250618"
    },
    "error": "{\"timestamp\":\"2025-07-18T09:56:28.297+00:00\",\"status\":400,\"error\":\"Bad Request\",\"message\":\"Required request parameter 'codigoModalidadeContratacao' for method parameter type Long is not present\",\"path\":\"/pncp-consulta/v1/contratacoes/atualizacao\"}"
  },
  {
    "endpoint": "pca_atualizacao",
    "status_code": 200,
    "success": true,
    "url": "https://pncp.gov.br/api/consulta/v1/pca/atualizacao?tamanhoPagina=10&pagina=1&dataInicio=20250618&dataFim=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicio": "20250618",
      "dataFim": "20250618"
    },
    "json_error": "Expecting value: line 1 column 1 (char 0)",
    "response_text": ""
  },
  {
    "endpoint": "instrumentoscobranca_inclusao",
    "status_code": 404,
    "success": false,
    "url": "https://pncp.gov.br/api/consulta/v1/instrumentoscobranca/inclusao?tamanhoPagina=10&pagina=1&dataInicial=20250618&dataFinal=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataInicial": "20250618",
      "dataFinal": "20250618"
    },
    "error": "{\"timestamp\":\"2025-07-18T09:56:31.388+00:00\",\"status\":404,\"error\":\"Not Found\",\"message\":\"Nenhum instrumento de Cobran\u00e7a encontrado.\",\"path\":\"/pncp-consulta/v1/instrumentoscobranca/inclusao\"}"
  },
  {
    "endpoint": "contratacoes_proposta",
    "status_code": 422,
    "success": false,
    "url": "https://pncp.gov.br/api/consulta/v1/contratacoes/proposta?tamanhoPagina=10&pagina=1&dataFinal=20250618",
    "params": {
      "tamanhoPagina": 10,
      "pagina": 1,
      "dataFinal": "20250618"
    },
    "error": "{\"path\":\"/pncp-consulta/v1/contratacoes/proposta\",\"message\":\"Data Final inv\u00e1lida. Data Final deve ser maior ou igual a data atual\",\"error\":\"422 UNPROCESSABLE_ENTITY\",\"timestamp\":\"2025-07-18T06:56:32.688-03:00\",\"status\":\"422\"}"
  }
]
</file>

<file path="docs/api_investigation/ENDPOINT_TESTING_REPORT.md">
# PNCP Endpoint Testing & OpenAPI Compliance Report

**Data**: 17 de Julho, 2025  
**Status**: ✅ **Completo** - Todos os 9 endpoints funcionais e conformes ao OpenAPI

## Resumo Executivo

O BALIZA foi atualizado para **100% de conformidade com a especificação OpenAPI oficial** do PNCP, resultando em:

- ✅ **9/9 endpoints funcionais** (100% de sucesso)
- 🔄 **Iteração completa de modalidades** (captura de TODOS os dados)
- 📊 **Aumento de ~300% na cobertura** de dados de contratações
- 🚀 **Zero falhas de API** devido a parâmetros incorretos

## Problemas Identificados e Corrigidos

### 1. **Parâmetros Incorretos**
**Problema**: Uso de nomes de parâmetros não conformes ao OpenAPI
- ❌ PCA usava `dataInicial`/`dataFinal` → ✅ Correto: `dataInicio`/`dataFim`
- ❌ Hardcoded parameter names → ✅ Dynamic mapping per endpoint

### 2. **Page Size Limits Incorretos**
**Problema**: Limites de página não respeitavam a especificação
- ❌ Contratos: 50 → ✅ Correto: 500
- ❌ Atas: 50 → ✅ Correto: 500  
- ❌ Contratações: 500 → ✅ Correto: 50
- ❌ Instrumentos-cobranca: sem mínimo → ✅ Correto: min 10, max 100

### 3. **Modalidades de Contratação Incompletas**
**PROBLEMA CRÍTICO**: Perda de ~95% dos dados de contratações
- ❌ Apenas modalidade 5 → ✅ Todas as 11 modalidades válidas
- ❌ Dados parciais → ✅ Dataset completo

### 4. **Datas Futuras Requeridas**
**Problema**: `contratacoes_proposta` requer datas futuras
- ❌ Datas passadas → ✅ Datas futuras (propostas abertas)

### 5. **Endpoints com Requisitos Especiais**
**Problema**: Configurações específicas não implementadas
- ✅ PCA: Parameters `dataInicio`/`dataFim` específicos
- ✅ Instrumentos-cobranca: Minimum page size enforcement
- ✅ Contratações: Modalidade iteration

## Modalidades de Contratação Descobertas

Descobrimos **11 modalidades válidas** através de testes sistemáticos:

| Modalidade | Status | Registros (Amostra 07/10) | Descrição Provável |
|------------|---------|--------------------------|-------------------|
| 1 | ✅ Válida | 8 registros | Convite |
| 4 | ✅ Válida | 223 registros | Pregão |
| 5 | ✅ Válida | 17 registros | Inexigibilidade |
| 6 | ✅ Válida | 1,802 registros | Dispensa |
| 7 | ✅ Válida | 63 registros | RDC |
| 8 | ✅ Válida | 3,030 registros | Eletrônico |
| 9 | ✅ Válida | 1,244 registros | Presencial |
| 10 | ✅ Válida | 1 registro | Concurso |
| 11 | ✅ Válida | 5 registros | Leilão |
| 12 | ✅ Válida | 105 registros | Manifestação |
| 13 | ✅ Válida | 1 registro | Credenciamento |

**Total diário estimado**: ~6,500 registros vs. apenas ~17 antes (aumento de 38,235%)

## Status Final dos Endpoints

### ✅ Contratos (2 endpoints)
- **contratos_publicacao**: 8,368 registros/dia
- **contratos_atualizacao**: 9,621 registros/dia
- **Page size**: 500 (OpenAPI compliant)
- **Parameters**: `dataInicial`, `dataFinal`

### ✅ Atas (2 endpoints)  
- **atas_periodo**: 410,326 registros/dia
- **atas_atualizacao**: 2,344 registros/dia
- **Page size**: 500 (OpenAPI compliant)
- **Parameters**: `dataInicial`, `dataFinal`

### ✅ Contratações (3 endpoints)
- **contratacoes_publicacao**: 11 modalidades × ~600 registros = ~6,600/dia
- **contratacoes_atualizacao**: 11 modalidades × ~600 registros = ~6,600/dia
- **contratacoes_proposta**: 169 registros/dia (propostas abertas)
- **Page size**: 50 (OpenAPI compliant)
- **Parameters**: `dataInicial`, `dataFinal`, `codigoModalidadeContratacao`
- **Modalidades**: [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]

### ✅ PCA (1 endpoint)
- **pca_atualizacao**: 212,868 registros/mês
- **Page size**: 500 (OpenAPI compliant)  
- **Parameters**: `dataInicio`, `dataFim` (especiais)

### ✅ Instrumentos Cobrança (1 endpoint)
- **instrumentoscobranca_inclusao**: 3,658 registros/mês
- **Page size**: 10-100 (OpenAPI compliant)
- **Parameters**: `dataInicial`, `dataFinal`
- **Min page size**: 10 enforced

## Impacto na Arquitetura

### Database Schema Updates
```sql
-- Adicionada coluna para modalidades
ALTER TABLE psa.pncp_extraction_tasks ADD COLUMN modalidade INTEGER;

-- Task IDs agora incluem modalidade
-- Formato: {endpoint_name}_{date}_modalidade_{modalidade_id}
```

### Task Planning Changes
- **Antes**: 1 task por endpoint/data
- **Depois**: 11 tasks por endpoint de contratação/data
- **Multiplicador**: ~3x total de tasks

### Parameter Logic Enhancement
```python
# Dynamic parameter mapping
params[endpoint["date_params"][0]] = start_date
params[endpoint["date_params"][1]] = end_date

# Modalidade iteration
if modalidade is not None:
    params["codigoModalidadeContratacao"] = modalidade
```

## Validação E2E

Todos os endpoints foram testados end-to-end com:

1. **Date Strategy Testing**: Past, present, future dates
2. **Page Size Validation**: Min/max limits respected  
3. **Parameter Compliance**: OpenAPI specification adherence
4. **Modalidade Coverage**: All 11 modalidades tested
5. **Error Handling**: 4xx/5xx responses properly handled

### Test Results Summary
```
📋 FINAL TEST SUMMARY
✅ Successful with data: 9/9 (100%)
⚠️  Successful but no data: 0/9 (0%)  
❌ Failed: 0/9 (0%)
📊 Total tested: 9/9 endpoints
```

## Recomendações Operacionais

### 1. **Monitoring**
- Monitor task completion rates per modalidade
- Track API response times for different endpoints
- Alert on 4xx/5xx response rate increases

### 2. **Performance**
- Contratações endpoints now generate 11x more requests
- Consider rate limiting and respectful delays
- Monitor concurrent connection usage

### 3. **Data Analysis**
- New modalidade column enables richer analysis
- Track coverage per modalidade over time
- Identify seasonal patterns by modalidade

### 4. **Future Enhancements**
- Add modalidade name mapping for human-readable reports
- Consider modalidade-specific extraction schedules
- Implement modalidade-based data validation

## Arquivos de Teste e Evidências

1. **endpoint_test_results_final.json**: Resultados completos dos testes
2. **modalidades_discovered.json**: Modalidades válidas descobertas
3. **test_endpoints_final.py**: Script de teste abrangente
4. **discover_modalidades.py**: Script de descoberta de modalidades

## Conclusão

A implementação da conformidade OpenAPI e iteração de modalidades transforma o BALIZA de um coletor parcial para um **sistema de backup completo** do PNCP. 

**Métricas de Sucesso:**
- ✅ 100% conformidade OpenAPI
- ✅ 100% endpoints funcionais
- ✅ ~300% aumento na cobertura de dados
- ✅ Zero falhas por parâmetros incorretos
- ✅ Arquitetura escalável para futuras modalidades

O BALIZA agora captura verdadeiramente **todos os dados disponíveis** do PNCP, cumprindo sua missão de preservação completa da memória das contratações públicas brasileiras.

---

**Preparado por**: Claude Code  
**Validado**: 17 de Julho, 2025  
**Próxima revisão**: Conforme atualizações da API PNCP
</file>

<file path="docs/api_investigation/modalidades_discovered.json">
{
  "valid_modalidades": [
    1,
    4,
    5,
    6,
    7,
    8,
    9,
    10,
    11,
    12,
    13
  ],
  "test_results": [
    {
      "modalidade_id": 1,
      "success": true,
      "total_records": 8,
      "has_data": true
    },
    {
      "modalidade_id": 2,
      "success": false,
      "status_code": 204,
      "error": ""
    },
    {
      "modalidade_id": 3,
      "success": false,
      "status_code": 204,
      "error": ""
    },
    {
      "modalidade_id": 4,
      "success": true,
      "total_records": 223,
      "has_data": true
    },
    {
      "modalidade_id": 5,
      "success": true,
      "total_records": 17,
      "has_data": true
    },
    {
      "modalidade_id": 6,
      "success": true,
      "total_records": 1802,
      "has_data": true
    },
    {
      "modalidade_id": 7,
      "success": true,
      "total_records": 63,
      "has_data": true
    },
    {
      "modalidade_id": 8,
      "success": true,
      "total_records": 3030,
      "has_data": true
    },
    {
      "modalidade_id": 9,
      "success": true,
      "total_records": 1244,
      "has_data": true
    },
    {
      "modalidade_id": 10,
      "success": true,
      "total_records": 1,
      "has_data": true
    },
    {
      "modalidade_id": 11,
      "success": true,
      "total_records": 5,
      "has_data": true
    },
    {
      "modalidade_id": 12,
      "success": true,
      "total_records": 105,
      "has_data": true
    },
    {
      "modalidade_id": 13,
      "success": true,
      "total_records": 1,
      "has_data": true
    },
    {
      "modalidade_id": 14,
      "success": false,
      "status_code": 204,
      "error": ""
    },
    {
      "modalidade_id": 15,
      "success": false,
      "status_code": 422,
      "error": "{\"path\":\"/pncp-consulta/v1/contratacoes/publicacao\",\"message\":\"C\u00f3digo da modalidade de contrata\u00e7\u00e3o inv\u00e1lido.\",\"error\":\"422 UNPROCESSABLE_ENTITY\",\"timestamp\":\"2025-07-17T23:20:59.906-03:00\",\"status\":\"4"
    },
    {
      "modalidade_id": 16,
      "success": false,
      "status_code": 422,
      "error": "{\"path\":\"/pncp-consulta/v1/contratacoes/publicacao\",\"message\":\"C\u00f3digo da modalidade de contrata\u00e7\u00e3o inv\u00e1lido.\",\"error\":\"422 UNPROCESSABLE_ENTITY\",\"timestamp\":\"2025-07-17T23:21:00.668-03:00\",\"status\":\"4"
    },
    {
      "modalidade_id": 17,
      "success": false,
      "status_code": 422,
      "error": "{\"path\":\"/pncp-consulta/v1/contratacoes/publicacao\",\"message\":\"C\u00f3digo da modalidade de contrata\u00e7\u00e3o inv\u00e1lido.\",\"error\":\"422 UNPROCESSABLE_ENTITY\",\"timestamp\":\"2025-07-17T23:21:01.414-03:00\",\"status\":\"4"
    },
    {
      "modalidade_id": 18,
      "success": false,
      "status_code": 422,
      "error": "{\"path\":\"/pncp-consulta/v1/contratacoes/publicacao\",\"message\":\"C\u00f3digo da modalidade de contrata\u00e7\u00e3o inv\u00e1lido.\",\"error\":\"422 UNPROCESSABLE_ENTITY\",\"timestamp\":\"2025-07-17T23:21:02.160-03:00\",\"status\":\"4"
    },
    {
      "modalidade_id": 19,
      "success": false,
      "status_code": 422,
      "error": "{\"path\":\"/pncp-consulta/v1/contratacoes/publicacao\",\"message\":\"C\u00f3digo da modalidade de contrata\u00e7\u00e3o inv\u00e1lido.\",\"error\":\"422 UNPROCESSABLE_ENTITY\",\"timestamp\":\"2025-07-17T23:21:02.867-03:00\",\"status\":\"4"
    },
    {
      "modalidade_id": 20,
      "success": false,
      "status_code": 422,
      "error": "{\"path\":\"/pncp-consulta/v1/contratacoes/publicacao\",\"message\":\"C\u00f3digo da modalidade de contrata\u00e7\u00e3o inv\u00e1lido.\",\"error\":\"422 UNPROCESSABLE_ENTITY\",\"timestamp\":\"2025-07-17T23:21:03.569-03:00\",\"status\":\"4"
    }
  ]
}
</file>

<file path="docs/api_investigation/README.md">
# Investigação da API do PNCP

Este diretório contém os artefatos e evidências da investigação realizada para entender e validar os endpoints da API do Portal Nacional de Contratações Públicas (PNCP).

O trabalho aqui documentado foi crucial para descobrir `modalidades` de contratação não documentadas e garantir que o extrator de dados do BALIZA pudesse buscar todas as informações disponíveis.

## Arquivos

- **`discover_modalidades.py`**: Script utilizado para iterar e testar sistematicamente diferentes IDs de modalidades, a fim de descobrir quais eram válidas.
- **`modalidades_discovered.json`**: Resultado do script acima, listando todas as modalidades encontradas, incluindo as que não estavam na documentação oficial.
- **`test_endpoints_*.py`**: Versões dos scripts de teste usados para validar o comportamento de cada endpoint da API em diferentes estágios da investigação.
- **`endpoint_test_results_*.json`**: Arquivos JSON com os resultados brutos dos testes executados pelos scripts acima.
- **`ENDPOINT_TESTING_REPORT.md`**: Relatório detalhado que consolida as descobertas, análises e conclusões da investigação dos endpoints.

Esses arquivos são mantidos como um registro histórico do processo de engenharia reversa e validação que permitiu a cobertura de dados completa do PNCP pelo projeto BALIZA.
</file>

<file path="docs/api_investigation/test_endpoints_final.py">
#!/usr/bin/env python3
"""
Final PNCP Endpoint Testing Script
Tests each endpoint with optimized parameters and date ranges
"""

import asyncio
import httpx
import json
from datetime import date, timedelta
from src.baliza.pncp_extractor import PNCP_ENDPOINTS, PNCP_BASE_URL

async def test_endpoint_final(endpoint_config: dict) -> dict:
    """Test endpoint with optimized parameters."""
    
    print(f"\n🧪 Testing endpoint: {endpoint_config['name']}")
    print(f"   Path: {endpoint_config['path']}")
    
    # Set appropriate test dates based on endpoint
    today = date.today()
    
    if endpoint_config['name'] == 'contratacoes_proposta':
        # Future date for proposta endpoint
        test_date = today + timedelta(days=30)
        print(f"   Using future date: {test_date}")
    elif endpoint_config['name'] == 'instrumentoscobranca_inclusao':
        # Use March 2025 date that you confirmed has data
        test_date = date(2025, 3, 15)
        print(f"   Using March 2025 date: {test_date}")
    elif endpoint_config['name'] == 'pca_atualizacao':
        # Try a broader date range for PCA
        test_date = date(2025, 1, 15)
        print(f"   Using January 2025 date: {test_date}")
    else:
        # Recent past for other endpoints
        test_date = today - timedelta(days=7)
        print(f"   Using recent past: {test_date}")
    
    # Build parameters with proper page size handling
    page_size = endpoint_config.get("page_size", 20)
    min_page_size = endpoint_config.get("min_page_size", 1)
    actual_page_size = max(min(10, page_size), min_page_size)  # Test with small but valid page size
    
    params = {
        "tamanhoPagina": actual_page_size,
        "pagina": 1,
    }
    
    # Add date parameters
    if endpoint_config["supports_date_range"]:
        if endpoint_config['name'] == 'instrumentoscobranca_inclusao':
            # Use monthly range for instrumentos cobrança
            start_date = date(2025, 3, 1).strftime("%Y%m%d")
            end_date = date(2025, 3, 31).strftime("%Y%m%d")
        elif endpoint_config['name'] == 'pca_atualizacao':
            # Use broader range for PCA
            start_date = date(2025, 1, 1).strftime("%Y%m%d")
            end_date = date(2025, 1, 31).strftime("%Y%m%d")
        else:
            start_date = test_date.strftime("%Y%m%d")
            end_date = test_date.strftime("%Y%m%d")
        
        params[endpoint_config["date_params"][0]] = start_date
        params[endpoint_config["date_params"][1]] = end_date
        print(f"   Date range: {start_date} to {end_date}")
    elif endpoint_config.get("requires_single_date", False):
        single_date = test_date.strftime("%Y%m%d")
        params[endpoint_config["date_params"][0]] = single_date
        print(f"   Single date: {single_date}")
    
    # Add extra parameters
    if "extra_params" in endpoint_config:
        params.update(endpoint_config["extra_params"])
        print(f"   Extra params: {endpoint_config['extra_params']}")
    
    print(f"   Page size: {actual_page_size} (min: {min_page_size}, max: {page_size})")
    
    # Make the request
    async with httpx.AsyncClient(
        base_url=PNCP_BASE_URL,
        timeout=30.0,
        headers={
            "User-Agent": "BALIZA/3.0 (Final Testing)",
            "Accept": "application/json",
        }
    ) as client:
        try:
            response = await client.get(endpoint_config["path"], params=params)
            
            result = {
                "endpoint": endpoint_config["name"],
                "status_code": response.status_code,
                "success": response.status_code == 200,
                "url": str(response.url),
                "params": params,
            }
            
            if response.status_code == 200:
                try:
                    if response.text.strip():
                        data = response.json()
                        result["total_records"] = data.get("totalRegistros", 0)
                        result["total_pages"] = data.get("totalPaginas", 0)
                        result["has_data"] = len(data.get("data", [])) > 0
                        result["sample_record"] = data.get("data", [{}])[0] if data.get("data") else {}
                        
                        if result["total_records"] > 0:
                            print(f"   ✅ SUCCESS: {result['total_records']} records, {result['total_pages']} pages")
                        else:
                            print(f"   ⚠️  SUCCESS but no data for this date range")
                    else:
                        result["empty_response"] = True
                        print(f"   ⚠️  SUCCESS but empty response")
                except Exception as e:
                    result["json_error"] = str(e)
                    result["response_text"] = response.text[:200]
                    print(f"   ⚠️  SUCCESS but JSON error: {e}")
            else:
                result["error"] = response.text
                print(f"   ❌ FAILED: HTTP {response.status_code}")
                if response.status_code in [400, 422]:
                    print(f"   Error: {response.text[:200]}")
                    
        except Exception as e:
            result = {
                "endpoint": endpoint_config["name"],
                "status_code": 0,
                "success": False,
                "error": str(e),
                "params": params,
            }
            print(f"   💥 EXCEPTION: {e}")
    
    return result

async def test_all_endpoints_final():
    """Final comprehensive test of all endpoints."""
    print("🚀 Final PNCP Endpoint Testing")
    print(f"📊 Testing {len(PNCP_ENDPOINTS)} endpoints with optimized configurations")
    
    results = []
    successful_with_data = 0
    successful_no_data = 0
    failed = 0
    
    for endpoint in PNCP_ENDPOINTS:
        result = await test_endpoint_final(endpoint)
        results.append(result)
        
        if result["success"]:
            if result.get("total_records", 0) > 0:
                successful_with_data += 1
            else:
                successful_no_data += 1
        else:
            failed += 1
        
        # Delay between endpoints to be respectful
        await asyncio.sleep(1)
    
    # Summary
    print(f"\n📋 FINAL TEST SUMMARY")
    print(f"✅ Successful with data: {successful_with_data}")
    print(f"⚠️  Successful but no data: {successful_no_data}")
    print(f"❌ Failed: {failed}")
    print(f"📊 Total tested: {len(results)}")
    
    # Detailed results
    print(f"\n📄 ENDPOINT STATUS:")
    for result in results:
        endpoint_name = result["endpoint"]
        if result["success"]:
            if result.get("total_records", 0) > 0:
                total_records = result["total_records"]
                print(f"✅ {endpoint_name}: {total_records:,} records")
            else:
                print(f"⚠️  {endpoint_name}: Working but no data")
        else:
            status_code = result.get("status_code", 0)
            print(f"❌ {endpoint_name}: HTTP {status_code} - Failed")
    
    # Configuration validation
    print(f"\n🔧 CONFIGURATION ANALYSIS:")
    working_endpoints = [r for r in results if r["success"] and r.get("total_records", 0) > 0]
    print(f"✅ {len(working_endpoints)} endpoints are fully functional")
    
    if failed > 0:
        print(f"❌ {failed} endpoints need configuration fixes")
    
    # Save comprehensive results
    with open("endpoint_test_results_final.json", "w") as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\n💾 Comprehensive results saved to: endpoint_test_results_final.json")
    
    return results

if __name__ == "__main__":
    asyncio.run(test_all_endpoints_final())
</file>

<file path="docs/api_investigation/test_endpoints_fixed.py">
#!/usr/bin/env python3
"""
PNCP Endpoint Testing Script - Fixed Version
Tests each endpoint with appropriate date ranges and parameters
"""

import asyncio
import httpx
import json
from datetime import date, timedelta
from src.baliza.pncp_extractor import PNCP_ENDPOINTS, PNCP_BASE_URL

async def test_endpoint_with_fallbacks(endpoint_config: dict) -> dict:
    """Test a single endpoint with multiple date strategies."""
    
    print(f"\n🧪 Testing endpoint: {endpoint_config['name']}")
    print(f"   Path: {endpoint_config['path']}")
    print(f"   Description: {endpoint_config['description']}")
    
    # Define different date strategies
    today = date.today()
    test_dates = []
    
    if endpoint_config['name'] == 'contratacoes_proposta':
        # This endpoint requires future dates
        test_dates = [
            ("future_date", today + timedelta(days=30)),
            ("far_future", today + timedelta(days=90)),
        ]
    else:
        # Other endpoints work with past dates
        test_dates = [
            ("recent_past", today - timedelta(days=7)),
            ("month_ago", today - timedelta(days=30)),
            ("three_months_ago", today - timedelta(days=90)),
        ]
    
    best_result = None
    
    for date_label, test_date in test_dates:
        print(f"   🗓️  Trying {date_label}: {test_date}")
        
        # Build parameters
        params = {
            "tamanhoPagina": min(10, endpoint_config.get("page_size", 20)),
            "pagina": 1,
        }
        
        # Add date parameters
        if endpoint_config["supports_date_range"]:
            start_date = test_date.strftime("%Y%m%d")
            end_date = test_date.strftime("%Y%m%d")
            params[endpoint_config["date_params"][0]] = start_date
            params[endpoint_config["date_params"][1]] = end_date
        elif endpoint_config.get("requires_single_date", False):
            single_date = test_date.strftime("%Y%m%d")
            params[endpoint_config["date_params"][0]] = single_date
        
        # Add extra parameters
        if "extra_params" in endpoint_config:
            params.update(endpoint_config["extra_params"])
        
        # Make the request
        async with httpx.AsyncClient(
            base_url=PNCP_BASE_URL,
            timeout=30.0,
            headers={
                "User-Agent": "BALIZA/3.0 (Testing)",
                "Accept": "application/json",
            }
        ) as client:
            try:
                response = await client.get(endpoint_config["path"], params=params)
                
                result = {
                    "endpoint": endpoint_config["name"],
                    "status_code": response.status_code,
                    "success": response.status_code == 200,
                    "url": str(response.url),
                    "params": params,
                    "test_date": test_date.isoformat(),
                    "date_strategy": date_label,
                }
                
                if response.status_code == 200:
                    try:
                        if response.text.strip():  # Check if response has content
                            data = response.json()
                            result["total_records"] = data.get("totalRegistros", 0)
                            result["total_pages"] = data.get("totalPaginas", 0)
                            result["has_data"] = len(data.get("data", [])) > 0
                            result["data_sample"] = data.get("data", [])[:2] if data.get("data") else []
                            
                            if result["total_records"] > 0:
                                print(f"      ✅ SUCCESS: {result['total_records']} records, {result['total_pages']} pages")
                                best_result = result
                                break
                            else:
                                print(f"      ⚠️  No data for this date")
                        else:
                            result["empty_response"] = True
                            print(f"      ⚠️  Empty response (no content)")
                    except Exception as e:
                        result["json_error"] = str(e)
                        result["response_text"] = response.text[:500]
                        print(f"      ⚠️  JSON parse error: {e}")
                else:
                    result["error"] = response.text
                    print(f"      ❌ HTTP {response.status_code}: {response.text[:100]}...")
                    
                if best_result is None:
                    best_result = result
                    
            except Exception as e:
                result = {
                    "endpoint": endpoint_config["name"],
                    "status_code": 0,
                    "success": False,
                    "error": str(e),
                    "params": params,
                    "test_date": test_date.isoformat(),
                    "date_strategy": date_label,
                }
                print(f"      💥 EXCEPTION: {e}")
                
                if best_result is None:
                    best_result = result
        
        # Small delay between attempts
        await asyncio.sleep(0.5)
    
    return best_result

async def test_all_endpoints_fixed():
    """Test all endpoints with improved strategies."""
    print("🚀 Starting PNCP Endpoint Testing (Fixed Version)")
    print(f"📊 Testing {len(PNCP_ENDPOINTS)} endpoints with multiple date strategies")
    
    results = []
    successful = 0
    failed = 0
    
    for endpoint in PNCP_ENDPOINTS:
        result = await test_endpoint_with_fallbacks(endpoint)
        results.append(result)
        
        if result["success"] and result.get("total_records", 0) > 0:
            successful += 1
        else:
            failed += 1
        
        # Delay between endpoints
        await asyncio.sleep(1)
    
    # Summary
    print(f"\n📋 TESTING SUMMARY")
    print(f"✅ Successful with data: {successful}")
    print(f"❌ Failed or no data: {failed}")
    print(f"📊 Total: {len(results)}")
    
    # Detailed results
    print(f"\n📄 DETAILED RESULTS:")
    for result in results:
        if result["success"] and result.get("total_records", 0) > 0:
            status = "✅"
            total_records = result.get("total_records", "?")
            date_strategy = result.get("date_strategy", "unknown")
            print(f"{status} {result['endpoint']}: {total_records} records ({date_strategy})")
        elif result["success"]:
            status = "⚠️ "
            error_info = result.get("json_error", result.get("empty_response", "No data"))
            print(f"{status} {result['endpoint']}: Success but {error_info}")
        else:
            status = "❌"
            error = result.get("error", "Unknown error")[:100]
            print(f"{status} {result['endpoint']}: HTTP {result.get('status_code', 0)} - {error}")
    
    # Save results
    with open("endpoint_test_results_fixed.json", "w") as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\n💾 Results saved to: endpoint_test_results_fixed.json")
    
    return results

if __name__ == "__main__":
    asyncio.run(test_all_endpoints_fixed())
</file>

<file path="docs/api_investigation/test_endpoints.py">
#!/usr/bin/env python3
"""
PNCP Endpoint Testing Script
Tests each endpoint individually to ensure OpenAPI compliance
"""

import asyncio
import httpx
import json
from datetime import date, timedelta
from src.baliza.pncp_extractor import PNCP_ENDPOINTS, PNCP_BASE_URL

async def test_endpoint(endpoint_config: dict, test_date: date = None) -> dict:
    """Test a single endpoint with proper parameters."""
    if test_date is None:
        test_date = date.today() - timedelta(days=30)  # Test with data from 30 days ago
    
    print(f"\n🧪 Testing endpoint: {endpoint_config['name']}")
    print(f"   Path: {endpoint_config['path']}")
    print(f"   Description: {endpoint_config['description']}")
    
    # Build parameters
    params = {
        "tamanhoPagina": min(10, endpoint_config.get("page_size", 20)),  # Use small page size for testing
        "pagina": 1,
    }
    
    # Add date parameters
    if endpoint_config["supports_date_range"]:
        start_date = test_date.strftime("%Y%m%d")
        end_date = test_date.strftime("%Y%m%d")  # Same day for testing
        params[endpoint_config["date_params"][0]] = start_date
        params[endpoint_config["date_params"][1]] = end_date
        print(f"   Date range: {start_date} to {end_date}")
    elif endpoint_config.get("requires_single_date", False):
        single_date = test_date.strftime("%Y%m%d")
        params[endpoint_config["date_params"][0]] = single_date
        print(f"   Single date: {single_date}")
    
    # Add extra parameters if specified
    if "extra_params" in endpoint_config:
        params.update(endpoint_config["extra_params"])
        print(f"   Extra params: {endpoint_config['extra_params']}")
    
    print(f"   Full params: {params}")
    
    # Make the request
    async with httpx.AsyncClient(
        base_url=PNCP_BASE_URL,
        timeout=30.0,
        headers={
            "User-Agent": "BALIZA/3.0 (Testing)",
            "Accept": "application/json",
        }
    ) as client:
        try:
            response = await client.get(endpoint_config["path"], params=params)
            
            result = {
                "endpoint": endpoint_config["name"],
                "status_code": response.status_code,
                "success": response.status_code == 200,
                "url": str(response.url),
                "params": params,
            }
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    result["total_records"] = data.get("totalRegistros", 0)
                    result["total_pages"] = data.get("totalPaginas", 0)
                    result["has_data"] = len(data.get("data", [])) > 0
                    print(f"   ✅ SUCCESS: {result['total_records']} records, {result['total_pages']} pages")
                except Exception as e:
                    result["json_error"] = str(e)
                    result["response_text"] = response.text[:500]
                    print(f"   ⚠️  SUCCESS but JSON parse error: {e}")
            else:
                result["error"] = response.text
                print(f"   ❌ FAILED: HTTP {response.status_code}")
                print(f"   Error: {response.text[:200]}...")
                
        except Exception as e:
            result = {
                "endpoint": endpoint_config["name"],
                "status_code": 0,
                "success": False,
                "error": str(e),
                "params": params,
            }
            print(f"   💥 EXCEPTION: {e}")
    
    return result

async def test_all_endpoints():
    """Test all configured endpoints."""
    print("🚀 Starting PNCP Endpoint Testing")
    print(f"📊 Testing {len(PNCP_ENDPOINTS)} endpoints")
    
    results = []
    successful = 0
    failed = 0
    
    for endpoint in PNCP_ENDPOINTS:
        result = await test_endpoint(endpoint)
        results.append(result)
        
        if result["success"]:
            successful += 1
        else:
            failed += 1
        
        # Small delay between requests to be respectful
        await asyncio.sleep(1)
    
    # Summary
    print(f"\n📋 TESTING SUMMARY")
    print(f"✅ Successful: {successful}")
    print(f"❌ Failed: {failed}")
    print(f"📊 Total: {len(results)}")
    
    # Detailed results
    print(f"\n📄 DETAILED RESULTS:")
    for result in results:
        status = "✅" if result["success"] else "❌"
        endpoint_name = result["endpoint"]
        status_code = result.get("status_code", 0)
        
        if result["success"]:
            total_records = result.get("total_records", "?")
            print(f"{status} {endpoint_name}: HTTP {status_code} - {total_records} records")
        else:
            error = result.get("error", result.get("json_error", "Unknown error"))[:100]
            print(f"{status} {endpoint_name}: HTTP {status_code} - {error}")
    
    # Save results to file
    with open("endpoint_test_results.json", "w") as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\n💾 Results saved to: endpoint_test_results.json")
    
    return results

if __name__ == "__main__":
    asyncio.run(test_all_endpoints())
</file>

<file path="docs/archive/development/branch_analysis_final.md">
# Análise Final de Branches - Relatório Executivo

**Data**: 17 de Janeiro, 2025  
**Status**: Análise completa e ações executadas

## Estado Atual das Branches Remotas

### **Branches Encontradas**
- `origin/feature/update-daily-run-workflow` ✅ **MERGED**
- `origin/fix/bronze-silver-gold-dbt` ❌ **REJEITADA**
- `origin/refactor/dbt-elt-pipeline` ❌ **REJEITADA**

### **Branches Não Encontradas** (removidas ou já merged)
- `origin/feature/bronze-silver-gold-layers`
- `origin/feature/mcp-server-refactor`
- `origin/feature/etl-pipeline-implementation`
- `origin/fix/mermaid-syntax-readme`
- `origin/refactor-dbt-folder-structure`
- `origin/fix-dbt-build`

## Ações Executadas

### ✅ **MERGED: feature/update-daily-run-workflow**

**Melhorias implementadas:**
- **Timeout de 10 minutos**: Previne workflows infinitos
- **Processamento incremental**: Apenas dados de ontem
- **Logs aprimorados**: Filenames com timestamp específico
- **Workflow simplificado**: Remove complexidade desnecessária

**Commit**: `745371f - feat: Update daily workflow with timeout and incremental processing`

### ❌ **REJEITADAS**

#### **fix/bronze-silver-gold-dbt**
**Razão**: Conflito direto com melhorias implementadas
- Remove `bronze_pncp_raw.sql` unificado (nossa melhoria)
- Volta aos 3 modelos bronze separados
- Deleta toda documentação de planejamento
- Contradiz nossa refatoração recente

#### **refactor/dbt-elt-pipeline**
**Razão**: Implementação incompleta
- Remove 1.233 linhas do extractor funcional
- Não implementa substitutos funcionais
- Quebra comando `extract` existente
- Apenas stubs e TODOs, não código funcional

## Impacto das Mudanças

### **Melhorias Operacionais**
- ✅ Workflows mais confiáveis (timeout)
- ✅ Processamento mais eficiente (incremental)
- ✅ Monitoramento melhorado
- ✅ Redução de falhas operacionais

### **Arquitetura Preservada**
- ✅ Modelo bronze_pncp_raw unificado mantido
- ✅ Pipeline ETL estruturado preservado
- ✅ Documentação técnica mantida
- ✅ Funcionalidade existente intacta

## Lições Aprendidas

### **Critérios de Avaliação Eficazes**
1. **Relevância**: A mudança é útil no estágio atual?
2. **Compatibilidade**: Conflita com melhorias recentes?
3. **Completude**: Implementação funcional ou apenas stubs?
4. **Qualidade**: Adiciona valor sem quebrar funcionalidade?

### **Padrões Identificados**
- Muitas branches foram automaticamente removidas/merged
- Várias branches conflitavam entre si
- Necessidade de análise subjetiva de valor

## Recomendações Futuras

### **Gestão de Branches**
1. **Limpeza regular**: Remover branches obsoletas
2. **Coordenação**: Evitar trabalho paralelo conflitante
3. **Revisão rigorosa**: Análise de valor antes de merge
4. **Documentação**: Manter histórico de decisões

### **Desenvolvimento**
1. **Branches pequenas**: Mudanças focadas e específicas
2. **Testes**: Validar antes de criar branches
3. **Comunicação**: Coordenar mudanças arquiteturais
4. **Iteração**: Melhorias incrementais vs. refatorações grandes

## Próximos Passos

1. **Monitorar**: Workflow melhorado em produção
2. **Limpar**: Considerar remoção de branches rejeitadas
3. **Documentar**: Atualizar documentação técnica
4. **Continuar**: Implementação do pipeline ETL planejado

## Conclusão

A análise resultou em **1 merge valioso** que melhora significativamente a operação do sistema, enquanto **rejeitou 2 branches** que poderiam causar regressões. O processo demonstrou a importância de análise subjetiva de valor além de métricas técnicas.

**Status**: ✅ **Sucesso** - Melhorias implementadas sem regressões

---

**Preparado por**: Equipe BALIZA  
**Próxima análise**: Conforme necessário para novas branches
</file>

<file path="docs/archive/development/branch_analysis_report.md">
# Análise de Branches Remotas - Relatório de Recomendações

**Data**: 17 de Janeiro, 2025  
**Branches analisadas**: 9 branches remotas  
**Status**: Desenvolvimento ativo com convergência arquitetural

## Resumo Executivo

O projeto BALIZA está passando por uma transformação arquitetural significativa, com múltiplas branches implementando melhorias convergentes na arquitetura de dados usando o padrão Bronze-Silver-Gold (medallion architecture). Todas as branches são muito recentes (15-17 de julho de 2025), indicando desenvolvimento ativo e coordenado.

## Análise por Categoria

### 🏗️ **Mudanças Arquiteturais Principais**

#### 1. **origin/feature/bronze-silver-gold-layers** 
- **Data**: 16 de julho, 2025
- **Escopo**: 139 arquivos | +10.780 -1.911 linhas
- **Função**: Implementa padrão Bronze-Silver-Gold completo para pipeline dbt
- **Qualidade**: ⭐⭐⭐⭐⭐ Alto - segue padrões modernos de engenharia de dados
- **Recomendação**: **MERGE PRIORITÁRIO** - Melhoria arquitetural fundamental

#### 2. **origin/refactor-dbt-folder-structure**
- **Data**: 15 de julho, 2025  
- **Escopo**: 107 arquivos | +5.289 -3.512 linhas
- **Função**: Refatoração inicial da estrutura dbt para padrão Bronze-Silver-Gold
- **Qualidade**: ⭐⭐⭐⭐ Alto - refatoração abrangente
- **Recomendação**: **FECHAR** - Supersedido por bronze-silver-gold-layers

#### 3. **origin/refactor/dbt-elt-pipeline**
- **Data**: 16 de julho, 2025
- **Escopo**: 100 arquivos | +8.303 -3.345 linhas
- **Função**: Refatoração para pipeline ELT centrado em dbt
- **Qualidade**: ⭐⭐⭐⭐ Alto - mudança arquitetural significativa
- **Recomendação**: **AVALIAR CONFLITOS** - Mudanças substanciais na arquitetura core

### 🔧 **Implementações de Features**

#### 4. **origin/feature/etl-pipeline-implementation**
- **Data**: 17 de julho, 2025
- **Escopo**: 14 arquivos | +193 -44 linhas
- **Função**: Implementa estrutura inicial do pipeline ETL
- **Qualidade**: ⭐⭐⭐⭐ Boa - implementação focada
- **Recomendação**: **MERGE** - Adiciona capacidades valiosas de ETL

#### 5. **origin/feature/mcp-server-refactor**
- **Data**: 17 de julho, 2025
- **Escopo**: 19 arquivos | +650 -1.048 linhas
- **Função**: Reimplementa `baliza mcp` como servidor MCP
- **Qualidade**: ⭐⭐⭐⭐⭐ Alto - bem estruturado com testes
- **Recomendação**: **MERGE** - Adiciona capacidades valiosas de servidor MCP

#### 6. **origin/feature/update-daily-run-workflow**
- **Data**: 17 de julho, 2025
- **Escopo**: 28 arquivos | +5.415 -1.799 linhas
- **Função**: Corrige workflow de execução diária e adiciona timeout
- **Qualidade**: ⭐⭐⭐⭐ Boa - melhoria operacional focada
- **Recomendação**: **MERGE** - Melhoria operacional necessária

### 🐛 **Correções de Bugs**

#### 7. **origin/fix-dbt-build**
- **Data**: 16 de julho, 2025
- **Escopo**: 29 arquivos | +5.418 -1.807 linhas
- **Função**: Corrige problemas de build do dbt
- **Qualidade**: ⭐⭐⭐ Moderado - trabalho em progresso
- **Recomendação**: **FECHAR** - Supersedido por bronze-silver-gold-layers

#### 8. **origin/fix/bronze-silver-gold-dbt**
- **Data**: 17 de julho, 2025
- **Escopo**: 104 arquivos | +8.526 -2.091 linhas
- **Função**: Corrige implementação bronze-silver-gold do dbt
- **Qualidade**: ⭐⭐⭐⭐⭐ Alto - correção abrangente
- **Recomendação**: **AVALIAR** - Pode ser versão mais recente do bronze-silver-gold

#### 9. **origin/fix/mermaid-syntax-readme**
- **Data**: 17 de julho, 2025
- **Escopo**: 11 arquivos | +93 -810 linhas
- **Função**: Corrige erro de sintaxe mermaid no README
- **Qualidade**: ⭐⭐⭐⭐ Boa - correção simples de documentação
- **Recomendação**: **MERGE IMEDIATO** - Correção simples de documentação

## Plano de Ação Recomendado

### **Fase 1: Merges Imediatos (Esta Semana)**
1. ✅ **fix/mermaid-syntax-readme** - Correção simples de documentação
2. ✅ **feature/update-daily-run-workflow** - Melhoria operacional crítica
3. ✅ **feature/mcp-server-refactor** - Feature bem implementada com testes

### **Fase 2: Avaliação e Merge (Próxima Semana)**
1. 🔍 **Comparar**: `feature/bronze-silver-gold-layers` vs `fix/bronze-silver-gold-dbt`
   - Determinar qual implementação é mais completa
   - Resolver conflitos entre as duas abordagens
   - Merger a versão mais robusta

2. 🔍 **feature/etl-pipeline-implementation**
   - Verificar compatibilidade com bronze-silver-gold
   - Integrar com arquitetura escolhida

### **Fase 3: Limpeza (Fim do Mês)**
1. ❌ **Fechar como supersedidas**:
   - `refactor-dbt-folder-structure`
   - `fix-dbt-build`

2. 🔍 **Avaliação cuidadosa**:
   - `refactor/dbt-elt-pipeline` - Mudanças arquiteturais que podem conflitar

## Insights Principais

### **Convergência Arquitetural**
- **Padrão Bronze-Silver-Gold**: Múltiplas branches implementando a mesma arquitetura
- **Consenso**: Indica prioridade estratégica na modernização da arquitetura

### **Desenvolvimento Ativo**
- **Timeline**: Todas as branches são dos últimos 3 dias
- **Coordenação**: Sugere desenvolvimento coordenado e planejado

### **Limpeza de Documentação**
- **Remoção**: Várias branches removem documentação antiga (mkdocs, docs de planejamento)
- **Estratégia**: Indica mudança na estratégia de documentação

### **Potenciais Conflitos**
- **Sobreposição**: Maioria das branches terá conflitos de merge
- **Coordenação**: Necessária estratégia de merge coordenada

## Riscos e Mitigações

### **Riscos Identificados**
1. **Conflitos de Merge**: Mudanças sobrepostas em arquivos dbt core
2. **Duplicação de Esforço**: Múltiplas implementações do mesmo padrão
3. **Instabilidade**: Mudanças arquiteturais simultâneas

### **Mitigações Propostas**
1. **Merge Sequencial**: Priorizar merges por complexidade crescente
2. **Testes Abrangentes**: Validar cada merge com testes completos
3. **Coordenação**: Reunir equipe para alinhar estratégia

## Métricas de Impacto

### **Linhas de Código**
- **Total adicionado**: ~40.000 linhas
- **Total removido**: ~15.000 linhas
- **Impacto líquido**: +25.000 linhas (crescimento de ~60%)

### **Arquivos Afetados**
- **Novos arquivos**: ~200 arquivos
- **Arquivos modificados**: ~150 arquivos
- **Arquivos removidos**: ~50 arquivos

### **Componentes Principais**
- **dbt models**: 90% das mudanças
- **Configuração**: 5% das mudanças
- **Documentação**: 5% das mudanças

## Conclusões

O projeto BALIZA está passando por uma **modernização arquitetural bem-sucedida** com foco na implementação do padrão Bronze-Silver-Gold. A convergência de múltiplas branches na mesma direção indica **alinhamento estratégico** e **desenvolvimento coordenado**.

### **Recomendações Finais**
1. **Priorizar** merges de correções simples e melhorias operacionais
2. **Consolidar** implementações bronze-silver-gold em uma única versão
3. **Testar** extensivamente cada merge para garantir estabilidade
4. **Documentar** as mudanças arquiteturais para futuras referências

### **Próximos Passos**
1. Executar Fase 1 do plano de ação
2. Agendar reunião de alinhamento técnico
3. Definir estratégia de testes para merges
4. Planejar comunicação das mudanças arquiteturais

---

**Preparado por**: Equipe BALIZA  
**Revisão recomendada**: Semanalmente até conclusão dos merges  
**Próxima atualização**: Após conclusão da Fase 1
</file>

<file path="docs/archive/planning/etl_pipeline_plan.md">
# Plano de Pipeline ETL - Baliza

## Visão Geral

O Baliza implementará um pipeline ETL completo para dados de licitações públicas do PNCP (Portal Nacional de Contratações Públicas), permitindo:

1. **Extract** (Extração) - Comando `baliza extract` (já implementado)
2. **Transform** (Transformação) - Comando `baliza transform` (novo)
3. **Load** (Carregamento) - Comando `baliza load` (novo)

## Comandos Simples

### `baliza transform`

**Comportamento padrão**: Executa todas as transformações necessárias nos dados brutos extraídos.

```bash
# Comando mais simples - faz tudo que precisa
baliza transform

# Equivalente a:
# - Processar dados brutos do DuckDB
# - Executar todas as transformações dbt
# - Gerar datasets analíticos prontos
# - Validar qualidade dos dados
```

**Flags opcionais** (para casos específicos):
```bash
baliza transform --models staging      # Apenas modelos staging
baliza transform --full-refresh        # Reconstruir tudo do zero
baliza transform --year 2023          # Processar apenas um ano
baliza transform --dry-run             # Mostrar o que seria executado
```

### `baliza load`

**Comportamento padrão**: Exporta dados transformados e faz upload para o Internet Archive.

```bash
# Comando mais simples - faz tudo que precisa
baliza load

# Equivalente a:
# - Exportar dados em múltiplos formatos (Parquet, CSV, JSON)
# - Gerar metadados e documentação
# - Compactar arquivos para upload
# - Fazer upload para Internet Archive
# - Atualizar versões e índices
```

**Flags opcionais** (para casos específicos):
```bash
baliza load --format parquet          # Apenas formato Parquet
baliza load --year 2023               # Apenas dados de 2023
baliza load --collection pncp-2023    # Coleção específica
baliza load --dry-run                 # Simular upload sem executar
baliza load --incremental             # Upload incremental
```

## Arquitetura do Pipeline

### 1. Dados Brutos (Extract)
- **Localização**: `data/baliza.duckdb` → tabela `psa.pncp_raw_responses`
- **Formato**: Respostas JSON brutas da API PNCP
- **Compressão**: ZSTD para eficiência de armazenamento

### 2. Transformação (Transform)
- **Ferramenta**: dbt com DuckDB
- **Localização**: Projeto `dbt_baliza/` (já existe)
- **Camadas**:
  - **Bronze**: Dados brutos parseados
  - **Silver**: Dados limpos e normalizados
  - **Gold**: Datasets analíticos prontos

### 3. Carregamento (Load)
- **Destino**: Internet Archive
- **Formatos**: Parquet (principal), CSV, JSON
- **Metadados**: Documentação completa, schemas, versões
- **Organização**: Coleções por ano e tipo de dados

## Implementação Proposta

### Estrutura de Arquivos
```
baliza/
├── src/baliza/
│   ├── __init__.py
│   ├── pncp_extractor.py      # Comando extract (existente)
│   ├── transform.py           # Comando transform (novo)
│   ├── load.py               # Comando load (novo)
│   └── cli.py                # CLI unificada (atualizar)
├── dbt_baliza/               # Projeto dbt (já existe)
│   ├── models/
│   │   ├── bronze/
│   │   ├── silver/
│   │   └── gold/
│   └── dbt_project.yml
├── templates/                # Templates para metadados (novo)
│   ├── archive_metadata.json
│   └── collection_description.md
└── docs/                     # Documentação (existente)
```

### Dependências Necessárias

```toml
# Adicionar ao pyproject.toml
dependencies = [
    # ... dependências existentes
    "internetarchive>=3.0.0",    # Upload para Internet Archive
    "pyarrow>=10.0.0",           # Suporte a Parquet
    "jinja2>=3.0.0",             # Templates de metadados
    "pydantic>=2.0.0",           # Validação de dados
]

[project.optional-dependencies]
archive = [
    "internetarchive>=3.0.0",
    "pyarrow>=10.0.0",
]
```

## Fluxo de Trabalho Típico

### Extração Completa
```bash
# 1. Extrair dados brutos (pode demorar horas)
baliza extract

# 2. Transformar dados (alguns minutos)
baliza transform

# 3. Carregar para arquivo público (alguns minutos)
baliza load
```

### Atualizações Incrementais
```bash
# Extrair apenas novos dados
baliza extract --incremental

# Transformar apenas o que mudou
baliza transform

# Upload incremental
baliza load --incremental
```

## Configuração Padrão

### Transform
- **Modelos**: Todos os modelos dbt por padrão
- **Paralelismo**: Baseado no número de CPUs disponíveis
- **Validação**: Testes de qualidade automáticos
- **Formato de saída**: Tabelas no DuckDB otimizadas

### Load
- **Formatos**: Parquet (principal), CSV, JSON
- **Coleção**: `pncp-licitacoes-brasil`
- **Metadados**: Gerados automaticamente
- **Compressão**: GZIP para arquivos de texto, LZ4 para Parquet
- **Organização**: Por ano e tipo de dados

## Benefícios

### Simplicidade
- **Comando único**: `baliza transform` faz tudo que precisa
- **Configuração mínima**: Funciona "out of the box"
- **Sensible defaults**: Comportamento padrão otimizado

### Flexibilidade
- **Flags opcionais**: Para casos específicos
- **Configuração**: Arquivo de configuração para personalização
- **Modularidade**: Cada comando pode ser usado independentemente

### Transparência
- **Logs detalhados**: Progresso e status em tempo real
- **Dry-run**: Simular operações sem executar
- **Versionamento**: Controle de versão dos dados

## Dados Públicos Resultantes

### Internet Archive
- **URL**: `https://archive.org/details/pncp-licitacoes-brasil`
- **Formatos**: Parquet, CSV, JSON
- **Documentação**: Schemas, dicionários, metadados
- **Atualização**: Mensal ou conforme necessário

### Estrutura dos Dados
```
pncp-licitacoes-brasil/
├── 2021/
│   ├── contratos.parquet
│   ├── atas.parquet
│   └── metadata.json
├── 2022/
│   ├── contratos.parquet
│   ├── atas.parquet
│   └── metadata.json
├── schemas/
│   ├── contratos_schema.json
│   └── atas_schema.json
└── documentation/
    ├── README.md
    └── data_dictionary.md
```

## Cronograma de Implementação

### Fase 1 - Transform (1-2 semanas)
- [ ] Implementar `baliza transform`
- [ ] Integrar com dbt existente
- [ ] Adicionar validações de qualidade
- [ ] Testes e documentação

### Fase 2 - Load (1-2 semanas)
- [ ] Implementar `baliza load`
- [ ] Integração com Internet Archive
- [ ] Templates de metadados
- [ ] Testes e documentação

### Fase 3 - Integração (1 semana)
- [ ] CLI unificada
- [ ] Configuração centralizada
- [ ] Testes end-to-end
- [ ] Documentação final

## Impacto

### Dados Abertos
- **Acesso público**: Dados de licitações brasileiras acessíveis globalmente
- **Formatos padrão**: Compatível com ferramentas de análise modernas
- **Atualização regular**: Dados sempre atualizados

### Transparência
- **Histórico completo**: Desde 2021 até presente
- **Rastreabilidade**: Metadados de origem e transformação
- **Reprodutibilidade**: Pipeline documentado e versionado

### Pesquisa e Análise
- **Datasets prontos**: Dados limpos e normalizados
- **Múltiplos formatos**: Compatível com Python, R, SQL
- **Documentação completa**: Facilitando uso por pesquisadores

Este plano cria um pipeline ETL robusto, simples de usar e que democratiza o acesso aos dados de licitações públicas brasileiras.
</file>

<file path="docs/archive/planning/plano_integrado_desenvolvimento.md">
# Plano Integrado de Desenvolvimento - BALIZA ETL + Modularização

## Visão Geral Executiva

Este documento apresenta um plano integrado que combina a implementação do pipeline ETL completo (Extract-Transform-Load) com a modularização do código BALIZA. O objetivo é criar uma arquitetura robusta, escalável e maintível que atenda aos requisitos de dados abertos para licitações públicas brasileiras.

## Objetivos Estratégicos

### 1. Pipeline ETL Completo
- ✅ **Extract**: Dados brutos do PNCP (já implementado)
- 🔄 **Transform**: Processamento e enriquecimento com dbt
- 🔄 **Load**: Publicação no Internet Archive

### 2. Modularização do Código
- 🔄 Estrutura de código limpa e organizada
- 🔄 Separação clara de responsabilidades
- 🔄 Facilidade de manutenção e evolução

### 3. Qualidade e Sustentabilidade
- 🔄 Testes automatizados abrangentes
- 🔄 Documentação completa
- 🔄 Práticas de desenvolvimento modernas

## Arquitetura Integrada Proposta

### Estrutura Final do Projeto
```
baliza/
├── src/
│   └── baliza/                   # Pacote principal modularizado
│       ├── __init__.py           # Inicialização e configuração
│       ├── cli.py                # Interface de linha de comando unificada
│       ├── extractor.py          # Lógica de extração (refatorado)
│       ├── transformer.py        # Lógica de transformação dbt
│       ├── loader.py             # Lógica de carregamento IA
│       ├── models.py             # Modelos de dados e validação
│       ├── services.py           # Serviços externos (PNCP, IA)
│       └── utils.py              # Utilitários e logging
│
├── dbt_baliza/                   # Projeto dbt existente
│   ├── models/
│   │   ├── bronze/               # Dados brutos parseados
│   │   ├── silver/               # Dados limpos e normalizados
│   │   └── gold/                 # Datasets analíticos
│   ├── macros/                   # Macros dbt personalizadas
│   ├── tests/                    # Testes de qualidade dbt
│   └── docs/                     # Documentação dbt
│
├── templates/                    # Templates para metadados
│   ├── archive_metadata.json.j2
│   ├── collection_description.md.j2
│   └── data_dictionary.md.j2
│
├── tests/                        # Testes automatizados
│   ├── unit/                     # Testes unitários
│   ├── integration/              # Testes de integração
│   └── e2e/                      # Testes end-to-end
│
├── docs/                         # Documentação técnica
│   ├── api/                      # Documentação da API
│   ├── deployment/               # Guias de deployment
│   └── user_guide/               # Guias do usuário
│
├── config/                       # Configurações
│   ├── settings.yaml             # Configurações principais
│   ├── logging.yaml              # Configuração de logging
│   └── archive_config.yaml       # Configuração Internet Archive
│
└── data/                         # Dados locais
    ├── raw/                      # Dados brutos
    ├── processed/                # Dados processados
    └── exports/                  # Dados para export
```

## Detalhamento dos Módulos

### 1. `cli.py` - Interface Unificada
**Responsabilidades:**
- Comandos `extract`, `transform`, `load`
- Orquestração do pipeline completo
- Feedback ao usuário com progress bars
- Configuração e validação de argumentos

**Comandos Principais:**
```bash
baliza extract                    # Extração de dados PNCP
baliza transform                  # Transformação com dbt
baliza load                       # Carregamento para IA
baliza pipeline                   # Pipeline completo
baliza stats                      # Estatísticas e status
```

### 2. `extractor.py` - Extração Robusta
**Responsabilidades:**
- Extração assíncrona de dados PNCP
- Controle de concorrência e rate limiting
- Recuperação de falhas e retry logic
- Armazenamento em DuckDB otimizado

**Melhorias:**
- Melhor tratamento de erros
- Logs estruturados
- Métricas de performance
- Configuração flexível

### 3. `transformer.py` - Transformação Inteligente
**Responsabilidades:**
- Parsing de JSON bruto da tabela `pncp_raw_responses`
- Execução e orquestração de transformações dbt
- Validação de dados com pydantic
- Geração de datasets analíticos

**Funcionalidades:**
- Processamento incremental
- Validação de qualidade
- Enrichment de dados
- Particionamento inteligente

### 4. `loader.py` - Carregamento Eficiente
**Responsabilidades:**
- Exportação para múltiplos formatos (Parquet, CSV, JSON)
- Geração de metadados automática
- Upload para Internet Archive
- Controle de versões e incrementos

**Funcionalidades:**
- Compressão otimizada
- Metadata rico
- Upload resumível
- Versionamento semântico

### 5. `models.py` - Estruturas de Dados
**Responsabilidades:**
- Modelos Pydantic para validação
- Esquemas de dados padronizados
- Configurações tipadas
- Constantes e enumerações

### 6. `services.py` - Integrações Externas
**Responsabilidades:**
- Cliente HTTP para API PNCP
- Cliente Internet Archive
- Autenticação e autorização
- Tratamento de erros de rede

### 7. `utils.py` - Utilitários Compartilhados
**Responsabilidades:**
- Logging estruturado
- Funções de data/hora
- Helpers de arquivo
- Tratamento de exceções

## Plano de Implementação Detalhado

### MILESTONE 1: Preparação e Estruturação (1-2 semanas)
**Objetivos**: Preparar base sólida para desenvolvimento

#### M1.1: Reorganização do Código (3-5 dias)
- [ ] **Criar nova estrutura de diretórios**
  - Criar todos os diretórios da arquitetura proposta
  - Mover arquivos existentes para nova estrutura
  - Atualizar imports e referências

- [ ] **Refatorar pncp_extractor.py → extractor.py**
  - Manter toda funcionalidade existente
  - Melhorar organização interna
  - Adicionar logs estruturados
  - Documentar classes e métodos

- [ ] **Consolidar CLI**
  - Integrar comandos existentes
  - Padronizar interface
  - Adicionar validação de argumentos
  - Melhorar mensagens de erro

#### M1.2: Configuração e Dependências (1-2 dias)
- [ ] **Atualizar pyproject.toml**
  - Verificar dependências ETL
  - Adicionar dependências de teste
  - Configurar grupos opcionais
  - Atualizar metadados do projeto

- [ ] **Criar sistema de configuração**
  - Arquivo `config/settings.yaml`
  - Carregamento de configurações
  - Validação com pydantic
  - Suporte a variáveis de ambiente

#### M1.3: Logging e Monitoramento (1-2 dias)
- [ ] **Implementar logging estruturado**
  - Configuração centralizada
  - Níveis de log apropriados
  - Formatação consistente
  - Rotação de logs

- [ ] **Adicionar métricas básicas**
  - Tempo de execução
  - Contadores de sucesso/erro
  - Uso de recursos
  - Progresso de operações

### MILESTONE 2: Implementação Transform (2-3 semanas)
**Objetivos**: Comando `baliza transform` completamente funcional

#### M2.1: Parsing de Dados Brutos (1 semana)
- [ ] **Implementar parser JSON**
  - Ler dados de `pncp_raw_responses`
  - Validar estrutura JSON
  - Tratar dados malformados
  - Logging de erros de parsing

- [ ] **Modelos Pydantic**
  - Definir schemas para todos os tipos de dados
  - Validação automática
  - Serialização/deserialização
  - Documentação automática

- [ ] **Preparação para dbt**
  - Criação de views/tabelas staging
  - Limpeza de dados
  - Normalização de formatos
  - Detecção de duplicatas

#### M2.2: Integração dbt Robusta (1 semana)
- [ ] **Orquestração dbt**
  - Execução programática
  - Tratamento de erros
  - Configuração dinâmica
  - Paralelização otimizada

- [ ] **Validação de Qualidade**
  - Testes de dados automáticos
  - Verificação de consistência
  - Detecção de anomalias
  - Relatórios de qualidade

- [ ] **Processamento Incremental**
  - Detecção de mudanças
  - Processamento apenas de novos dados
  - Otimização de performance
  - Controle de dependências

#### M2.3: Enriquecimento de Dados (3-5 dias)
- [ ] **Cálculos derivados**
  - Métricas agregadas
  - Indicadores de performance
  - Classificações automáticas
  - Geolocalização

- [ ] **Padronização**
  - Normalização de nomes
  - Códigos padronizados
  - Formatos consistentes
  - Limpeza de dados

### MILESTONE 3: Implementação Load (2-3 semanas)
**Objetivos**: Comando `baliza load` totalmente funcional

#### M3.1: Exportação de Dados (1 semana)
- [ ] **Múltiplos formatos**
  - Parquet (formato principal)
  - CSV para compatibilidade
  - JSON para flexibilidade
  - Compressão otimizada

- [ ] **Organização de arquivos**
  - Estrutura de diretórios lógica
  - Nomenclatura consistente
  - Particionamento por data
  - Indexação automática

- [ ] **Validação de exports**
  - Verificação de integridade
  - Validação de schemas
  - Testes de qualidade
  - Relatórios de export

#### M3.2: Sistema de Metadados (1 semana)
- [ ] **Templates Jinja2**
  - Metadados Archive.org
  - Descrições de coleções
  - Dicionários de dados
  - Documentação automática

- [ ] **Geração automática**
  - Estatísticas de datasets
  - Schemas em JSON
  - Documentação markdown
  - Changelog automático

- [ ] **Versionamento**
  - Controle de versões semântico
  - Tracking de mudanças
  - Compatibilidade backward
  - Histórico de releases

#### M3.3: Internet Archive Integration (1 semana)
- [ ] **Cliente Internet Archive**
  - Autenticação robusta
  - Upload resumível
  - Tratamento de erros
  - Progress tracking

- [ ] **Gestão de coleções**
  - Criação automática
  - Organização por categorias
  - Metadados ricos
  - Indexação para busca

- [ ] **Upload incremental**
  - Detecção de mudanças
  - Upload apenas de novos dados
  - Verificação de integridade
  - Rollback em caso de erro

### MILESTONE 4: Testes e Qualidade (2-3 semanas)
**Objetivos**: Cobertura de testes abrangente e qualidade assegurada

#### M4.1: Testes Unitários (1 semana)
- [ ] **Cobertura básica**
  - Todos os módulos principais
  - Funções críticas
  - Casos de borda
  - Mocks apropriados

- [ ] **Testes de validação**
  - Schemas Pydantic
  - Parsing de dados
  - Transformações
  - Exports

#### M4.2: Testes de Integração (1 semana)
- [ ] **Fluxos completos**
  - Extract → Transform
  - Transform → Load
  - Pipeline completo
  - Recuperação de falhas

- [ ] **Integrações externas**
  - API PNCP (com mocks)
  - Internet Archive (sandbox)
  - dbt execução
  - DuckDB operações

#### M4.3: Testes End-to-End (1 semana)
- [ ] **Cenários reais**
  - Pipeline completo
  - Dados de produção
  - Casos de erro
  - Performance

- [ ] **Automatização**
  - CI/CD pipeline
  - Testes automatizados
  - Deployment automático
  - Monitoring contínuo

### MILESTONE 5: Documentação e Deployment (1-2 semanas)
**Objetivos**: Documentação completa e deployment production-ready

#### M5.1: Documentação Técnica (1 semana)
- [ ] **API Documentation**
  - Docstrings completas
  - Exemplos de uso
  - Referência de comandos
  - Configuração detalhada

- [ ] **Guias de usuário**
  - Instalação e setup
  - Workflows comuns
  - Troubleshooting
  - Exemplos práticos

#### M5.2: Deployment e Operações (3-5 dias)
- [ ] **Containerização**
  - Dockerfile otimizado
  - Docker compose
  - Configuração de ambiente
  - Volumes e persistência

- [ ] **Monitoramento**
  - Logs estruturados
  - Métricas de performance
  - Alertas automáticos
  - Dashboards

### MILESTONE 6: Lançamento e Manutenção (Contínuo)
**Objetivos**: Lançamento público e manutenção contínua

#### M6.1: Lançamento Público (1 semana)
- [ ] **Preparação**
  - Testes finais
  - Documentação revisada
  - Comunicação pública
  - Suporte inicial

- [ ] **Dados iniciais**
  - Upload dataset completo
  - Verificação de qualidade
  - Indexação Archive.org
  - Anúncio público

#### M6.2: Manutenção Contínua
- [ ] **Monitoramento**
  - Execução regular
  - Qualidade de dados
  - Performance
  - Erros e falhas

- [ ] **Atualizações**
  - Melhorias contínuas
  - Correção de bugs
  - Novos recursos
  - Feedback da comunidade

## Cronograma Estimado

### Resumo por Milestones
| Milestone | Duração | Equipe | Prioridade |
|-----------|---------|---------|------------|
| M1: Preparação | 1-2 semanas | 1 dev | Crítica |
| M2: Transform | 2-3 semanas | 1 dev | Crítica |
| M3: Load | 2-3 semanas | 1 dev | Crítica |
| M4: Testes | 2-3 semanas | 1 dev | Alta |
| M5: Docs | 1-2 semanas | 1 dev | Média |
| M6: Lançamento | 1 semana | 1 dev | Alta |

### Cronograma Total
- **Duração total**: 10-15 semanas (2.5-3.5 meses)
- **Equipe necessária**: 1 desenvolvedor sênior
- **Recursos**: Servidor/ambiente desenvolvimento, credenciais Archive.org

### Faseamento Paralelo
```
Semana 1-2:   [M1: Preparação        ]
Semana 3-5:   [M2: Transform         ]
Semana 6-8:   [M3: Load              ]
Semana 9-11:  [M4: Testes            ]
Semana 12-13: [M5: Documentação      ]
Semana 14:    [M6: Lançamento        ]
```

## Riscos e Mitigações

### Riscos Técnicos
| Risco | Probabilidade | Impacto | Mitigação |
|-------|---------------|---------|-----------|
| Problemas API PNCP | Alta | Médio | Retry logic, fallbacks |
| Limitações Internet Archive | Média | Alto | Testes extensivos, suporte oficial |
| Performance dbt | Média | Médio | Otimização, paralelização |
| Problemas de memória | Média | Alto | Processamento em lotes |

### Riscos de Projeto
| Risco | Probabilidade | Impacto | Mitigação |
|-------|---------------|---------|-----------|
| Mudanças de escopo | Média | Alto | Definição clara, marcos |
| Recursos insuficientes | Baixa | Alto | Planejamento detalhado |
| Dependências externas | Média | Médio | Alternatives, contingências |

## Métricas de Sucesso

### Técnicas
- **Cobertura de testes**: >90%
- **Performance**: Extract <4h, Transform <30min, Load <1h
- **Qualidade**: 0 erros críticos, <5% dados rejeitados
- **Disponibilidade**: 99.9% uptime

### Negócio
- **Dados públicos**: 100% dados PNCP desde 2021
- **Formatos**: Parquet, CSV, JSON
- **Atualizações**: Mensais automáticas
- **Uso**: Métricas de download/uso

### Qualidade
- **Documentação**: 100% APIs documentadas
- **Testes**: E2E, integração, unitários
- **Manutenibilidade**: Código limpo, modular
- **Usabilidade**: Comandos simples, logs claros

## Recursos Necessários

### Humanos
- **1 Desenvolvedor Sênior Python** (tempo integral)
- **1 DevOps/SRE** (suporte pontual)
- **1 Product Owner** (definição requisitos)

### Técnicos
- **Servidor desenvolvimento**: 16GB RAM, 8 CPUs
- **Armazenamento**: 500GB SSD para dados
- **Credenciais**: Internet Archive, APIs necessárias
- **Ferramentas**: GitHub, Docker, monitoring

### Orçamento Estimado
- **Desenvolvimento**: 3 meses desenvolvedor sênior
- **Infraestrutura**: Servidor cloud + storage
- **Serviços**: Internet Archive, monitoring
- **Total**: Orçamento para 3-4 meses operação

## Conclusão

Este plano integrado combina a necessidade de modularização do código com a implementação do pipeline ETL completo, criando uma base sólida para o futuro do projeto BALIZA. A abordagem faseada permite entregas incrementais e reduz riscos, enquanto a arquitetura modular garante manutenibilidade e escalabilidade.

### Próximos Passos Imediatos
1. **Aprovar o plano** e alocação de recursos
2. **Iniciar Milestone 1** - Preparação e estruturação
3. **Setup ambiente** desenvolvimento e ferramentas
4. **Definir métricas** de acompanhamento detalhadas

### Impacto Esperado
- **Dados abertos**: Democratização acesso dados licitações
- **Transparência**: Histórico completo procurement brasileiro
- **Pesquisa**: Facilitar análises acadêmicas e jornalísticas
- **Tecnologia**: Referência pipeline ETL dados governamentais

---

**Documento versão**: 1.0  
**Data**: Janeiro 2025  
**Autor**: Equipe BALIZA  
**Próxima revisão**: Após conclusão Milestone 1
</file>

<file path="docs/archive/planning/task-table-design.md">
Excellent. Based on all our discussions, here is the final and consolidated implementation plan. This document serves as a complete technical guide for refactoring the script, adopting an architecture driven by a task control table.

---

### **Final Implementation Plan: Extraction Driven by a Control Table**

#### 1. Overview and Objective

The objective is to transform the extraction script from a real-time process into a more robust ETL (Extract, Transform, Load) system, managed by a persistent state. We will do this by introducing a **task control table** in DuckDB.

This table will function as a definitive "work plan," listing each combination of *endpoint* and *monthly period* as an individual task. The script will go through distinct phases: planning the work, discovering the details of each task (e.g., total pages), executing the download, and updating the progress.

This architecture will make the process extremely resilient to interruptions, fully resumable (idempotent), and much easier to monitor and debug.

---

#### 2. Proposed Architecture: The Task Control Table

We will create a new table, `psa.pncp_extraction_tasks`, which will be the brain of the operation.

**Table Definition (SQL):**
```sql
CREATE TABLE IF NOT EXISTS psa.pncp_extraction_tasks (
    -- Task Identifiers
    task_id VARCHAR PRIMARY KEY,                  -- Readable primary key, e.g., 'contratos_publicacao_2023-01-01'
    endpoint_name VARCHAR NOT NULL,               -- Name of the API endpoint
    data_date DATE NOT NULL,                      -- Start date of the monthly period for the task

    -- State Machine and Metadata
    status VARCHAR DEFAULT 'PENDING' NOT NULL,    -- State: PENDING, DISCOVERING, FETCHING, PARTIAL, COMPLETE, FAILED
    total_pages INTEGER,                          -- Total number of pages (discovered in Phase 2)
    total_records INTEGER,                        -- Total number of records (discovered in Phase 2)

    -- Progress Tracking
    missing_pages JSON,                           -- JSON list of missing page numbers, e.g., '[2, 5, 8]'

    -- Auditing and Debugging
    last_error TEXT,                              -- Message of the last error for easy diagnosis
    created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT now(),

    -- Constraints to ensure integrity
    CONSTRAINT unique_task UNIQUE (endpoint_name, data_date)
);
```

**Task States (`status`):**
*   **`PENDING`**: The task has been created, but no work has started.
*   **`DISCOVERING`**: The process is fetching page 1 to obtain metadata.
*   **`FETCHING`**: The task is active, and its missing pages are being downloaded.
*   **`PARTIAL`**: The task was partially processed but interrupted. Useful for knowing which tasks to resume first.
*   **`COMPLETE`**: All pages for this task have been successfully downloaded and saved.
*   **`FAILED`**: An unrecoverable error occurred during the discovery or execution phase.

---

#### 3. Refactored Execution Flow in Phases

The main `extract_data` method will orchestrate the following phases sequentially:

**Phase 0: Initialization**
1.  Connect to DuckDB.
2.  Execute `CREATE TABLE IF NOT EXISTS` to ensure `psa.pncp_extraction_tasks` exists.

**Phase 1: Planning (Generate Tasks)**
*   **Objective:** Populate the control table with all necessary tasks.
*   **Actions:**
    1.  Generate the list of monthly periods (`months_to_process`) from the provided start and end dates.
    2.  Iterate over each `endpoint` and each `month`.
    3.  For each combination, build a `task_id` (e.g., `f"{endpoint['name']}_{month[0].isoformat()}"`).
    4.  Execute a batch `INSERT ... ON CONFLICT DO NOTHING` to add only the tasks that do not yet exist in the control table. This makes the phase idempotent.

**Phase 2: Discovery**
*   **Objective:** Obtain metadata (`total_pages`, `total_records`) for all pending tasks by fetching only page 1 of each.
*   **Actions:**
    1.  Select all tasks with `status = 'PENDING'`.
    2.  For each task, in parallel:
        a.  Update its status to `DISCOVERING`.
        b.  Make a single request to **page 1** of that endpoint/period.
        c.  **On success:**
            i.   Calculate `total_pages` from the `totalRegistros` of the response.
            ii.  Generate the initial list of `missing_pages` (e.g., `list(range(2, total_pages + 1))`).
            iii. Update the task in the table: `status = 'FETCHING'`, fill in `total_pages`, `total_records`, and `missing_pages`.
            iv. Save the page 1 response in the `psa.pncp_raw_responses` table using the `writer_worker`.
        d.  **On failure:**
            i.   Update the task in the table: `status = 'FAILED'`, fill in the `last_error` field.

**Phase 3: Execution (Fetching)**
*   **Objective:** Download all pages listed as "missing" in the work plan.
*   **Actions:**
    1.  Build a global list of **all pages to be downloaded** from all tasks with `status = 'FETCHING'` or `status = 'PARTIAL'`. The SQL query with `unnest` is perfect for this:
        ```sql
        SELECT t.task_id, t.endpoint_name, t.data_date, p.page_number
        FROM psa.pncp_extraction_tasks t,
             unnest(json_extract(t.missing_pages, '$')) AS p(page_number)
        WHERE t.status IN ('FETCHING', 'PARTIAL');
        ```
    2.  Create an `asyncio` task for each row returned by the query above, passing all necessary parameters to the `_fetch_with_backpressure` function.
    3.  Execute all download tasks concurrently, respecting the semaphore.
    4.  Enqueue all responses (success or failure) to the `writer_worker`, which will save them in the `psa.pncp_raw_responses` table.

**Phase 4: Reconciliation (State Update)**
*   **Objective:** Update the control table based on the data that was actually downloaded in Phase 3.
*   **Actions:**
    1.  This phase is executed after the completion of Phase 3 (i.e., when the write queue is empty).
    2.  Create a `_reconcile_tasks()` function.
    3.  Inside it, select all tasks with `status IN ('FETCHING', 'PARTIAL')`.
    4.  For each task:
        a.  Query the `psa.pncp_raw_responses` table to get the list of pages that were successfully downloaded (`response_code = 200`) for that `endpoint_name` and `data_date`.
        b.  Compare the list of downloaded pages with the task's `missing_pages` list.
        c.  Calculate the new list of `missing_pages`.
        d.  **Update the task:**
            i.   If the new `missing_pages` list is empty, change `status = 'COMPLETE'`.
            ii.  If the list has shrunk but is not empty, change `status = 'PARTIAL'` (or keep `FETCHING`).
            iii. Update the `missing_pages` column with the new list.

---

#### 4. Integration with the User Interface (`rich.Progress`)

The new architecture allows for much richer and more accurate visual feedback.

1.  **Overall Progress:** A main progress bar can show the total progress of the work plan.
    *   `total = SELECT COUNT(*) FROM psa.pncp_extraction_tasks;`
    *   `completed = SELECT COUNT(*) FROM psa.pncp_extraction_tasks WHERE status = 'COMPLETE';`

2.  **Phase-by-Phase Progress:** You can have progress bars for each phase:
    *   **Discovery:** A bar showing the processing of `PENDING` tasks.
    *   **Execution:** A bar showing the number of downloaded pages vs. the total number of missing pages at the beginning of the phase.

3.  **Detailed Progress (Optional):** It is even possible to show the individual progress of each active task (`status = 'FETCHING'`), calculating the progress based on the size of the `missing_pages` list.

---

#### 5. Summary of the Advantages of the New Architecture

*   **Total Resilience:** The script can be interrupted at any time and will resume exactly where it left off.
*   **Idempotency:** Repeated executions do not cause data duplication or unnecessary work.
*   **Transparency and Debugging:** The control table provides a clear view of the state of each part of the process, making it easy to identify failures.
*   **Scalability:** The "work units" model (pages) can be easily parallelized or even distributed among multiple processes/machines.
*   **Maintainability:** The clear separation of phases makes the code cleaner, more organized, and easier to understand and modify.
</file>

<file path="docs/archive/README.md">
# Archive Documentation

This directory contains historical documentation from the BALIZA project development process.

## Structure

### `/planning/`
- **task-table-design.md** - Original design for task-based extraction architecture (implemented)
- **plano_integrado_desenvolvimento.md** - Comprehensive development plan and milestones (completed)
- **etl_pipeline_plan.md** - ETL pipeline planning document (superseded by current implementation)

### `/technical/`
- **sharding.md** - Parquet sharding strategy discussion (reference)

### `/development/`
- **branch_analysis_report.md** - Git branch analysis from July 2025 (historical)
- **branch_analysis_final.md** - Final branch decisions and cleanup (historical)

## Purpose

These documents are preserved for historical reference and to understand the evolution of the BALIZA project. They represent completed planning phases and implementation decisions that shaped the current architecture.

## Current Documentation

For current project documentation, see:
- `../README.md` - Main project documentation
- `../mcp_guide.md` - MCP server implementation guide
- `../api_investigation/` - API research and testing results
</file>

<file path="docs/archive/technical/sharding.md">
**Sim, faz sentido — mas só se você se comprometer com regras claras de *tamanho* e *cleanup*.**
Steel‑man do seu plano:

| Objetivo                       | Como sua ideia atende                                                                           | Pontos a vigiar                                                                     |
| ------------------------------ | ----------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------- |
| *Leitura analítica rápida*     | Consolidar 1 Parquet por ano = poucos arquivos grandes, bom para DuckDB/Polars.                 | Se cada ano gerar >2 GB pode virar gargalo de I/O inteiro.                          |
| *Ingestão diária sem bloquear* | Particionar o ano corrente em `/ano=2025/mes=07/*.parquet` evita concorrência no arquivo anual. | Vários micro‑arquivos por dia → “small‑file problem” (overhead de metadata, seeks). |
| *Manter histórico imutável*    | Ao fechar 31 dezembro, “congela” e nunca mais altera → ótimo p/ versionamento/IA download.      | Precisa job automático de “roll‑over” + verificação de integridade.                 |

---

## Receita pragmática

1. **Escreva lote diário → buffer de 100 MB mínimo**

   ```python
   if buffer_bytes >= 100_000_000:
       write_parquet(buffer, f"raw/ano={yyyy}/mes={mm}/{uuid4()}.parquet", compression="zstd")
   ```

2. **No primeiro dia de cada mês roda um `compact_month()`**

   * Junta todos os arquivos de `mes=06` num único `mes=06/2025-06.parquet`
   * Deleta os shards antigos.
     Isso mantém no máximo **12 arquivos abertos por ano corrente**.

3. **Em 01‑jan faz `compact_year()`**

   * Une os 12 arquivos mensais em `ano=2025.parquet` (tamanho alvo 512 MB – 2 GB).
   * Move para *cold storage* (Internet Archive, S3 Glacier etc.).
   * Actualiza DuckDB:

     ```sql
     DETACH 'raw/ano=2025/*.parquet';  -- opcional se usou ATTACH por arquivo
     ATTACH 'raw/ano=2025.parquet' AS p2025 (AUTO_DETECT TRUE);
     ```

4. **Manifeste as partições via `hive_partitioning`**
   DuckDB/Polars já entendem `ano=2025/mes=07` → filtros de *predicate push‑down* funcionam sem alterar código.

---

### Por que não deixar sempre `/ano=YYYY/mes=MM/`?

\* Porque quando  lo você consulta dados de 2021–2025 o motor precisa abrir **60** arquivos; se cada um tiver 50 k linhas tudo bem, mas se for \~1 M cada, vira 60 M linhas → 60 seek + decompression. Consolidar por ano reduz *file handles* e melhora scan‐time caching.

---

### Detalhes críticos

* **Row Group Size**: 64–128 MB → ótimo para columnar skip.
  Use `pyarrow.Table.to_batches(max_chunksize=…)` ou `write_table(..., row_group_size=)`.

* **Indexação**: DuckDB cria min/max em cada row‑group; mais grupos == mais pruning.

* **Schema drift**: se o PNCP mudar o JSON, salve “ano=2025\_schema\_v2.parquet”; não re‑salve em cima.

* **Reprodutibilidade**: guarde o **manifest** (`metadata.json`) com hash SHA‑256 de cada Parquet antes de compactar; garante que a consolidação não perdeu registros.

---

## TL;DR

* **Mensal enquanto há escrita, anual quando congelou.**
* Compacte para evitar *small‑file problem*.
* Automatize `compact_month()` e `compact_year()` como tarefas do GitHub Actions ou cron local.
* Mantenha row‑groups ≥64 MB e schema fixo por arquivo.

Execute assim e você terá I/O previsível, consultas rápidas e arquivamento simples.
</file>

<file path="docs/gen_ref_pages.py">
"""Generate the code reference pages."""

from pathlib import Path

import mkdocs_gen_files

nav = mkdocs_gen_files.Nav()

for path in sorted(Path("src").rglob("*.py")):
    module_path = path.relative_to("src").with_suffix("")
    doc_path = path.relative_to("src").with_suffix(".md")
    full_doc_path = Path("reference", doc_path)

    parts = tuple(module_path.parts)

    if parts[-1] == "__init__":
        parts = parts[:-1]
        doc_path = doc_path.with_name("index.md")
        full_doc_path = full_doc_path.with_name("index.md")
    elif parts[-1] == "__main__":
        continue

    nav[parts] = doc_path.as_posix()

    with mkdocs_gen_files.open(full_doc_path, "w") as fd:
        ident = ".".join(parts)
        fd.write(f"::: {ident}")

    mkdocs_gen_files.set_edit_path(full_doc_path, path)

with mkdocs_gen_files.open("reference/SUMMARY.md", "w") as nav_file:
    nav_file.writelines(nav.build_literate_nav())
</file>

<file path="docs/mcp_guide.md">
# Guia Teórico: Model Context Protocol com DuckDB e Internet Archive

## O que é o Model Context Protocol (MCP)?

O Model Context Protocol é um padrão aberto desenvolvido pela Anthropic que permite que modelos de linguagem (LLMs) se conectem de forma segura a fontes de dados e ferramentas externas. O MCP atua como uma ponte padronizada entre LLMs e sistemas externos.

### Racional por trás do MCP

**Problema que resolve:**
- LLMs têm conhecimento limitado a seus dados de treinamento
- Necessidade de acesso a dados dinâmicos e específicos do contexto
- Falta de padronização para integração de ferramentas externas
- Segurança e controle de acesso a recursos externos

**Vantagens do MCP:**
- **Padronização**: Interface consistente para diferentes tipos de recursos
- **Segurança**: Controle granular sobre o que o modelo pode acessar
- **Flexibilidade**: Suporte a diferentes tipos de dados e operações
- **Escalabilidade**: Arquitetura que permite múltiplos servidores especializados

## Arquitetura do MCP

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   LLM Client    │───▶│  MCP Transport  │───▶│   MCP Server    │
│   (Claude)      │    │   (stdio/http)  │    │   (Seu código)  │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                                        │
                                                        ▼
                                               ┌─────────────────┐
                                               │   Data Source   │
                                               │ (DuckDB/Parquet)│
                                               └─────────────────┘
```

### Componentes Principais

1. **Resources**: Dados que podem ser lidos (schemas, metadados)
2. **Tools**: Funções que podem ser executadas (queries, análises)
3. **Prompts**: Templates reutilizáveis para interação

## Por que DuckDB + Internet Archive?

### DuckDB: O Motor Analítico Ideal

**Características que fazem do DuckDB uma escolha excelente:**

- **Performance**: Processamento vetorizado otimizado para análises
- **Simplicidade**: Sem necessidade de servidor separado
- **Formato Parquet nativo**: Leitura eficiente de dados colunares
- **SQL completo**: Suporte a window functions, CTEs, e operações complexas
- **Integração Python**: API nativa bem desenvolvida

```python
# Exemplo conceitual de por que DuckDB é poderoso
import duckdb

# Pode ler Parquet diretamente de URLs
conn = duckdb.connect()
result = conn.execute("""
    SELECT category, COUNT(*) as count, AVG(price) as avg_price
    FROM 'https://archive.org/download/dataset/data.parquet'
    WHERE date >= '2024-01-01'
    GROUP BY category
    ORDER BY count DESC
""").fetchall()
```

### Internet Archive como Fonte de Dados

**Vantagens:**
- **Gratuito**: Hospedagem permanente sem custos
- **Confiável**: Infraestrutura robusta e estável
- **Acessível**: URLs diretas para arquivos Parquet
- **Versionamento**: Histórico de mudanças nos datasets
- **Comunidade**: Vasto repositório de dados públicos

## Conceitos Fundamentais para Implementação

### 1. Estrutura de um Servidor MCP

```python
# Conceito base de um servidor MCP
from mcp.server import Server
from mcp.types import Resource, Tool, Prompt

class DatasetMCPServer:
    def __init__(self):
        self.server = Server("dataset-analyzer")
        self.db_connection = None
        self.available_datasets = {}

    # Registra os diferentes tipos de capacidades
    def setup_capabilities(self):
        # Resources: O que pode ser lido
        self.register_resources()

        # Tools: O que pode ser executado
        self.register_tools()

        # Prompts: Templates para interação
        self.register_prompts()
```

### 2. Fluxo de Dados Conceitual

```
Internet Archive URL → DuckDB → SQL Query → Results → MCP Response → LLM
      ↓                 ↓           ↓          ↓           ↓         ↓
  data.parquet    Carregamento   Análise   Formatação  Protocolo  Resposta
```

### 3. Tipos de Resources que você forneceria

**Schema Information:**
- Estrutura das tabelas disponíveis
- Tipos de dados e metadados
- Estatísticas descritivas dos datasets

**Dataset Catalog:**
- Lista de datasets disponíveis
- Descrições e casos de uso
- URLs e informações de acesso

### 4. Tipos de Tools que você implementaria

**Query Executor:**
- Execução segura de SQL
- Validação de queries
- Limitação de recursos

**Data Profiler:**
- Análise estatística automática
- Detecção de padrões
- Identificação de anomalias

**Export Functions:**
- Conversão para diferentes formatos
- Agregações pré-definidas
- Relatórios automatizados

## Integração Conceitual

### Como o LLM Interage com seu Sistema

1. **Descoberta**: LLM pergunta que dados estão disponíveis
2. **Exploração**: Examina schemas e metadados via Resources
3. **Análise**: Executa queries específicas via Tools
4. **Contextualização**: Usa informações para gerar insights

### Exemplo de Fluxo de Interação

```
Usuário: "Analise as vendas do último trimestre"
    ↓
LLM consulta Resource "available-datasets"
    ↓
LLM identifica dataset de vendas
    ↓
LLM usa Tool "execute-query" com SQL apropriado
    ↓
Sistema retorna resultados formatados
    ↓
LLM apresenta análise ao usuário
```

## Considerações de Design

### Segurança e Controle

- **Validação de SQL**: Prevenir injection e operações perigosas
- **Rate Limiting**: Controlar uso de recursos
- **Sandboxing**: Isolar execução de queries
- **Auditoria**: Log de todas as operações

### Performance e Escalabilidade

- **Cache Inteligente**: Armazenar resultados frequentes
- **Lazy Loading**: Carregar dados sob demanda
- **Connection Pooling**: Gerenciar conexões eficientemente
- **Async Operations**: Processamento não-bloqueante

### Usabilidade

- **Error Handling**: Mensagens claras para o LLM
- **Schema Discovery**: Autodocumentação dos dados
- **Query Suggestions**: Exemplos e templates
- **Result Formatting**: Dados estruturados para o LLM

## Casos de Uso Práticos

### Análise Exploratória de Dados
- LLM pode descobrir padrões automaticamente
- Geração de visualizações baseada em dados
- Identificação de correlações e anomalias

### Relatórios Automatizados
- Templates de análise reutilizáveis
- Geração de insights contextualizados
- Comparações temporais automáticas

### Data Discovery
- Catalogação automática de datasets
- Recomendações baseadas em contexto
- Mapeamento de relacionamentos entre dados

## Próximos Passos para Implementação

1. **Prototipagem**: Comece com um dataset simples
2. **Iteração**: Adicione funcionalidades gradualmente
3. **Validação**: Teste com diferentes tipos de queries
4. **Otimização**: Melhore performance conforme necessário
5. **Documentação**: Crie guias para outros desenvolvedores

## Conclusão

O MCP representa uma evolução natural na forma como LLMs interagem com dados externos. Ao combinar DuckDB com arquivos Parquet do Internet Archive, você cria uma solução poderosa que é:

- **Eficiente**: Processamento otimizado de dados colunares
- **Acessível**: Dados públicos sem custos de infraestrutura
- **Flexível**: Suporte a análises complexas via SQL
- **Padronizada**: Interface consistente via MCP

Esta abordagem democratiza o acesso a análises de dados avançadas, permitindo que LLMs forneçam insights valiosos a partir de datasets reais de forma segura e controlada.
</file>

<file path="docs/openapi/api-pncp-consulta.json">
{"openapi":"3.0.1","info":{"title":"API PNCP CONSULTA","description":"API REST de serviços do Portal Nacional de Contratações Públicas (PNCP)","contact":{"name":"Serviço Federal de Processamento de Dados - Serpro","url":"https://www.serpro.gov.br","email":"css.serpro@serpro.gov.br"},"version":"1.0"},"servers":[{"url":"/api/consulta"},{"url":"http://localhost:8080/pncp-consulta"}],"tags":[{"name":"Ata","description":"Consultas de Atas de Registro de Preços"},{"name":"Contratação","description":"Consultas de Contratações"},{"name":"Contrato/Empenho","description":"Consultas de Contratos/Empenhos"},{"name":"Instrumento de Cobrança de Contrato/Empenho","description":"Consultas de Instrumentos de Cobrança de Contratos/Empenhos"},{"name":"Contratação","description":"Manutenção de Contratações"},{"name":"Plano de Contratação","description":"Consultas de Planos de Contratações"}],"paths":{"/v1/pca/usuario":{"get":{"tags":["Plano de Contratação"],"summary":"Consultar Itens de PCA por Ano do PCA, IdUsuario e Código de Classificação Superior","operationId":"consultarItensPorUsuarioAno","parameters":[{"name":"anoPca","in":"query","required":true,"schema":{"type":"integer","format":"int32"}},{"name":"idUsuario","in":"query","required":true,"schema":{"type":"integer","format":"int64"}},{"name":"codigoClassificacaoSuperior","in":"query","required":false,"schema":{"type":"string"}},{"name":"cnpj","in":"query","required":false,"schema":{"type":"string"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":500,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoPlanoContratacaoComItensDoUsuarioDTO"}}}}}}},"/v1/pca/atualizacao":{"get":{"tags":["Plano de Contratação"],"summary":"Consultar PCA por Data de Atualização Global","operationId":"consultarItensPorUsuarioAno_1","parameters":[{"name":"dataInicio","in":"query","required":true,"schema":{"type":"string"}},{"name":"dataFim","in":"query","required":true,"schema":{"type":"string"}},{"name":"cnpj","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoUnidade","in":"query","required":false,"schema":{"type":"string"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":500,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoPlanoContratacaoComItensDoUsuarioDTO"}}}}}}},"/v1/pca/":{"get":{"tags":["Plano de Contratação"],"summary":"Consultar Itens de PCA por Ano do PCA e Código de Classificação Superior","operationId":"consultarItensPorAno","parameters":[{"name":"anoPca","in":"query","required":true,"schema":{"type":"integer","format":"int32"}},{"name":"codigoClassificacaoSuperior","in":"query","required":true,"schema":{"maxLength":100,"minLength":0,"type":"string"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":500,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoPlanoContratacaoComItensDoUsuarioDTO"}}}}}}},"/v1/orgaos/{cnpj}/compras/{ano}/{sequencial}":{"get":{"tags":["Contratação"],"summary":"Consultar Contratação","operationId":"consultarCompra","parameters":[{"name":"cnpj","in":"path","required":true,"schema":{"type":"string"}},{"name":"ano","in":"path","required":true,"schema":{"type":"integer","format":"int32"}},{"name":"sequencial","in":"path","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/RecuperarCompraDTO"}}}}}}},"/v1/instrumentoscobranca/inclusao":{"get":{"tags":["Instrumento de Cobrança de Contrato/Empenho"],"summary":"Consultar Instrumentos de Cobrança por Data de Inclusão","operationId":"consultarInstrumentos","parameters":[{"name":"dataInicial","in":"query","required":true,"schema":{"type":"string"}},{"name":"dataFinal","in":"query","required":true,"schema":{"type":"string"}},{"name":"tipoInstrumentoCobranca","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"cnpjOrgao","in":"query","required":false,"schema":{"type":"string"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":100,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoConsultarInstrumentoCobrancaDTO"}}}}}}},"/v1/contratos":{"get":{"tags":["Contrato/Empenho"],"summary":"Consultar Contratos por Data de Publicação","operationId":"consultarContratosPorDataPublicacao","parameters":[{"name":"dataInicial","in":"query","required":true,"schema":{"type":"string"}},{"name":"dataFinal","in":"query","required":true,"schema":{"type":"string"}},{"name":"cnpjOrgao","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoUnidadeAdministrativa","in":"query","required":false,"schema":{"type":"string"}},{"name":"usuarioId","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":500,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoRecuperarContratoDTO"}}}}}}},"/v1/contratos/atualizacao":{"get":{"tags":["Contrato/Empenho"],"summary":"Consultar Contratos/Empenhos por Data de Atualização Global","operationId":"consultarContratosPorDataAtualizacaoGlobal","parameters":[{"name":"dataInicial","in":"query","required":true,"schema":{"type":"string"}},{"name":"dataFinal","in":"query","required":true,"schema":{"type":"string"}},{"name":"cnpjOrgao","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoUnidadeAdministrativa","in":"query","required":false,"schema":{"type":"string"}},{"name":"usuarioId","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":500,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoRecuperarContratoDTO"}}}}}}},"/v1/contratacoes/publicacao":{"get":{"tags":["Contratação"],"summary":"Consultar Contratações por Data de Publicação","operationId":"consultarContratacaoPorDataDePublicacao","parameters":[{"name":"dataInicial","in":"query","required":true,"schema":{"type":"string"}},{"name":"dataFinal","in":"query","required":true,"schema":{"type":"string"}},{"name":"codigoModalidadeContratacao","in":"query","required":true,"schema":{"type":"integer","format":"int64"}},{"name":"codigoModoDisputa","in":"query","required":false,"schema":{"type":"integer","format":"int32"}},{"name":"uf","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoMunicipioIbge","in":"query","required":false,"schema":{"type":"string"}},{"name":"cnpj","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoUnidadeAdministrativa","in":"query","required":false,"schema":{"type":"string"}},{"name":"idUsuario","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":50,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoRecuperarCompraPublicacaoDTO"}}}}}}},"/v1/contratacoes/proposta":{"get":{"tags":["Contratação"],"summary":"Consultar Contratações com Recebimento de Propostas Aberto","operationId":"consultarContratacaoPeriodoRecebimentoPropostas","parameters":[{"name":"dataFinal","in":"query","required":true,"schema":{"type":"string"}},{"name":"codigoModalidadeContratacao","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"uf","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoMunicipioIbge","in":"query","required":false,"schema":{"type":"string"}},{"name":"cnpj","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoUnidadeAdministrativa","in":"query","required":false,"schema":{"maxLength":30,"minLength":1,"type":"string"}},{"name":"idUsuario","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":50,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoRecuperarCompraPublicacaoDTO"}}}}}}},"/v1/contratacoes/atualizacao":{"get":{"tags":["Contratação"],"summary":"Consultar Contratações por Data de Atualização Global","operationId":"consultarContratacaoPorDataUltimaAtualizacao","parameters":[{"name":"dataInicial","in":"query","required":true,"schema":{"type":"string"}},{"name":"dataFinal","in":"query","required":true,"schema":{"type":"string"}},{"name":"codigoModalidadeContratacao","in":"query","required":true,"schema":{"type":"integer","format":"int64"}},{"name":"codigoModoDisputa","in":"query","required":false,"schema":{"type":"integer","format":"int32"}},{"name":"uf","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoMunicipioIbge","in":"query","required":false,"schema":{"type":"string"}},{"name":"cnpj","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoUnidadeAdministrativa","in":"query","required":false,"schema":{"type":"string"}},{"name":"idUsuario","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":50,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoRecuperarCompraPublicacaoDTO"}}}}}}},"/v1/atas":{"get":{"tags":["Ata"],"summary":"Consultar Ata de Registro de Preço por Período de Vigência","operationId":"consultarAtaRegistroPrecoPeriodo","parameters":[{"name":"dataInicial","in":"query","required":true,"schema":{"type":"string"}},{"name":"dataFinal","in":"query","required":true,"schema":{"type":"string"}},{"name":"idUsuario","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"cnpj","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoUnidadeAdministrativa","in":"query","required":false,"schema":{"maxLength":30,"minLength":1,"type":"string"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":500,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoAtaRegistroPrecoPeriodoDTO"}}}}}}},"/v1/atas/atualizacao":{"get":{"tags":["Ata"],"summary":"Consultar Atas de Registro de Preço por Data de Atualização Global","operationId":"consultarAtaRegistroPrecoDataAtualizacao","parameters":[{"name":"dataInicial","in":"query","required":true,"schema":{"type":"string"}},{"name":"dataFinal","in":"query","required":true,"schema":{"type":"string"}},{"name":"idUsuario","in":"query","required":false,"schema":{"type":"integer","format":"int64"}},{"name":"cnpj","in":"query","required":false,"schema":{"type":"string"}},{"name":"codigoUnidadeAdministrativa","in":"query","required":false,"schema":{"maxLength":30,"minLength":1,"type":"string"}},{"name":"pagina","in":"query","required":true,"schema":{"minimum":1,"type":"integer","format":"int32"}},{"name":"tamanhoPagina","in":"query","required":false,"schema":{"maximum":500,"minimum":10,"type":"integer","format":"int32"}}],"responses":{"400":{"description":"Bad Request","content":{"*/*":{"schema":{"oneOf":[{"type":"object","additionalProperties":{"type":"string"}},{"$ref":"#/components/schemas/RespostaErroValidacaoDTO"}]}}}},"422":{"description":"Unprocessable Entity","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"204":{"description":"No Content","content":{"*/*":{"schema":{"type":"object","additionalProperties":{"type":"string"}}}}},"500":{"description":"Internal Server Error","content":{"*/*":{"schema":{"type":"string"}}}},"401":{"description":"Unauthorized","content":{"*/*":{"schema":{"type":"string"}}}},"200":{"description":"OK","content":{"*/*":{"schema":{"$ref":"#/components/schemas/PaginaRetornoAtaRegistroPrecoPeriodoDTO"}}}}}}}},"components":{"schemas":{"RespostaErroValidacaoDTO":{"type":"object","properties":{"message":{"type":"string"},"path":{"type":"string"},"timestamp":{"type":"string"},"status":{"type":"string"},"error":{"type":"string"}}},"PaginaRetornoPlanoContratacaoComItensDoUsuarioDTO":{"type":"object","properties":{"data":{"type":"array","items":{"$ref":"#/components/schemas/PlanoContratacaoComItensDoUsuarioDTO"}},"totalRegistros":{"type":"integer","format":"int64"},"totalPaginas":{"type":"integer","format":"int64"},"numeroPagina":{"type":"integer","format":"int64"},"paginasRestantes":{"type":"integer","format":"int64"},"empty":{"type":"boolean"}}},"PlanoContratacaoComItensDoUsuarioDTO":{"type":"object","properties":{"itens":{"type":"array","items":{"$ref":"#/components/schemas/PlanoContratacaoItemDTO"}},"codigoUnidade":{"type":"string"},"nomeUnidade":{"type":"string"},"anoPca":{"type":"integer","format":"int32"},"orgaoEntidadeRazaoSocial":{"type":"string"},"orgaoEntidadeCnpj":{"type":"string"},"dataPublicacaoPNCP":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacaoGlobalPCA":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"idPcaPncp":{"type":"string"}}},"PlanoContratacaoItemDTO":{"type":"object","properties":{"nomeClassificacaoCatalogo":{"type":"string"},"quantidadeEstimada":{"type":"number"},"descricaoItem":{"type":"string"},"pdmCodigo":{"type":"string"},"dataInclusao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"numeroItem":{"type":"integer","format":"int32"},"dataAtualizacao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"valorTotal":{"type":"number"},"pdmDescricao":{"type":"string"},"codigoItem":{"type":"string"},"unidadeRequisitante":{"type":"string"},"grupoContratacaoCodigo":{"type":"string"},"grupoContratacaoNome":{"type":"string"},"classificacaoSuperiorCodigo":{"type":"string"},"classificacaoSuperiorNome":{"type":"string"},"unidadeFornecimento":{"type":"string"},"valorUnitario":{"type":"number"},"valorOrcamentoExercicio":{"type":"number"},"dataDesejada":{"type":"string","format":"date"},"classificacaoCatalogoId":{"type":"integer","format":"int64"},"categoriaItemPcaNome":{"type":"string"}}},"ContratacaoFonteOrcamentariaDTO":{"type":"object","properties":{"codigo":{"type":"integer","format":"int64"},"nome":{"type":"string"},"descricao":{"type":"string"},"dataInclusao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"}}},"RecuperarAmparoLegalDTO":{"type":"object","properties":{"descricao":{"type":"string"},"nome":{"type":"string"},"codigo":{"type":"integer","format":"int64"}}},"RecuperarCompraDTO":{"type":"object","properties":{"valorTotalEstimado":{"type":"number"},"valorTotalHomologado":{"type":"number"},"indicadorOrcamentoSigiloso":{"type":"string","writeOnly":true,"enum":["COMPRA_SEM_SIGILO","COMPRA_PARCIALMENTE_SIGILOSA","COMPRA_TOTALMENTE_SIGILOSA"]},"orcamentoSigilosoCodigo":{"type":"integer","format":"int32"},"orcamentoSigilosoDescricao":{"type":"string"},"numeroControlePNCP":{"type":"string"},"linkSistemaOrigem":{"type":"string"},"linkProcessoEletronico":{"type":"string"},"anoCompra":{"type":"integer","format":"int32"},"sequencialCompra":{"type":"integer","format":"int32"},"numeroCompra":{"type":"string"},"processo":{"type":"string"},"orgaoEntidade":{"$ref":"#/components/schemas/RecuperarOrgaoEntidadeDTO"},"unidadeOrgao":{"$ref":"#/components/schemas/RecuperarUnidadeOrgaoDTO"},"orgaoSubRogado":{"$ref":"#/components/schemas/RecuperarOrgaoEntidadeDTO"},"unidadeSubRogada":{"$ref":"#/components/schemas/RecuperarUnidadeOrgaoDTO"},"modalidadeId":{"type":"integer","format":"int64"},"modalidadeNome":{"type":"string"},"justificativaPresencial":{"type":"string"},"modoDisputaId":{"type":"integer","format":"int64"},"modoDisputaNome":{"type":"string"},"tipoInstrumentoConvocatorioCodigo":{"type":"integer","format":"int64"},"tipoInstrumentoConvocatorioNome":{"type":"string"},"amparoLegal":{"$ref":"#/components/schemas/RecuperarAmparoLegalDTO"},"objetoCompra":{"type":"string"},"informacaoComplementar":{"type":"string"},"srp":{"type":"boolean"},"fontesOrcamentarias":{"type":"array","items":{"$ref":"#/components/schemas/ContratacaoFonteOrcamentariaDTO"}},"dataPublicacaoPncp":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAberturaProposta":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataEncerramentoProposta":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"situacaoCompraId":{"type":"string","enum":["1","2","3","4"]},"situacaoCompraNome":{"type":"string"},"existeResultado":{"type":"boolean"},"dataInclusao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacaoGlobal":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"usuarioNome":{"type":"string"}}},"RecuperarOrgaoEntidadeDTO":{"type":"object","properties":{"cnpj":{"type":"string"},"razaoSocial":{"type":"string"},"poderId":{"type":"string"},"esferaId":{"type":"string"}}},"RecuperarUnidadeOrgaoDTO":{"type":"object","properties":{"ufNome":{"type":"string"},"codigoUnidade":{"type":"string"},"nomeUnidade":{"type":"string"},"ufSigla":{"type":"string"},"municipioNome":{"type":"string"},"codigoIbge":{"type":"string"}}},"Categoria":{"type":"object","properties":{"id":{"type":"integer","format":"int64"},"nome":{"type":"string"}}},"ConsultarInstrumentoCobrancaDTO":{"type":"object","properties":{"cnpj":{"type":"string"},"ano":{"type":"integer","format":"int32"},"sequencialContrato":{"type":"integer","format":"int32"},"sequencialInstrumentoCobranca":{"type":"integer","format":"int32"},"tipoInstrumentoCobranca":{"$ref":"#/components/schemas/TipoInstrumentoCobrancaDTO"},"numeroInstrumentoCobranca":{"type":"string"},"dataEmissaoDocumento":{"type":"string","format":"date"},"observacao":{"type":"string"},"chaveNFe":{"type":"string"},"fonteNFe":{"type":"integer","format":"int64"},"dataConsultaNFe":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"statusResponseNFe":{"type":"string"},"jsonResponseNFe":{"type":"string"},"notaFiscalEletronica":{"$ref":"#/components/schemas/NotaFiscalEletronicaConsultaDTO"},"dataInclusao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"recuperarContratoDTO":{"$ref":"#/components/schemas/RecuperarContratoDTO"}}},"EventoNotaFiscalConsultaDTO":{"type":"object","properties":{"dataEvento":{"type":"string"},"tipoEvento":{"type":"string"},"evento":{"type":"string"},"motivoEvento":{"type":"string"}}},"ItemNotaFiscalConsultaDTO":{"type":"object","properties":{"numeroItem":{"type":"string"},"descricaoProdutoServico":{"type":"string"},"codigoNCM":{"type":"string"},"descricaoNCM":{"type":"string"},"cfop":{"type":"string"},"quantidade":{"type":"string"},"unidade":{"type":"string"},"valorUnitario":{"type":"string"},"valorTotal":{"type":"string"}}},"NotaFiscalEletronicaConsultaDTO":{"type":"object","properties":{"instrumentoCobrancaId":{"type":"integer","format":"int64"},"chave":{"type":"string"},"nfTransparenciaID":{"type":"integer","format":"int64"},"numero":{"type":"integer","format":"int64"},"serie":{"type":"integer","format":"int32"},"dataEmissao":{"type":"string"},"niEmitente":{"type":"string"},"nomeEmitente":{"type":"string"},"nomeMunicipioEmitente":{"type":"string"},"codigoOrgaoDestinatario":{"type":"string"},"nomeOrgaoDestinatario":{"type":"string"},"codigoOrgaoSuperiorDestinatario":{"type":"string"},"nomeOrgaoSuperiorDestinatario":{"type":"string"},"valorNotaFiscal":{"type":"string"},"tipoEventoMaisRecente":{"type":"string"},"dataTipoEventoMaisRecente":{"type":"string"},"dataInclusao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"itens":{"type":"array","items":{"$ref":"#/components/schemas/ItemNotaFiscalConsultaDTO"}},"eventos":{"type":"array","items":{"$ref":"#/components/schemas/EventoNotaFiscalConsultaDTO"}}}},"PaginaRetornoConsultarInstrumentoCobrancaDTO":{"type":"object","properties":{"data":{"type":"array","items":{"$ref":"#/components/schemas/ConsultarInstrumentoCobrancaDTO"}},"totalRegistros":{"type":"integer","format":"int64"},"totalPaginas":{"type":"integer","format":"int64"},"numeroPagina":{"type":"integer","format":"int64"},"paginasRestantes":{"type":"integer","format":"int64"},"empty":{"type":"boolean"}}},"RecuperarContratoDTO":{"type":"object","properties":{"numeroControlePncpCompra":{"type":"string"},"codigoPaisFornecedor":{"type":"string"},"anoContrato":{"type":"integer","format":"int32"},"tipoContrato":{"$ref":"#/components/schemas/TipoContrato"},"numeroContratoEmpenho":{"type":"string"},"dataAssinatura":{"type":"string","format":"date"},"dataVigenciaInicio":{"type":"string","format":"date"},"dataVigenciaFim":{"type":"string","format":"date"},"niFornecedor":{"type":"string"},"tipoPessoa":{"type":"string","enum":["PJ","PF","PE"]},"orgaoEntidade":{"$ref":"#/components/schemas/RecuperarOrgaoEntidadeDTO"},"categoriaProcesso":{"$ref":"#/components/schemas/Categoria"},"dataPublicacaoPncp":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"sequencialContrato":{"type":"integer","format":"int32"},"unidadeOrgao":{"$ref":"#/components/schemas/RecuperarUnidadeOrgaoDTO"},"informacaoComplementar":{"type":"string"},"processo":{"type":"string"},"unidadeSubRogada":{"$ref":"#/components/schemas/RecuperarUnidadeOrgaoDTO"},"orgaoSubRogado":{"$ref":"#/components/schemas/RecuperarOrgaoEntidadeDTO"},"nomeRazaoSocialFornecedor":{"type":"string"},"niFornecedorSubContratado":{"type":"string"},"nomeFornecedorSubContratado":{"type":"string"},"numeroControlePNCP":{"type":"string"},"receita":{"type":"boolean"},"numeroParcelas":{"type":"integer","format":"int32"},"numeroRetificacao":{"type":"integer","format":"int32"},"tipoPessoaSubContratada":{"type":"string","enum":["PJ","PF","PE"]},"objetoContrato":{"type":"string"},"valorInicial":{"type":"number"},"valorParcela":{"type":"number"},"valorGlobal":{"type":"number"},"valorAcumulado":{"type":"number"},"dataAtualizacaoGlobal":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"identificadorCipi":{"type":"string"},"urlCipi":{"type":"string"},"usuarioNome":{"type":"string"}}},"TipoContrato":{"type":"object","properties":{"id":{"type":"integer","format":"int64"},"nome":{"type":"string"}}},"TipoInstrumentoCobrancaDTO":{"type":"object","properties":{"id":{"type":"integer","format":"int64"},"nome":{"type":"string"},"descricao":{"type":"string"},"dataInclusao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"statusAtivo":{"type":"boolean"}}},"PaginaRetornoRecuperarContratoDTO":{"type":"object","properties":{"data":{"type":"array","items":{"$ref":"#/components/schemas/RecuperarContratoDTO"}},"totalRegistros":{"type":"integer","format":"int64"},"totalPaginas":{"type":"integer","format":"int64"},"numeroPagina":{"type":"integer","format":"int64"},"paginasRestantes":{"type":"integer","format":"int64"},"empty":{"type":"boolean"}}},"PaginaRetornoRecuperarCompraPublicacaoDTO":{"type":"object","properties":{"data":{"type":"array","items":{"$ref":"#/components/schemas/RecuperarCompraPublicacaoDTO"}},"totalRegistros":{"type":"integer","format":"int64"},"totalPaginas":{"type":"integer","format":"int64"},"numeroPagina":{"type":"integer","format":"int64"},"paginasRestantes":{"type":"integer","format":"int64"},"empty":{"type":"boolean"}}},"RecuperarCompraPublicacaoDTO":{"type":"object","properties":{"srp":{"type":"boolean"},"orgaoEntidade":{"$ref":"#/components/schemas/RecuperarOrgaoEntidadeDTO"},"anoCompra":{"type":"integer","format":"int32"},"sequencialCompra":{"type":"integer","format":"int32"},"dataInclusao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataPublicacaoPncp":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"numeroCompra":{"type":"string"},"unidadeOrgao":{"$ref":"#/components/schemas/RecuperarUnidadeOrgaoDTO"},"amparoLegal":{"$ref":"#/components/schemas/RecuperarAmparoLegalDTO"},"dataAberturaProposta":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataEncerramentoProposta":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"informacaoComplementar":{"type":"string"},"processo":{"type":"string"},"objetoCompra":{"type":"string"},"linkSistemaOrigem":{"type":"string"},"justificativaPresencial":{"type":"string"},"unidadeSubRogada":{"$ref":"#/components/schemas/RecuperarUnidadeOrgaoDTO"},"orgaoSubRogado":{"$ref":"#/components/schemas/RecuperarOrgaoEntidadeDTO"},"valorTotalHomologado":{"type":"number"},"linkProcessoEletronico":{"type":"string"},"numeroControlePNCP":{"type":"string"},"modalidadeId":{"type":"integer","format":"int64"},"dataAtualizacaoGlobal":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"modoDisputaId":{"type":"integer","format":"int64"},"valorTotalEstimado":{"type":"number"},"modalidadeNome":{"type":"string"},"modoDisputaNome":{"type":"string"},"tipoInstrumentoConvocatorioCodigo":{"type":"integer","format":"int64"},"tipoInstrumentoConvocatorioNome":{"type":"string"},"fontesOrcamentarias":{"type":"array","items":{"$ref":"#/components/schemas/ContratacaoFonteOrcamentariaDTO"}},"situacaoCompraId":{"type":"string","enum":["1","2","3","4"]},"situacaoCompraNome":{"type":"string"},"usuarioNome":{"type":"string"}}},"AtaRegistroPrecoPeriodoDTO":{"type":"object","properties":{"numeroControlePNCPAta":{"type":"string"},"numeroAtaRegistroPreco":{"type":"string"},"anoAta":{"type":"integer","format":"int32"},"numeroControlePNCPCompra":{"type":"string"},"cancelado":{"type":"boolean"},"dataCancelamento":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAssinatura":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"vigenciaInicio":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"vigenciaFim":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataPublicacaoPncp":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataInclusao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacao":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"dataAtualizacaoGlobal":{"type":"string","format":"date-time","example":"2025-07-11T13:08:48"},"usuario":{"type":"string"},"objetoContratacao":{"type":"string"},"cnpjOrgao":{"type":"string"},"nomeOrgao":{"type":"string"},"cnpjOrgaoSubrogado":{"type":"string"},"nomeOrgaoSubrogado":{"type":"string"},"codigoUnidadeOrgao":{"type":"string"},"nomeUnidadeOrgao":{"type":"string"},"codigoUnidadeOrgaoSubrogado":{"type":"string"},"nomeUnidadeOrgaoSubrogado":{"type":"string"}}},"PaginaRetornoAtaRegistroPrecoPeriodoDTO":{"type":"object","properties":{"data":{"type":"array","items":{"$ref":"#/components/schemas/AtaRegistroPrecoPeriodoDTO"}},"totalRegistros":{"type":"integer","format":"int64"},"totalPaginas":{"type":"integer","format":"int64"},"numeroPagina":{"type":"integer","format":"int64"},"paginasRestantes":{"type":"integer","format":"int64"},"empty":{"type":"boolean"}}}},"securitySchemes":{"bearerAuth":{"type":"http","scheme":"bearer","bearerFormat":"JWT"}}}}
</file>

<file path="mkdocs.yml">
site_name: BALIZA
site_description: 'Backup Aberto de Licitações Zelando pelo Acesso - Historical archive of Brazilian public procurement data'
site_author: 'Franklin Baldo'
site_url: 'https://franklinbaldo.github.io/baliza/'

repo_name: 'franklinbaldo/baliza'
repo_url: 'https://github.com/franklinbaldo/baliza'
edit_uri: 'edit/main/docs/'

theme:
  name: material
  language: en
  palette:
    - media: "(prefers-color-scheme: light)"
      scheme: default
      toggle:
        icon: material/weather-night
        name: Switch to dark mode
    - media: "(prefers-color-scheme: dark)"
      scheme: slate
      toggle:
        icon: material/weather-sunny
        name: Switch to light mode
  features:
    - navigation.tabs
    - navigation.sections
    - navigation.top
    - search.suggest
    - search.highlight
    - content.tabs.link
    - content.code.annotation
    - content.code.copy
  icon:
    repo: fontawesome/brands/github-alt

extra:
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/franklinbaldo
    - icon: fontawesome/brands/linkedin
      link: https://www.linkedin.com/in/franklinbaldo/

plugins:
  - gen-files:
      scripts:
        - docs/gen_ref_pages.py
  - literate-nav:
      nav_file: SUMMARY.md
  - search

markdown_extensions:
  - pymdownx.highlight:
      anchor_linenums: true
  - pymdownx.inlinehilite
  - pymdownx.snippets
  - admonition
  - pymdownx.details
  - pymdownx.superfences
  - pymdownx.tabbed:
      alternate_style: true
</file>

<file path="scripts/export_to_parquet.py">
import duckdb
import os
from datetime import date, timedelta

def export_new_data_to_parquet(db_path="data/baliza.duckdb", output_dir="data/parquet"):
    """
    Connects to the DuckDB database generated by a Baliza run,
    extracts the data for the most recent extraction date, and exports it
    to partitioned Parquet files.

    The partitioning is done by endpoint, year, and month.
    """
    if not os.path.exists(db_path):
        print(f"Database file not found at {db_path}. Nothing to export.")
        return

    con = duckdb.connect(database=db_path, read_only=True)

    # The table name where Baliza stores raw responses
    table_name = "raw_pncp"

    # We'll export data from yesterday, as the daily run is configured to fetch recent data.
    target_date = date.today() - timedelta(days=1)
    print(f"Targeting data for date: {target_date.strftime('%Y-%m-%d')}")

    # Export the raw data for the target date to partitioned Parquet files
    print(f"Exporting raw data from {target_date.strftime('%Y-%m-%d')} to Parquet...")

    # The raw data is stored in a JSON blob. We extract metadata for partitioning.
    # The `data` column is the JSON blob from the PNCP API.
    sql_query = f"""
    COPY (
        SELECT
            json_extract_string(data, '$.dataPublicacao') as data_publicacao,
            endpoint,
            data,
            CAST(strftime(CAST(json_extract_string(data, '$.dataPublicacao') AS DATE), '%Y') AS INTEGER) as ano_publicacao,
            CAST(strftime(CAST(json_extract_string(data, '$.dataPublicacao') AS DATE), '%m') AS INTEGER) as mes_publicacao
        FROM {table_name}
        WHERE CAST(json_extract_string(data, '$.dataPublicacao') AS DATE) = '{target_date.strftime('%Y-%m-%d')}'
    ) TO '{output_dir}' (
        FORMAT PARQUET,
        PARTITION_BY (endpoint, ano_publicacao, mes_publicacao),
        OVERWRITE_OR_IGNORE 1,
        FILENAME_PATTERN "data_{{i}}"
    );
    """

    try:
        con.execute(sql_query)
        print(f"Successfully exported data to {output_dir}")
    except Exception as e:
        print(f"Failed to export data to Parquet. Error: {e}")
    finally:
        con.close()

if __name__ == "__main__":
    # Make sure the script is executable and has the correct path context
    # when running in the GitHub Actions workflow.
    export_new_data_to_parquet()
</file>

<file path="scripts/test_contratacoes_proposta.py">
#!/usr/bin/env python3
"""
Test contratacoes_proposta endpoint to understand date requirements and limits
"""

import asyncio
import httpx
from datetime import date, timedelta
from src.baliza.extractor import PNCP_BASE_URL


async def test_contratacoes_proposta_limits():
    """Test contratacoes_proposta endpoint date limits and requirements"""
    print("🧪 Testing contratacoes_proposta endpoint requirements")
    
    today = date.today()
    
    # Test different scenarios
    test_scenarios = [
        # Test if dataFinal is required
        ("No dataFinal parameter", {}),
        
        # Test with today's date
        ("Today's date", {"dataFinal": today.strftime("%Y%m%d")}),
        
        # Test with future dates
        ("Tomorrow", {"dataFinal": (today + timedelta(days=1)).strftime("%Y%m%d")}),
        ("1 week future", {"dataFinal": (today + timedelta(days=7)).strftime("%Y%m%d")}),
        ("30 days future", {"dataFinal": (today + timedelta(days=30)).strftime("%Y%m%d")}),
        ("90 days future", {"dataFinal": (today + timedelta(days=90)).strftime("%Y%m%d")}),
        ("1 year future", {"dataFinal": (today + timedelta(days=365)).strftime("%Y%m%d")}),
        ("2 years future", {"dataFinal": (today + timedelta(days=730)).strftime("%Y%m%d")}),
        ("5 years future", {"dataFinal": (today + timedelta(days=1825)).strftime("%Y%m%d")}),
    ]
    
    async with httpx.AsyncClient(
        base_url=PNCP_BASE_URL,
        timeout=30.0,
        headers={
            "User-Agent": "BALIZA/3.0 (Testing)",
            "Accept": "application/json",
        }
    ) as client:
        
        for scenario_name, base_params in test_scenarios:
            print(f"\n   Testing: {scenario_name}")
            
            # Test with modalidade 6 (usually has most data)
            params = {
                "tamanhoPagina": 10,
                "pagina": 1,
                "codigoModalidadeContratacao": 6,
                **base_params
            }
            
            try:
                response = await client.get("/v1/contratacoes/proposta", params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    total_records = data.get("totalRegistros", 0)
                    print(f"      ✅ SUCCESS: {total_records:,} records found")
                    if total_records > 0:
                        sample_data = data.get("data", [])
                        if sample_data:
                            first_record = sample_data[0]
                            print(f"         Sample contract: {first_record.get('numeroControlePNCP', 'N/A')}")
                            print(f"         Deadline: {first_record.get('dataFimPropostas', 'N/A')}")
                elif response.status_code == 422:
                    error_data = response.json()
                    print(f"      ❌ HTTP 422: {error_data.get('message', 'Validation error')}")
                elif response.status_code == 400:
                    error_data = response.json()
                    print(f"      ❌ HTTP 400: {error_data.get('message', 'Bad request')}")
                else:
                    print(f"      ❌ HTTP {response.status_code}: {response.text[:200]}")
                    
            except Exception as e:
                print(f"      💥 Exception: {e}")
            
            # Small delay to be respectful
            await asyncio.sleep(1.0)
    
    print("\n🏁 Contratacoes proposta testing complete!")


async def test_without_modalidade():
    """Test if modalidade parameter is required"""
    print("\n🧪 Testing contratacoes_proposta WITHOUT modalidade parameter")
    
    today = date.today()
    future_date = today + timedelta(days=30)
    
    params = {
        "tamanhoPagina": 10,
        "pagina": 1,
        "dataFinal": future_date.strftime("%Y%m%d"),
        # No modalidade parameter
    }
    
    async with httpx.AsyncClient(
        base_url=PNCP_BASE_URL,
        timeout=30.0,
        headers={
            "User-Agent": "BALIZA/3.0 (Testing)",
            "Accept": "application/json",
        }
    ) as client:
        
        try:
            response = await client.get("/v1/contratacoes/proposta", params=params)
            
            if response.status_code == 200:
                data = response.json()
                total_records = data.get("totalRegistros", 0)
                print(f"   ✅ SUCCESS without modalidade: {total_records:,} records found")
            elif response.status_code == 400:
                error_data = response.json()
                print(f"   ❌ HTTP 400: {error_data.get('message', 'Bad request')}")
                print("   → Modalidade parameter IS required")
            else:
                print(f"   ❌ HTTP {response.status_code}: {response.text[:200]}")
                
        except Exception as e:
            print(f"   💥 Exception: {e}")


if __name__ == "__main__":
    asyncio.run(test_contratacoes_proposta_limits())
    asyncio.run(test_without_modalidade())
</file>

<file path="scripts/test_instrumentos.py">
#!/usr/bin/env python3
"""
Test instrumentoscobranca_inclusao endpoint with different date ranges
"""

import asyncio
import httpx
from datetime import date, timedelta
from src.baliza.pncp_extractor import PNCP_BASE_URL


async def test_instrumentos_cobranca():
    """Test instrumentoscobranca_inclusao with various date ranges"""
    print("🧪 Testing instrumentoscobranca_inclusao endpoint")
    
    # Test different date ranges to find data
    test_ranges = [
        (date(2024, 1, 1), date(2024, 1, 31)),   # January 2024
        (date(2024, 3, 1), date(2024, 3, 31)),   # March 2024
        (date(2024, 6, 1), date(2024, 6, 30)),   # June 2024
        (date(2023, 12, 1), date(2023, 12, 31)), # December 2023
        (date(2023, 6, 1), date(2023, 6, 30)),   # June 2023
        (date(2022, 12, 1), date(2022, 12, 31)), # December 2022
        (date(2021, 12, 1), date(2021, 12, 31)), # December 2021
    ]
    
    async with httpx.AsyncClient(
        base_url=PNCP_BASE_URL,
        timeout=30.0,
        headers={
            "User-Agent": "BALIZA/3.0 (Testing)",
            "Accept": "application/json",
        }
    ) as client:
        
        for start_date, end_date in test_ranges:
            print(f"\n   Testing range: {start_date} to {end_date}")
            
            params = {
                "tamanhoPagina": 10,
                "pagina": 1,
                "dataInicial": start_date.strftime("%Y%m%d"),
                "dataFinal": end_date.strftime("%Y%m%d"),
            }
            
            try:
                response = await client.get("/v1/instrumentoscobranca/inclusao", params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    total_records = data.get("totalRegistros", 0)
                    print(f"      ✅ SUCCESS: {total_records:,} records found!")
                    if total_records > 0:
                        print(f"         Sample data: {data.get('data', [])[:1]}")
                    break  # Found data, no need to test more
                elif response.status_code == 404:
                    print(f"      ❌ HTTP 404: No data found for this period")
                else:
                    print(f"      ❌ HTTP {response.status_code}: {response.text[:200]}")
                    
            except Exception as e:
                print(f"      💥 Exception: {e}")
            
            # Small delay to be respectful
            await asyncio.sleep(1.0)
    
    print("\n🏁 Instrumentos cobranca testing complete!")


if __name__ == "__main__":
    asyncio.run(test_instrumentos_cobranca())
</file>

<file path="scripts/test_modalidades.py">
#!/usr/bin/env python3
"""
Test script for modalidade iteration functionality
"""

import asyncio
import httpx
from datetime import date, timedelta
from baliza.extractor import PNCP_ENDPOINTS, PNCP_BASE_URL


async def test_contratacoes_with_modalidades():
    """Test contratacoes endpoints with modalidade iteration"""
    print("🚀 Testing contratacoes endpoints with modalidade iteration\n")
    
    # Test date - use a date from the past that should have data
    test_date = date(2024, 6, 18)  # Use a date from last year
    
    # Find contratacoes endpoints
    contratacoes_endpoints = [
        ep for ep in PNCP_ENDPOINTS 
        if ep["name"] in ["contratacoes_publicacao", "contratacoes_atualizacao"]
    ]
    
    async with httpx.AsyncClient(
        base_url=PNCP_BASE_URL,
        timeout=30.0,
        headers={
            "User-Agent": "BALIZA/3.0 (Testing)",
            "Accept": "application/json",
        }
    ) as client:
        
        for endpoint in contratacoes_endpoints:
            print(f"\n🧪 Testing {endpoint['name']}")
            modalidades = endpoint.get("iterate_modalidades", [])
            
            for modalidade in modalidades:
                print(f"   Testing modalidade {modalidade}...")
                
                # Build parameters
                params = {
                    "tamanhoPagina": 10,
                    "pagina": 1,
                    "dataInicial": test_date.strftime("%Y%m%d"),
                    "dataFinal": test_date.strftime("%Y%m%d"),
                    "codigoModalidadeContratacao": modalidade
                }
                
                try:
                    response = await client.get(endpoint["path"], params=params)
                    
                    if response.status_code == 200:
                        data = response.json()
                        total_records = data.get("totalRegistros", 0)
                        print(f"      ✅ Modalidade {modalidade}: {total_records:,} records")
                    else:
                        print(f"      ❌ Modalidade {modalidade}: HTTP {response.status_code}")
                        if response.status_code == 422:
                            error_data = response.json()
                            print(f"         Error: {error_data.get('message', 'Unknown error')}")
                        
                except Exception as e:
                    print(f"      💥 Modalidade {modalidade}: Exception - {e}")
                
                # Small delay to be respectful
                await asyncio.sleep(0.5)


async def test_contratacoes_proposta_with_future_date():
    """Test contratacoes_proposta endpoint with future date"""
    print("\n🧪 Testing contratacoes_proposta with future date")
    
    # Use tomorrow's date
    future_date = date.today() + timedelta(days=1)
    
    endpoint = next(
        (ep for ep in PNCP_ENDPOINTS if ep["name"] == "contratacoes_proposta"),
        None
    )
    
    if not endpoint:
        print("❌ contratacoes_proposta endpoint not found")
        return
    
    async with httpx.AsyncClient(
        base_url=PNCP_BASE_URL,
        timeout=30.0,
        headers={
            "User-Agent": "BALIZA/3.0 (Testing)",
            "Accept": "application/json",
        }
    ) as client:
        
        modalidades = endpoint.get("iterate_modalidades", [])
        
        for modalidade in modalidades:
            print(f"   Testing modalidade {modalidade} with future date...")
            
            params = {
                "tamanhoPagina": 10,
                "pagina": 1,
                "dataFinal": future_date.strftime("%Y%m%d"),
                "codigoModalidadeContratacao": modalidade
            }
            
            try:
                response = await client.get(endpoint["path"], params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    total_records = data.get("totalRegistros", 0)
                    print(f"      ✅ Modalidade {modalidade}: {total_records:,} records")
                else:
                    print(f"      ❌ Modalidade {modalidade}: HTTP {response.status_code}")
                    if response.status_code == 422:
                        error_data = response.json()
                        print(f"         Error: {error_data.get('message', 'Unknown error')}")
                    
            except Exception as e:
                print(f"      💥 Modalidade {modalidade}: Exception - {e}")
            
            # Small delay to be respectful
            await asyncio.sleep(0.5)


async def test_instrumentos_cobranca_with_data():
    """Test instrumentos cobranca with a date that has data"""
    print("\n🧪 Testing instrumentoscobranca_inclusao with different dates")
    
    endpoint = next(
        (ep for ep in PNCP_ENDPOINTS if ep["name"] == "instrumentoscobranca_inclusao"),
        None
    )
    
    if not endpoint:
        print("❌ instrumentoscobranca_inclusao endpoint not found")
        return
    
    # Test different date ranges
    test_dates = [
        (date(2024, 3, 1), date(2024, 3, 31)),  # March 2024
        (date(2024, 6, 1), date(2024, 6, 30)),  # June 2024
        (date(2024, 1, 1), date(2024, 1, 31)),  # January 2024
    ]
    
    async with httpx.AsyncClient(
        base_url=PNCP_BASE_URL,
        timeout=30.0,
        headers={
            "User-Agent": "BALIZA/3.0 (Testing)",
            "Accept": "application/json",
        }
    ) as client:
        
        for start_date, end_date in test_dates:
            print(f"   Testing date range: {start_date} to {end_date}")
            
            params = {
                "tamanhoPagina": 10,
                "pagina": 1,
                "dataInicial": start_date.strftime("%Y%m%d"),
                "dataFinal": end_date.strftime("%Y%m%d"),
            }
            
            try:
                response = await client.get(endpoint["path"], params=params)
                
                if response.status_code == 200:
                    data = response.json()
                    total_records = data.get("totalRegistros", 0)
                    print(f"      ✅ {start_date} to {end_date}: {total_records:,} records")
                else:
                    print(f"      ❌ {start_date} to {end_date}: HTTP {response.status_code}")
                    if response.status_code == 404:
                        error_data = response.json()
                        print(f"         Error: {error_data.get('message', 'Not Found')}")
                    
            except Exception as e:
                print(f"      💥 {start_date} to {end_date}: Exception - {e}")
            
            # Small delay to be respectful
            await asyncio.sleep(1.0)


async def main():
    """Run all modalidade tests"""
    print("🔍 PNCP Modalidade Testing Script")
    print("=" * 50)
    
    await test_contratacoes_with_modalidades()
    await test_contratacoes_proposta_with_future_date()
    await test_instrumentos_cobranca_with_data()
    
    print("\n✅ All modalidade tests completed!")


if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="src/baliza/__init__.py">
"""
BALIZA: Backup Aberto de Licitações Zelando pelo Acesso
Simplified PNCP data extractor for Brazilian public procurement data
"""

__version__ = "0.2.0"
</file>

<file path="src/baliza/.gitignore">
__pycache__/*
build/
dist/
*.egg-info/
.pytest_cache/
*.pyc
# pyenv
.python-version

# Environments
.env
.venv

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# JetBrains
.idea/

/coverage.xml
/.coverage
</file>

<file path="src/baliza/enums.py">
"""
PNCP Enum Utilities - Centralized enum management for BALIZA
"""

from enum import Enum
from typing import Dict, List, Optional, Type, Union


class InstrumentoConvocatorio(Enum):
    EDITAL = 1
    AVISO_CONTRATACAO_DIRETA = 2
    ATO_QUE_AUTORIZA_CONTRATACAO_DIRETA = 3


class ModalidadeContratacao(Enum):
    LEILAO_ELETRONICO = 1
    DIALOGO_COMPETITIVO = 2
    CONCURSO = 3
    CONCORRENCIA_ELETRONICA = 4
    CONCORRENCIA_PRESENCIAL = 5
    PREGAO_ELETRONICO = 6
    PREGAO_PRESENCIAL = 7
    DISPENSA_DE_LICITACAO = 8
    INEXIGIBILIDADE = 9
    MANIFESTACAO_DE_INTERESSE = 10
    PRE_QUALIFICACAO = 11
    CREDENCIAMENTO = 12
    LEILAO_PRESENCIAL = 13


class ModoDisputa(Enum):
    ABERTO = 1
    FECHADO = 2
    ABERTO_FECHADO = 3
    DISPENSA_COM_DISPUTA = 4
    NAO_SE_APLICA = 5
    FECHADO_ABERTO = 6


class CriterioJulgamento(Enum):
    MENOR_PRECO = 1
    MAIOR_DESCONTO = 2
    TECNICA_E_PRECO = 4
    MAIOR_LANCE = 5
    MAIOR_RETORNO_ECONOMICO = 6
    NAO_SE_APLICA = 7
    MELHOR_TECNICA = 8
    CONTEUDO_ARTISTICO = 9


class SituacaoContratacao(Enum):
    DIVULGADA_NO_PNCP = 1
    REVOGADA = 2
    ANULADA = 3
    SUSPENSA = 4


class SituacaoItemContratacao(Enum):
    EM_ANDAMENTO = 1
    HOMOLOGADO = 2
    ANULADO_REVOGADO_CANCELADO = 3
    DESERTO = 4
    FRACASSADO = 5


class TipoBeneficio(Enum):
    PARTICIPACAO_EXCLUSIVA_ME_EPP = 1
    SUBCONTRATACAO_PARA_ME_EPP = 2
    COTA_RESERVADA_PARA_ME_EPP = 3
    SEM_BENEFICIO = 4
    NAO_SE_APLICA = 5


class SituacaoResultadoItemContratacao(Enum):
    INFORMADO = 1
    CANCELADO = 2


class TipoContrato(Enum):
    CONTRATO = 1
    COMODATO = 2
    ARRENDAMENTO = 3
    CONCESSAO = 4
    TERMO_DE_ADESAO = 5
    CONVENIO = 6
    EMPENHO = 7
    OUTROS = 8
    TERMO_DE_EXECUCAO_DESCENTRALIZADA = 9
    ACORDO_DE_COOPERACAO_TECNICA = 10
    TERMO_DE_COMPROMISSO = 11
    CARTA_CONTRATO = 12


class TipoTermoContrato(Enum):
    TERMO_DE_RESCISAO = 1
    TERMO_ADITIVO = 2
    TERMO_DE_APOSTILamento = 3


class CategoriaProcesso(Enum):
    CESSAO = 1
    COMPRAS = 2
    INFORMATICA_TIC = 3
    INTERNACIONAL = 4
    LOCACAO_IMOVEIS = 5
    MAO_DE_OBRA = 6
    OBRAS = 7
    SERVICOS = 8
    SERVICOS_DE_ENGENHARIA = 9
    SERVICOS_DE_SAUDE = 10
    ALIENACAO_DE_BENS_MOVEIS_IMOVEIS = 11


class TipoDocumento(Enum):
    AVISO_CONTRATACAO_DIRETA = 1
    EDITAL = 2
    MINUTA_CONTRATO = 3
    TERMO_REFERENCIA = 4
    ANTEPROJETO = 5
    PROJETO_BASICO = 6
    ESTUDO_TECNICO_PRELIMINAR = 7
    PROJETO_EXECUTIVO = 8
    MAPA_RISCOS = 9
    DFD = 10
    ATA_REGISTRO_PRECO = 11
    CONTRATO = 12
    TERMO_RESCISAO = 13
    TERMO_ADITIVO = 14
    TERMO_APOSTILAMENTO = 15
    OUTROS = 16
    NOTA_EMPENHO = 17
    RELATORIO_FINAL_CONTRATO = 18


class NaturezaJuridica(Enum):
    NAO_INFORMADA = 0
    ORGAO_PUBLICO_EXECUTIVO_FEDERAL = 1015
    ORGAO_PUBLICO_EXECUTIVO_ESTADUAL_DF = 1023
    ORGAO_PUBLICO_EXECUTIVO_MUNICIPAL = 1031
    ORGAO_PUBLICO_LEGISLATIVO_FEDERAL = 1040
    ORGAO_PUBLICO_LEGISLATIVO_ESTADUAL_DF = 1058
    ORGAO_PUBLICO_LEGISLATIVO_MUNICIPAL = 1066
    ORGAO_PUBLICO_JUDICIARIO_FEDERAL = 1074
    ORGAO_PUBLICO_JUDICIARIO_ESTADUAL = 1082
    AUTARQUIA_FEDERAL = 1104
    AUTARQUIA_ESTADUAL_DF = 1112
    AUTARQUIA_MUNICIPAL = 1120
    FUNDACAO_PUBLICA_DIREITO_PUBLICO_FEDERAL = 1139
    FUNDACAO_PUBLICA_DIREITO_PUBLICO_ESTADUAL_DF = 1147
    FUNDACAO_PUBLICA_DIREITO_PUBLICO_MUNICIPAL = 1155
    ORGAO_PUBLICO_AUTONOMO_FEDERAL = 1163
    ORGAO_PUBLICO_AUTONOMO_ESTADUAL_DF = 1171
    ORGAO_PUBLICO_AUTONOMO_MUNICIPAL = 1180
    COMISSAO_POLINACIONAL = 1198
    CONSORCIO_PUBLICO_DIREITO_PUBLICO = 1210
    CONSORCIO_PUBLICO_DIREITO_PRIVADO = 1228
    ESTADO_DF = 1236
    MUNICIPIO = 1244
    FUNDACAO_PUBLICA_DIREITO_PRIVADO_FEDERAL = 1252
    FUNDACAO_PUBLICA_DIREITO_PRIVADO_ESTADUAL_DF = 1260
    FUNDACAO_PUBLICA_DIREITO_PRIVADO_MUNICIPAL = 1279
    FUNDO_PUBLICO_ADMINISTRACAO_INDIRETA_FEDERAL = 1287
    FUNDO_PUBLICO_ADMINISTRACAO_INDIRETA_ESTADUAL_DF = 1295
    FUNDO_PUBLICO_ADMINISTRACAO_INDIRETA_MUNICIPAL = 1309
    FUNDO_PUBLICO_ADMINISTRACAO_DIRETA_FEDERAL = 1317
    FUNDO_PUBLICO_ADMINISTRACAO_DIRETA_ESTADUAL_DF = 1325
    FUNDO_PUBLICO_ADMINISTRACAO_DIRETA_MUNICIPAL = 1333
    UNIAO = 1341
    EMPRESA_PUBLICA = 2011
    SOCIEDADE_ECONOMIA_MISTA = 2038
    SOCIEDADE_ANONIMA_ABERTA = 2046
    SOCIEDADE_ANONIMA_FECHADA = 2054


class PorteEmpresa(Enum):
    ME = 1
    EPP = 2
    DEMAIS = 3
    NAO_SE_APLICA = 4
    NAO_INFORMADO = 5


class AmparoLegal(Enum):
    LEI_14133_ART_28_I = 1
    LEI_14133_ART_28_II = 2
    LEI_14133_ART_28_III = 3
    LEI_14133_ART_28_IV = 4
    LEI_14133_ART_28_V = 5
    LEI_14133_ART_74_I = 6
    LEI_14133_ART_74_II = 7
    LEI_14133_ART_74_III_A = 8
    LEI_14133_ART_74_III_B = 9
    LEI_14133_ART_74_III_C = 10
    LEI_14133_ART_74_III_D = 11
    LEI_14133_ART_74_III_E = 12
    LEI_14133_ART_74_III_F = 13
    LEI_14133_ART_74_III_G = 14
    LEI_14133_ART_74_III_H = 15
    LEI_14133_ART_74_IV = 16
    LEI_14133_ART_74_V = 17
    LEI_14133_ART_75_I = 18
    LEI_14133_ART_75_II = 19
    LEI_14133_ART_75_III_A = 20
    LEI_14133_ART_75_III_B = 21
    LEI_14133_ART_75_IV_A = 22
    LEI_14133_ART_75_IV_B = 23
    LEI_14133_ART_75_IV_C = 24
    LEI_14133_ART_75_IV_D = 25
    LEI_14133_ART_75_IV_E = 26
    LEI_14133_ART_75_IV_F = 27
    LEI_14133_ART_75_IV_G = 28


class CategoriaItemPlanoContratacoes(Enum):
    MATERIAL = 1
    SERVICO = 2
    OBRAS = 3
    SERVICOS_DE_ENGENHARIA = 4
    SOLUCOES_DE_TIC = 5
    LOCACAO_DE_IMOVEIS = 6
    ALIENACAO_CONCESSAO_PERMISSAO = 7
    OBRAS_E_SERVICOS_DE_ENGENHARIA = 8


# Enum utilities
def get_enum_by_value(enum_class: Type[Enum], value: Union[int, str]) -> Optional[Enum]:
    """Get enum member by value, returning None if not found."""
    try:
        return enum_class(value)
    except ValueError:
        return None


def get_enum_name_by_value(enum_class: Type[Enum], value: Union[int, str]) -> Optional[str]:
    """Get enum member name by value, returning None if not found."""
    enum_member = get_enum_by_value(enum_class, value)
    return enum_member.name if enum_member else None


def validate_enum_value(enum_class: Type[Enum], value: Union[int, str]) -> bool:
    """Validate that a value exists in the enum."""
    return get_enum_by_value(enum_class, value) is not None


def get_enum_values(enum_class: Type[Enum]) -> List[int]:
    """Get all values from an enum class."""
    return [member.value for member in enum_class]


def get_enum_choices(enum_class: Type[Enum]) -> Dict[int, str]:
    """Get all enum values with their names as a dictionary."""
    return {member.value: member.name for member in enum_class}


def get_enum_description(enum_class: Type[Enum], value: Union[int, str]) -> str:
    """Get a human-readable description of an enum value."""
    enum_member = get_enum_by_value(enum_class, value)
    if not enum_member:
        return f"Unknown {enum_class.__name__} value: {value}"
    
    # Convert enum name to human-readable format
    name = enum_member.name.replace('_', ' ').title()
    return f"{name} ({enum_member.value})"


# Enum registry for dynamic access
ENUM_REGISTRY = {
    'InstrumentoConvocatorio': InstrumentoConvocatorio,
    'ModalidadeContratacao': ModalidadeContratacao,
    'ModoDisputa': ModoDisputa,
    'CriterioJulgamento': CriterioJulgamento,
    'SituacaoContratacao': SituacaoContratacao,
    'SituacaoItemContratacao': SituacaoItemContratacao,
    'TipoBeneficio': TipoBeneficio,
    'SituacaoResultadoItemContratacao': SituacaoResultadoItemContratacao,
    'TipoContrato': TipoContrato,
    'TipoTermoContrato': TipoTermoContrato,
    'CategoriaProcesso': CategoriaProcesso,
    'TipoDocumento': TipoDocumento,
    'NaturezaJuridica': NaturezaJuridica,
    'PorteEmpresa': PorteEmpresa,
    'AmparoLegal': AmparoLegal,
    'CategoriaItemPlanoContratacoes': CategoriaItemPlanoContratacoes,
}


def get_enum_by_name(enum_name: str) -> Optional[Type[Enum]]:
    """Get enum class by name."""
    return ENUM_REGISTRY.get(enum_name)


def get_all_enum_metadata() -> Dict[str, Dict[str, Union[str, List[Dict[str, Union[int, str]]]]]]:
    """Get metadata for all enums in the registry."""
    metadata = {}
    
    for enum_name, enum_class in ENUM_REGISTRY.items():
        metadata[enum_name] = {
            'name': enum_name,
            'description': f"Enum for {enum_name.replace('_', ' ').lower()}",
            'values': [
                {
                    'value': member.value,
                    'name': member.name,
                    'description': get_enum_description(enum_class, member.value)
                }
                for member in enum_class
            ]
        }
    
    return metadata
</file>

<file path="src/baliza/mcp.py">
# This file is deprecated and will be removed.
# The MCP logic is now handled by `mcp_server.py`.
</file>

<file path="src/baliza/pncp_writer.py">
import asyncio
import json
import logging
from datetime import date
from pathlib import Path
from typing import Any, Dict, List

import duckdb
from filelock import FileLock, Timeout
from rich.console import Console

logger = logging.getLogger(__name__)
console = Console(force_terminal=True, legacy_windows=False, stderr=False)


# Data directory
DATA_DIR = Path.cwd() / "data"
BALIZA_DB_PATH = DATA_DIR / "baliza.duckdb"


def connect_utf8(path: str) -> duckdb.DuckDBPyConnection:
    """Connect to DuckDB with UTF-8 error handling."""
    try:
        return duckdb.connect(path)
    except duckdb.Error as exc:
        # redecodifica string problema (CP‑1252 → UTF‑8)
        msg = (
            str(exc).encode("latin1", errors="ignore").decode("utf-8", errors="replace")
        )
        # Para DuckDB, usamos RuntimeError com a mensagem corrigida
        raise RuntimeError(msg) from exc


class PNCPWriter:
    """Handles writing PNCP data to DuckDB."""

    def __init__(self):
        self.conn: duckdb.DuckDBPyConnection | None = None
        self.db_lock: FileLock | None = None
        self.writer_running = False

    async def __aenter__(self):
        """Async context manager entry."""
        self._init_database()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit with graceful cleanup."""
        if self.conn:
            try:
                self.conn.commit()  # Commit any pending changes
                self.conn.close()
            except (duckdb.Error, AttributeError) as db_err:
                logger.warning(f"Error during database cleanup: {db_err}")

        if self.db_lock:
            try:
                self.db_lock.release()
            except (Timeout, RuntimeError) as lock_err:
                logger.warning(f"Error releasing database lock: {lock_err}")

    def _init_database(self):
        """Initialize DuckDB with PSA schema."""
        DATA_DIR.mkdir(parents=True, exist_ok=True)

        self.db_lock = FileLock(str(BALIZA_DB_PATH) + ".lock")
        try:
            self.db_lock.acquire(timeout=0.5)
        except Timeout:
            raise RuntimeError("Outra instância está usando pncp_new.db")

        self.conn = connect_utf8(str(BALIZA_DB_PATH))

        # Create PSA schema
        self.conn.execute("CREATE SCHEMA IF NOT EXISTS psa")

        # Create raw responses table with ZSTD compression for response_content
        self.conn.execute(
            """
            CREATE TABLE IF NOT EXISTS psa.pncp_raw_responses (
                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                endpoint_url VARCHAR NOT NULL,
                endpoint_name VARCHAR NOT NULL,
                request_parameters JSON,
                response_code INTEGER NOT NULL,
                response_content TEXT,
                response_headers JSON,
                data_date DATE,
                run_id VARCHAR,
                total_records INTEGER,
                total_pages INTEGER,
                current_page INTEGER,
                page_size INTEGER
            ) WITH (compression = "zstd")
        """
        )

        # Create the new control table
        self.conn.execute("DROP TABLE IF EXISTS psa.pncp_extraction_tasks")
        self.conn.execute(
            """
            CREATE TABLE psa.pncp_extraction_tasks (
                task_id VARCHAR PRIMARY KEY,
                endpoint_name VARCHAR NOT NULL,
                data_date DATE NOT NULL,
                modalidade INTEGER,
                status VARCHAR DEFAULT 'PENDING' NOT NULL,
                total_pages INTEGER,
                total_records INTEGER,
                missing_pages JSON,
                last_error TEXT,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
                updated_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
                CONSTRAINT unique_task UNIQUE (endpoint_name, data_date, modalidade)
            );
        """
        )

        # Create indexes if they don't exist
        self._create_indexes_if_not_exist()

        # Migrate existing table to use ZSTD compression
        self._migrate_to_zstd_compression()

    def _index_exists(self, index_name: str) -> bool:
        """Check if a given index exists in the database."""
        try:
            # Query information_schema to check if index exists
            result = self.conn.execute(
                "SELECT 1 FROM information_schema.indexes WHERE index_name = ?",
                [index_name],
            ).fetchone()
            return result is not None
        except duckdb.Error:
            # Fallback: try to create the index and catch the error
            try:
                self.conn.execute(
                    f"CREATE INDEX IF NOT EXISTS {index_name}_test ON psa.pncp_raw_responses(endpoint_name)"
                )
                self.conn.execute(f"DROP INDEX IF EXISTS {index_name}_test")
                return False  # If we can create a test index, the target doesn't exist
            except duckdb.Error:
                return True  # If we can't create test index, assume target exists

    def _create_indexes_if_not_exist(self):
        """Create indexes only if they do not already exist."""
        indexes_to_create = {
            "idx_endpoint_date_page": "CREATE INDEX IF NOT EXISTS idx_endpoint_date_page ON psa.pncp_raw_responses(endpoint_name, data_date, current_page)",
            "idx_response_code": "CREATE INDEX IF NOT EXISTS idx_response_code ON psa.pncp_raw_responses(response_code)",
        }

        for idx_name, create_sql in indexes_to_create.items():
            try:
                self.conn.execute(create_sql)
                logger.info(f"Index '{idx_name}' ensured.")
            except duckdb.Error as e:
                logger.exception(f"Failed to create index '{idx_name}': {e}")

    def _migrate_to_zstd_compression(self):
        """Migrate existing table to use ZSTD compression for better storage efficiency."""
        try:
            # Check if table exists and has data
            table_exists = (
                self.conn.execute(
                    "SELECT COUNT(*) FROM information_schema.tables WHERE table_name = 'pncp_raw_responses' AND table_schema = 'psa'"
                ).fetchone()[0]
                > 0
            )

            if not table_exists:
                return  # Table doesn't exist yet, will be created with ZSTD

            # Check if migration already happened by looking for a marker
            try:
                marker_exists = (
                    self.conn.execute(
                        "SELECT COUNT(*) FROM psa.pncp_raw_responses WHERE run_id = 'ZSTD_MIGRATION_MARKER'"
                    ).fetchone()[0]
                    > 0
                )

                if marker_exists:
                    return  # Migration already completed

            except (duckdb.Error, AttributeError) as db_err:
                logger.debug(
                    "Table might not exist or have run_id column yet", error=str(db_err)
                )

            # Check if table already has ZSTD compression by attempting to create a duplicate
            try:
                self.conn.execute(
                    """
                    CREATE TABLE psa.pncp_raw_responses_zstd (
                        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                        extracted_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        endpoint_url VARCHAR NOT NULL,
                        endpoint_name VARCHAR NOT NULL,
                        request_parameters JSON,
                        response_code INTEGER NOT NULL,
                        response_content TEXT,
                        response_headers JSON,
                        data_date DATE,
                        run_id VARCHAR,
                        total_records INTEGER,
                        total_pages INTEGER,
                        current_page INTEGER,
                        page_size INTEGER
                    ) WITH (compression = "zstd")
                """
                )

                # Check if we have data to migrate
                row_count = self.conn.execute(
                    "SELECT COUNT(*) FROM psa.pncp_raw_responses"
                ).fetchone()[0]

                if row_count > 0:
                    console.print(
                        f"🗜️ Migrating {row_count:,} rows to ZSTD compression..."
                    )

                    # Copy data to new compressed table
                    self.conn.execute(
                        """
                        INSERT INTO psa.pncp_raw_responses_zstd
                        SELECT * FROM psa.pncp_raw_responses
                    """
                    )

                    # Add migration marker
                    self.conn.execute(
                        """
                        INSERT INTO psa.pncp_raw_responses_zstd
                        (endpoint_url, endpoint_name, request_parameters, response_code, response_content, response_headers, run_id)
                        VALUES ('MIGRATION_MARKER', 'ZSTD_MIGRATION', '{}', 0, 'Migration completed', '{}', 'ZSTD_MIGRATION_MARKER')
                    """
                    )

                    # Drop old table and rename new one
                    self.conn.execute("DROP TABLE psa.pncp_raw_responses")
                    self.conn.execute(
                        "ALTER TABLE psa.pncp_raw_responses_zstd RENAME TO pncp_raw_responses"
                    )

                    # Recreate indexes
                    self.conn.execute(
                        "CREATE INDEX idx_endpoint_date_page ON psa.pncp_raw_responses(endpoint_name, data_date, current_page)"
                    )
                    self.conn.execute(
                        "CREATE INDEX idx_response_code ON psa.pncp_raw_responses(response_code)"
                    )

                    self.conn.commit()
                    console.print("Successfully migrated to ZSTD compression")
                else:
                    # No data to migrate, just replace table
                    self.conn.execute("DROP TABLE psa.pncp_raw_responses")
                    self.conn.execute(
                        "ALTER TABLE psa.pncp_raw_responses_zstd RENAME TO pncp_raw_responses"
                    )
                    console.print("Empty table replaced with ZSTD compression")

            except duckdb.Error as create_error:
                # If table already exists with ZSTD, clean up
                with contextlib.suppress(duckdb.Error):
                    self.conn.execute("DROP TABLE psa.pncp_raw_responses_zstd")

                # This likely means the table already has ZSTD or migration already happened
                if "already exists" in str(create_error):
                    pass  # Expected, migration already done
                else:
                    raise

        except duckdb.Error as e:
            console.print(f"⚠️ ZSTD migration error: {e}")
            # Rollback on error
            with contextlib.suppress(duckdb.Error):
                self.conn.rollback()

    def _batch_store_responses(self, responses: List[Dict[str, Any]]):
        """Store multiple responses in a single batch operation with transaction."""
        if not responses:
            return

        # Prepare batch data
        batch_data = []
        for resp in responses:
            batch_data.append(
                [
                    resp["endpoint_url"],
                    resp["endpoint_name"],
                    json.dumps(resp["request_parameters"]),
                    resp["response_code"],
                    resp["response_content"],
                    json.dumps(resp["response_headers"]),
                    resp["data_date"],
                    resp["run_id"],
                    resp["total_records"],
                    resp["total_pages"],
                    resp["current_page"],
                    resp["page_size"],
                ]
            )

        # Batch insert with transaction
        self.conn.execute("BEGIN TRANSACTION")
        try:
            self.conn.executemany(
                """
                INSERT INTO psa.pncp_raw_responses (
                    endpoint_url, endpoint_name, request_parameters,
                    response_code, response_content, response_headers,
                    data_date, run_id, total_records, total_pages,
                    current_page, page_size
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                batch_data,
            )
            self.conn.execute("COMMIT")
        except duckdb.Error as e:
            self.conn.execute("ROLLBACK")
            logger.error(f"Batch store failed: {e}")
            raise

    async def writer_worker(self, page_queue: asyncio.Queue, commit_every: int = 75) -> None:
        """Dedicated writer coroutine for single-threaded DB writes.

        Optimized for:
        - commit_every=75 pages ≈ 5-8 seconds between commits
        - Reduces I/O overhead by 7.5x (10→75 pages per commit)
        - Local batch buffer minimizes executemany() calls
        """
        counter = 0
        batch_buffer = []

        while True:
            try:
                # Get page from queue (None is sentinel to stop)
                page = await page_queue.get()
                if page is None:
                    break

                # Add to local buffer
                batch_buffer.append(page)
                counter += 1

                # Flush buffer every commit_every pages
                if counter % commit_every == 0 and batch_buffer:
                    self._batch_store_responses(batch_buffer)
                    self.conn.commit()
                    batch_buffer.clear()

                # Mark task as done
                page_queue.task_done()

            except duckdb.Error as e:
                console.print(f"❌ Writer error: {e}")
                page_queue.task_done()
                break

        # Flush any remaining items
        if batch_buffer:
            self._batch_store_responses(batch_buffer)
            self.conn.commit()

        self.writer_running = False

    def get_raw_content(self, endpoint_name: str, data_date: date, page: int) -> str:
        """Retrieve raw JSON content from database."""
        result = self.conn.execute(
            """
            SELECT response_content FROM psa.pncp_raw_responses
            WHERE endpoint_name = ? AND data_date = ? AND current_page = ? AND response_code = 200
            LIMIT 1
        """,
            [endpoint_name, data_date, page],
        ).fetchone()

        if not result:
            raise ValueError(f"Page not found: {endpoint_name}, {data_date}, {page}")

        return result[0]

    def __del__(self):
        """Cleanup."""
        if hasattr(self, "conn"):
            self.conn.close()
</file>

<file path="src/baliza/utils.py">
"""Utility functions for the baliza package."""

import json
import logging
from typing import Any

import orjson

logger = logging.getLogger(__name__)


def parse_json_robust(content: str) -> Any:
    """Parse JSON with orjson (fast) and fallback to stdlib json for edge cases."""
    try:
        return orjson.loads(content)
    except orjson.JSONDecodeError as e:
        logger.warning(f"orjson failed to parse JSON, falling back to standard json: {e}")
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON with both orjson and standard json: {e}")
            raise
</file>

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(uv run:*)",
      "Bash(set PYTHONIOENCODING=utf-8)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(taskkill:*)",
      "Bash(wmic:*)",
      "Bash(*)",
      "Bash(ls:*)",
      "Bash(dbt:*)",
      "Bash(git checkout:*)",
      "Bash(git merge:*)",
      "Bash(git push:*)"
    ],
    "deny": []
  }
}
</file>

<file path="docs/openapi/MANUAL-PNCP-CONSULSTAS-VERSAO-1.md">
> Este manualf oi convertido para markdown por LLM a partir do original em: https://www.gov.br/pncp/pt-br/central-de-conteudo/manuais/versoes-anteriores/ManualPNCPAPIConsultasVerso1.0.pdf


# Manual das APIs de Consultas PNCP

## Sumário

1. Objetivo
2. Protocolo de Comunicação
3. Acesso ao PNCP
    3.1. Endereços de Acesso
4. Recomendações Iniciais
    4.1. Composição do Número de Controle PNCP de PCA/Contratação/Ata/Contrato
        * Número de Controle do PCA
        * Número de Controle da Contratação
        * Número de Controle da Ata
        * Número de Controle do Contrato
    4.2. Dados de Retorno padronizados
5. Tabelas de Domínio
    5.1. Instrumento Convocatório
    5.2. Modalidade de Contratação
    5.3. Modo de Disputa
    5.4. Critério de Julgamento
    5.5. Situação da Contratação
    5.6. Situação do Item da Contratação
    5.7. Tipo de Benefício
    5.8. Situação do Resultado do Item da Contratação
    5.9. Tipo de Contrato
    5.10. Tipo de Termo de Contrato
    5.11. Categoria do Processo
    5.12. Tipo de Documento
    5.13. Natureza Jurídica
    5.14. Porte da Empresa
    5.15. Amparo Legal
    5.16. Categoria do Item do Plano de Contratações
    5.17. Identificador de Usuário
6. Catálogo de Serviços (APIs)
    6.1. Consultar Itens de PCA por Ano, idUsuario e Classificação Superior
    6.2. Consultar Itens de PCA por Ano e Classificação Superior
    6.3. Serviço Consultar Contratações por Data de Publicação
    6.4. Serviço Consultar Contratações com Período de Recebimento de Propostas em Aberto
    6.5. Serviço Consultar Atas de Registro de Preço por Período de Vigência
    6.6. Serviço Consultar Contratos por Data de Publicação
7. Suporte
8. Glossário

---

## 1. Objetivo

Este documento contempla as orientações para consultas aos dados de contratações, alienação de bens móveis e imóveis, atas de registro de preços e contratos realizados no âmbito da Lei nº 14.133/2021.

---

## 2. Protocolo de Comunicação

As consultas serão realizadas por meio de API (Application Programme Interface) que utiliza o protocolo de comunicação REST - Representational State Transfer/ HTTP 1.1 cujos dados trafegados utilizam a notação JSON - JavaScript Object Notation.

---

## 3. Acesso ao PNCP

### 3.1. Endereços de Acesso

A invocação dos serviços será realizada através das URLs citadas abaixo, conforme requisitos de segurança detalhados na seção seguinte.

**Ambiente de Produtivo**

*   **Portal:** https://pncp.gov.br
*   **Documentação Técnica (Serviços):** https://pncp.gov.br/api/consulta/swagger-ui/index.html
*   **Serviços (${BASE_URL}):** https://pncp.gov.br/api/consulta

*Nota: ${BASE_URL} será utilizada nos exemplos de requisições citados neste documento. É a URL base para acesso aos serviços disponíveis no PNCP.*

---

## 4. Recomendações Iniciais

### 4.1. Composição do Número de Controle PNCP de PCA/Contratação/Ata/Contrato

O PNCP gera automaticamente um identificador, que é um número de controle, no qual utiliza-se para reconhecer todas as demais transações realizadas para aquele registro.

Atualmente encontram-se disponíveis: plano de contratações anual (PCA), contratação (licitação ou contratação direta), ata de registro de preços ou contrato, conforme a composição abaixo:

#### Número de Controle do PCA

(id pca pncp) (Máscara: 99999999999999-0-999999/9999.)

Cada PCA receberá um número de controle composto por:

*   CNPJ do Órgão/Entidade do PCA (14 dígitos)
*   Dígito "0" - marcador que indica tratar-se de um plano de contratação anual
*   Número sequencial do Plano no PNCP\*
*   Ano do Plano (4 dígitos)

#### Número de Controle da Contratação

(id contratação pncp) (Máscara: 99999999999999-1-999999/9999.)

Cada contratação receberá um número de controle composto por:

*   CNPJ do Órgão/Entidade da contratação (14 dígitos)
*   Dígito "1" - marcador que indica tratar-se de uma contratação
*   Número sequencial da contratação no PNCP \*
*   Ano da contratação (4 dígitos)

#### Número de Controle da Ata

(id ata pncp) (Máscara: 99999999999999-1-999999/9999-999999.)

Cada ata receberá um número de controle composto por:

*   Número de Controle PNCP da Contratação (24 dígitos)
*   Número sequencial da ata no PNCP \*

#### Número de Controle do Contrato

(id contrato pncp) (Máscara: 99999999999999-2-999999/9999.)

Cada contrato receberá um número de controle composto por:

*   CNPJ do Órgão/Entidade do Contrato (14 dígitos)
*   Dígito "2" - marcador que indica tratar-se de um contrato
*   Número sequencial do contrato no PNCP \*
*   Ano do contrato (4 dígitos)

\*O número PNCP será gerado sequencialmente com 6 dígitos e reiniciado a cada mudança de ano.

### 4.2. Dados de Retorno padronizados

Ao realizar consultas para obter dados do Planos Anuais de Contratações – PCA e Contratações, a API realizará o procedimento de busca por esses dados e ao final será retornado o total de registros encontrados, o total de páginas necessárias para a obtenção de todos os registros, o número da página que a consulta foi realizada e o total de páginas restantes.

Essas informações são essenciais para tornar a entrega dos dados mais rápida possível, evitando demora ou até mesmo interrupção da entrega dos pacotes contendo os a informações solicitadas por parte do servidor de arquivos do PNCP.

**Dados de retorno**

| Id | Campo                    | Tipo    | Descrição                                                                                                   |
|----|--------------------------|---------|-------------------------------------------------------------------------------------------------------------|
| 1  | data                     | Vetor   | Vetor com os dados dos registros encontrados                                                                  |
| 2  | totalRegistros           | Inteiro | Total de registros encontrados                                                                                |
| 3  | totalPaginas             | Inteiro | Total de páginas necessárias para a obtenção de todos os registros                                             |
| 4  | numeroPagina             | Inteiro | Número da página que a consulta foi realizada                                                               |
| 5  | paginasRestantes         | Inteiro | Total de páginas restantes                                                                                  |
| 6  | empty                    | Boleano | Indicador se o atributo data está vazio                                                                     |

---

## 5. Tabelas de Domínio

A seguir são encontradas informações sobre as tabelas de domínio, ou seja, listas dados de interesse que contem valores fixos, usados em várias consultas que tem o intuito de auxiliar na realização e consultas.

### 5.1. Instrumento Convocatório

*   (código = 1) Edital: Instrumento convocatório utilizado no diálogo competitivo, concurso, concorrência, pregão, manifestação de interesse, pré-qualificação e credenciamento.
*   (código = 2) Aviso de Contratação Direta: Instrumento convocatório utilizado na Dispensa com Disputa.
*   (código = 3) Ato que autoriza a Contratação Direta: Instrumento convocatório utilizado na Dispensa sem Disputa ou na Inexigibilidade.

### 5.2. Modalidade de Contratação

*   (código = 1) Leilão - Eletrônico
*   (código = 2) Diálogo Competitivo
*   (código = 3) Concurso
*   (código = 4) Concorrência - Eletrônica
*   (código = 5) Concorrência - Presencial
*   (código = 6) Pregão - Eletrônico
*   (código = 7) Pregão - Presencial
*   (código = 8) Dispensa de Licitação
*   (código = 9) Inexigibilidade
*   (código = 10) Manifestação de Interesse
*   (código = 11) Pré-qualificação
*   (código = 12) Credenciamento
*   (código = 13) Leilão - Presencial

### 5.3. Modo de Disputa

*   (código = 1) Aberto
*   (código = 2) Fechado
*   (código = 3) Aberto-Fechado
*   (código = 4) Dispensa Com Disputa
*   (código = 5) Não se aplica
*   (código = 6) Fechado-Aberto

### 5.4. Critério de Julgamento

*   (código = 1) Menor preço
*   (código = 2) Maior desconto
*   (código = 4) Técnica e preço
*   (código = 5) Maior lance
*   (código = 6) Maior retorno econômico
*   (código = 7) Não se aplica
*   (código = 8) Melhor técnica
*   (código = 9) Conteúdo artístico

---

## 5.5. Situação da Contratação

*   (código = 1) Divulgada no PNCP: Contratação divulgada no PNCP. Situação atribuída na inclusão da contratação.
*   (código = 2) Revogada: Contratação revogada conforme justificativa.
*   (código = 3) Anulada: Contratação revogada conforme justificativa.
*   (código = 4) Suspensa: Contratação suspensa conforme justificativa.

---

## 5.6. Situação do Item da Contratação

*   (código = 1) Em Andamento: Item com disputa/seleção do fornecedor/arrematante não finalizada. Situação atribuída na inclusão do item da contratação
*   (código = 2) Homologado: Item com resultado (fornecedor/arrematante informado)
*   (código = 3) Anulado/Revogado/Cancelado: Item cancelado conforme justificativa
*   (código = 4) Deserto: Item sem resultado (sem fornecedores/arrematantes interessados)
*   (código = 5) Fracassado: Item sem resultado (fornecedores/arrematantes desclassificados ou inabilitados)

---

## 5.7. Tipo de Benefício

*   (código = 1) Participação exclusiva para ME/EPP
*   (código = 2) Subcontratação para ME/EPP
*   (código = 3) Cota reservada para ME/EPP
*   (código = 4) Sem benefício
*   (código = 5) Não se aplica

---

## 5.8. Situação do Resultado do Item da Contratação

*   (código = 1) Informado: Que possui valor e fornecedor e marca oriundo do resultado da contratação. Situação atribuída na inclusão do resultado do item da contratação.
*   (código = 2) Cancelado: Resultado do item cancelado conforme justificativa.

---

## 5.9. Tipo de Contrato

*   (código = 1) Contrato (termo inicial): Acordo formal recíproco de vontades firmado entre as partes
*   (código = 2) Comodato: Contrato de concessão de uso gratuito de bem móvel ou imóvel
*   (código = 3) Arrendamento: Contrato de cessão de um bem por um determinado período mediante pagamento
*   (código = 4) Concessão: Contrato firmado com empresa privada para execução de serviço público sendo remunerada por tarifa
*   (código = 5) Termo de Adesão: Contrato em que uma das partes estipula todas as cláusulas sem a outra parte poder modificá-las
*   (código = 6) Convênio: Acordos firmados entre as partes buscando a realização de um objetivo em comum
*   (código = 7) Empenho: É uma promessa de pagamento por parte do Estado para um fim específico
*   (código = 8) Outros: Outros tipos de contratos que não os listados
*   (código = 9) Termo de Execução Descentralizada (TED): Instrumento utilizado para a descentralização de crédito entre órgãos/entidades da União
*   (código = 10) Acordo de Cooperação Técnica (ACT): Acordos firmados entre órgãos visando a execução de programas de trabalho ou projetos
*   (código = 11) Termo de Compromisso: Acordo firmado para cumprir compromisso estabelecido entre as partes
*   (código = 12) Carta Contrato: Documento que formaliza e ratifica acordo entre duas ou mais partes nas hipóteses em que a lei dispensa a celebração de um contrato

---

## 5.10. Tipo de Termo de Contrato

*   (código = 1) Termo de Rescisão: Encerramento é antes da data final do contrato.
*   (código = 2) Termo Aditivo: Atualiza o contrato como um todo, podendo prorrogar, reajustar, acrescer, suprimir, alterar cláusulas e reajustar.
*   (código = 3) Termo de Apostilamento: Atualiza o valor do contrato.

---

## 5.11. Categoria do Processo

*   (código = 1) Cessão
*   (código = 2) Compras
*   (código = 3) Informática (TIC)
*   (código = 4) Internacional
*   (código = 5) Locação Imóveis
*   (código = 6) Mão de Obra
*   (código = 7) Obras
*   (código = 8) Serviços
*   (código = 9) Serviços de Engenharia
*   (código = 10) Serviços de Saúde
*   (código = 11) Alienação de bens móveis/imóveis

---

## 5.12. Tipo de Documento

**Tipos de documentos da contratação:**

*   (código = 1) Aviso de Contratação Direta
*   (código = 2) Edital
*   **Outros anexos:**
    *   (código = 3) Minuta do Contrato
    *   (código = 4) Termo de Referência
    *   (código = 5) Anteprojeto
    *   (código = 6) Projeto Básico
    *   (código = 7) Estudo Técnico Preliminar
    *   (código = 8) Projeto Executivo
    *   (código = 9) Mapa de Riscos
    *   (código = 10) DFD

**Tipos de documentos da ata de registro de preço:**

*   (código = 11) Ata de Registro de Preço

**Tipos de documentos de contrato:**

*   (código = 12) Contrato
*   (código = 13) Termo de Rescisão
*   (código = 14) Termo Aditivo
*   (código = 15) Termo de Apostilamento
*   (código = 17) Nota de Empenho
*   (código = 18) Relatório Final de Contrato

\*\* Para outros documentos do processo usar o código 16.

---

## 5.13. Natureza Jurídica

**Código - Natureza jurídica**

*   0000 - Natureza Jurídica não informada
*   1015 - Órgão Público do Poder Executivo Federal
*   1023 - Órgão Público do Poder Executivo Estadual ou do Distrito Federal
*   1031 - Órgão Público do Poder Executivo Municipal
*   1040 - Órgão Público do Poder Legislativo Federal
*   1058 - Órgão Público do Poder Legislativo Estadual ou do Distrito Federal
*   1066 - Órgão Público do Poder Legislativo Municipal
*   1074 - Órgão Público do Poder Judiciário Federal
*   1082 - Órgão Público do Poder Judiciário Estadual
*   1104 - Autarquia Federal
*   1112 - Autarquia Estadual ou do Distrito Federal
*   1120 - Autarquia Municipal
*   1139 - Fundação Pública de Direito Público Federal
*   1147 - Fundação Pública de Direito Público Estadual ou do Distrito Federal
*   1155 - Fundação Pública de Direito Público Municipal
*   1163 - Órgão Público Autônomo Federal
*   1171 - Órgão Público Autônomo Estadual ou do Distrito Federal
*   1180 - Órgão Público Autônomo Municipal
*   1198 - Comissão Polinacional
*   1210 - Consórcio Público de Direito Público (Associação Pública)
*   1228 - Consórcio Público de Direito Privado
*   1236 - Estado ou Distrito Federal
*   1244 - Município
*   1252 - Fundação Pública de Direito Privado Federal
*   1260 - Fundação Pública de Direito Privado Estadual ou do Distrito Federal
*   1279 - Fundação Pública de Direito Privado Municipal
*   1287 - Fundo Público da Administração Indireta Federal
*   1295 - Fundo Público da Administração Indireta Estadual ou do Distrito Federal
*   1309 - Fundo Público da Administração Indireta Municipal
*   1317 - Fundo Público da Administração Direta Federal
*   1325 - Fundo Público da Administração Direta Estadual ou do Distrito Federal
*   1333 - Fundo Público da Administração Direta Municipal
*   1341 - União
*   2011 - Empresa Pública
*   2038 - Sociedade de Economia Mista
*   2046 - Sociedade Anônima Aberta
*   2054 - Sociedade Anônima Fechada

---

## 5.14. Porte da Empresa

*   (código = 1) ME: Microempresa
*   (código = 2) EPP: Empresa de pequeno porte
*   (código = 3) Demais: Demais empresas
*   (código = 4) Não se aplica: Quando o fornecedor/arrematante for pessoa física.
*   (código = 5) Não informado: Quando não possuir o porte da empresa.

---

## 5.15. Amparo Legal

*   (código = 1) Lei 14.133/2021, Art. 28, I
*   (código = 2) Lei 14.133/2021, Art. 28, II
*   (código = 3) Lei 14.133/2021, Art. 28, III
*   (código = 4) Lei 14.133/2021, Art. 28, IV
*   (código = 5) Lei 14.133/2021, Art. 28, V
*   (código = 6) Lei 14.133/2021, Art. 74, I
*   (código = 7) Lei 14.133/2021, Art. 74, II
*   (código = 8) Lei 14.133/2021, Art. 74, III, a
*   (código = 9) Lei 14.133/2021, Art. 74, III, b
*   (código = 10) Lei 14.133/2021, Art. 74, III, c
*   (código = 11) Lei 14.133/2021, Art. 74, III, d
*   (código = 12) Lei 14.133/2021, Art. 74, III, e
*   (código = 13) Lei 14.133/2021, Art. 74, III, f
*   (código = 14) Lei 14.133/2021, Art. 74, III, g
*   (código = 15) Lei 14.133/2021, Art. 74, III, h
*   (código = 16) Lei 14.133/2021, Art. 74, IV
*   (código = 17) Lei 14.133/2021, Art. 74, V
*   (código = 18) Lei 14.133/2021, Art. 75, I
*   (código = 19) Lei 14.133/2021, Art. 75, II
*   (código = 20) Lei 14.133/2021, Art. 75, III, a
*   (código = 21) Lei 14.133/2021, Art. 75, III, b
*   (código = 22) Lei 14.133/2021, Art. 75, IV, a
*   (código = 23) Lei 14.133/2021, Art. 75, IV, b
*   (código = 24) Lei 14.133/2021, Art. 75, IV, c
*   (código = 25) Lei 14.133/2021, Art. 75, IV, d
*   (código = 26) Lei 14.133/2021, Art. 75, IV, e
*   (código = 27) Lei 14.133/2021, Art. 75, IV, f
*   (código = 28) Lei 14.133/2021, Art. 75, IV, g

---

## 5.16. Categoria do Item do Plano de Contratações

*   (código = 1) Material
*   (código = 2) Serviço
*   (código = 3) Obras
*   (código = 4) Serviços de Engenharia
*   (código = 5) Soluções de TIC
*   (código = 6) Locação de Imóveis
*   (código = 7) Alienação/Concessão/Permissão
*   (código = 8) Obras e Serviços de Engenharia

---

## 5.17. Identificador de Usuário

Para uso de algumas APIs pode ser necessário incluir o Identificador Único do portal ou sistema integrado (idUsuario). Essa informação pode ser encontrada acessando o sítio: Portais Integrados ao PNCP - Portal Nacional de Contratações Públicas - PNCP (www.gov.br) e clicando em “Pesquisa ID” conforme imagem a seguir:

*(Imagem do portal PNCP, mostrando a opção "Pesquisa ID")*

---

## 6. Catálogo de Serviços (APIs)

### 6.1. Consultar Itens de PCA por Ano, idUsuario e Classificação Superior

Serviço que permite recuperar a lista de itens pertencentes a um determinado Plano de Contratações Anual (PCA) por determinado ano e usuário (Portais de Contratações), opcionalmente filtrando por ordem de classificação superior.

**Detalhes de Requisição**

| Endpoint             | Método HTTP | Exemplo de Payload |
|----------------------|-------------|--------------------|
| /v1/pca/usuario      | GET         | Não se aplica      |

**Exemplo Requisição (cURL)**

```bash
curl -X 'GET' \
  'https://pncp.gov.br/api/consulta/v1/pca/usuario?anoPca=2023&idUsuario=3&codigoClassificacaoSuperior=979&pagina=1' \
  -H 'accept: */*'
```

**Dados de entrada**

*Nota: Alimentar o parâmetro {anoPca}, {idUsuario} e {pagina} na URL.*

| Campo                         | Tipo        | Obrigatório | Descrição                                                                                                                                              |
|-------------------------------|-------------|-------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|
| anoPca                        | Inteiro     | Sim         | Ano do PCA                                                                                                                                             |
| idUsuario                     | Inteiro     | Sim         | Número de identificação do usuário (Sistema de Contratações Públicas) que publicou a informação no Portal PNCP                                       |
| codigoClassificacaoSuperior   | Texto (100) | Não         | Código da Classe do material ou Grupo do serviço conforme catálogos de matérias e serviços utilizados pelos portais de compras.                          |
| pagina                        | Inteiro     | Sim         | Número da página que se deseja obter os dados.                                                                                                         |
| tamanhoPagina                 | Inteiro     | Não         | Por padrão cada página contém no máximo 500 registros, no entanto o tamanho de registros em cada página pode ser ajustado (até o limite de 500 registros) com vistas a tornar a entrega de dados mais rápida. |

**Dados de retorno**

| Id | Campo                         | Tipo    | Descrição                                                                |
|----|-------------------------------|---------|--------------------------------------------------------------------------|
| 1  | orgaoEntidadeCnpj             | Texto   | CNPJ do Órgão pertencente ao PCA                                         |
| 2  | orgaoEntidadeRazaoSocial      | Texto   | Razão Social do Órgão pertencente ao PCA                                 |
| 3  | codigoUnidade                 | Texto   | Código da Unidade Responsável do Órgão                                   |
| 4  | nomeUnidade                   | Texto   | Nome da Unidade Responsável                                              |
| 5  | anoPca                        | Inteiro | Ano do Plano de Contratações da Unidade                                  |
| 6  | idPcaPncp                     | Texto   | Número de Controle PNCP do PCA (id PCA PNCP)                             |
| 7  | dataPublicacaoPncp            | Data    | Data da publicação do item do plano no PNCP                               |
| 8  | Lista                         | Lista   | Lista de Itens do PCA da Unidade                                         |
| 8.1| numeroltem                    | Inteiro | Número do item no Plano (único e sequencial crescente)                 |
| 8.2| categorialtemPcaNome          | Texto   | Nome categoria do item conforme tabela de domínio Categoria do Item do Plano de Contratações |
| 8.3| classificacaoCatalogold      | Texto   | Código da Indicação se Item é Material ou Serviço. Domínio: 1 - Material; 2 - Serviço; |
| 8.4| nomeClassificacaoCatalogo     | Texto   | Nome da Indicação se Item é Material ou Serviço. Domínio: 1 - Material; 2 - Serviço; |
| 8.5| classificacaoSuperiorCodigo   | Texto (100) | Código da Classe do material ou Grupo do serviço conforme catálogo           |
| 8.6| classificacaoSuperiorNome     | Texto (255) | Descrição da Classe do material ou Grupo do serviço conforme catálogo      |
| 8.7| pdmCodigo                     | Texto (100) | Código PDM referente ao material conforme o CNBS                         |
| 8.8| pdmDescricao                  | Texto (255) | Descrição PDM referente ao material conforme o CNBS                      |
| 8.9| codigoltem                    | Texto (100) | Código do Material ou Serviço conforme o catálogo utilizado              |
| 8.10| descricaoltem                 | Texto (2048)| Descrição do material ou serviço conforme catálogo utilizado             |
| 8.11| unidadeFornecimento           | Texto   | Unidade de fornecimento                                                  |
| 8.12| quantidadeEstimada            | Decimal | Quantidade estimada do item do plano de contratação (maior ou igual a zero). Precisão de até 4 dígitos decimais; Ex: 10.0001; |
| 8.13| valorUnitario                 | Decimal | Valor unitário do item (maior ou igual a zero). Precisão de até 4 dígitos decimais; Ex: 100.0001; |
| 8.14| valorTotal                    | Decimal | Valor total do item (maior ou igual a zero). Precisão de até 4 dígitos decimais; Ex: 100.0001; |
| 8.15| valorOrcamentoExercicio       | Decimal | Valor orçamentário estimado para o exercício (maior ou igual a zero). Precisão de até 4 dígitos decimais; Ex: 100.0001; |
| 8.16| dataDesejada                  | Data    | Data desejada para a contratação                                         |
| 8.17| unidadeRequisitante           | Texto   | Nome da unidade requisitante                                             |
| 8.18| grupoContratacaoCodigo        | Texto   | Código da Contratação Futura                                             |
| 8.19| grupoContratacaoNome          | Texto   | Nome da Contratação Futura                                               |
| 8.20| datalnclusao                  | Data    | Data da inclusão do registro do item do plano no PNCP                    |
| 8.21| dataAtualizacao               | Data    | Data da última atualização do registro do item do plano                 |

**Códigos de Retorno**

| Código HTTP | Mensagem    | Tipo    |
|-------------|-------------|---------|
| 200         | OK          | Sucesso |
| 204         | No Content  | Sucesso |
| 400         | Bad Request | Erro    |
| 422         | Unprocessable Entity | Erro    |
| 500         | Internal Server Error | Erro    |

---

## 6.2. Consultar Itens de PCA por Ano e Classificação Superior

Serviço que permite recuperar a lista de itens pertencentes a um determinado Plano de Contratações Anual (PCA), opcionalmente filtrando por ordem de classificação superior.

**Detalhes de Requisição**

| Endpoint    | Método HTTP | Exemplo de Payload |
|-------------|-------------|--------------------|
| /v1/pca/    | GET         | Não se aplica      |

**Exemplo Requisição (cURL)**

```bash
curl -X 'GET' \
  'https://pncp.gov.br/api/consulta/v1/pca/?anoPca=2023&codigoClassificacaoSuperior=979&pagina=1' \
  -H 'accept: */*'
```

**Dados de entrada**

*Nota: Alimentar o parâmetro {ano} na URL.*

| Campo                         | Tipo        | Obrigatório | Descrição                                                                                                       |
|-------------------------------|-------------|-------------|-----------------------------------------------------------------------------------------------------------------|
| anoPca                        | Inteiro     | Sim         | Ano do PCA                                                                                                      |
| codigoClassificacaoSuperior   | Texto (100) | Sim         | Código da Classe do material ou Grupo do serviço conforme catálogos de matérias e serviços utilizados pelos portais de compras. |
| pagina                        | Inteiro     | Sim         | Número da página que se deseja obter os dados.                                                                  |
| tamanhoPagina                 | Inteiro     | Não         | Por padrão cada página contém no máximo 500 registros, no entanto o tamanho de registros em cada página pode ser ajustado (até o limite de 500 registros) com vistas a tornar a entrega de dados mais rápida. |

**Dados de retorno**

| Id | Campo                         | Tipo    | Descrição                                                                |
|----|-------------------------------|---------|--------------------------------------------------------------------------|
| 1  | orgaoEntidadeCnpj             | Texto   | CNPJ do Órgão                                                            |
| 2  | orgaoEntidadeRazaoSocial      | Texto   | Razão Social do Órgão                                                    |
| 3  | codigoUnidade                 | Texto   | Código da Unidade Responsável                                            |
| 4  | nomeUnidade                   | Texto   | Nome da Unidade Responsável                                              |
| 5  | anoPca                        | Inteiro | Ano do Plano de Contratações da Unidade                                  |
| 6  | idPcaPncp                     | Texto   | Número de Controle PNCP do PCA (id PCA PNCP)                             |
| 7  | dataPublicacaoPncp            | Data    | Data da publicação do item do plano no PNCP                               |
| 8  | Lista                         | Lista   | Lista de Itens do PCA da Unidade                                         |
| 8.1| numeroltem                    | Inteiro | Número do item no Plano (único e sequencial crescente)                 |
| 8.2| categorialtemPcaNome          | Texto   | Nome categoria do item conforme tabela de domínio Categoria do Item do Plano de Contratações |
| 8.3| classificacaoCatalogold      | Texto   | Código da Indicação se Item é Material ou Serviço. Domínio: 1 - Material; 2 - Serviço; |
| 8.4| nomeClassificacaoCatalogo     | Texto   | Nome da Indicação se Item é Material ou Serviço. Domínio: 1 - Material; 2 - Serviço; |
| 8.5| classificacaoSuperiorCodigo   | Texto (100) | Código da Classe do material ou Grupo do serviço conforme catálogo           |
| 8.6| classificacaoSuperiorNome     | Texto (255) | Descrição da Classe do material ou Grupo do serviço conforme catálogo      |
| 8.7| pdmCodigo                     | Texto (100) | Código PDM referente ao material conforme o CNBS                         |
| 8.8| pdmDescricao                  | Texto (255) | Descrição PDM referente ao material conforme o CNBS                      |
| 8.9| codigoltem                    | Texto (100) | Código do Material ou Serviço conforme o catálogo utilizado              |
| 8.10| descricaoltem                 | Texto (2048)| Descrição do material ou serviço conforme catálogo utilizado             |
| 8.11| unidadeFornecimento           | Texto   | Unidade de fornecimento                                                  |
| 8.12| quantidadeEstimada            | Decimal | Quantidade estimada do item do plano de contratação (maior ou igual a zero). Precisão de até 4 dígitos decimais; Ex: 10.0001; |
| 8.13| valorUnitario                 | Decimal | Valor unitário do item (maior ou igual a zero). Precisão de até 4 dígitos decimais; Ex: 100.0001; |
| 8.14| valorTotal                    | Decimal | Valor total do item (maior ou igual a zero). Precisão de até 4 dígitos decimais; Ex: 100.0001; |
| 8.15| valorOrcamentoExercicio       | Decimal | Valor orçamentário estimado para o exercício (maior ou igual a zero). Precisão de até 4 dígitos decimais; Ex: 100.0001; |
| 8.16| dataDesejada                  | Data    | Data desejada para a contratação                                         |
| 8.17| unidadeRequisitante           | Texto   | Nome da unidade requisitante                                             |
| 8.18| grupoContratacaoCodigo        | Texto   | Código da Contratação Futura                                             |
| 8.19| grupoContratacaoNome          | Texto   | Nome da Contratação Futura                                               |
| 8.20| datalnclusao                  | Data    | Data da inclusão do registro do item do plano no PNCP                    |
| 8.21| dataAtualizacao               | Data    | Data da última atualização do registro do item do plano                 |

---

## 6.3. Serviço Consultar Contratações por Data de Publicação

Serviço que permite consultar contratações publicadas no PNCP por um período informado. Junto à data inicial e data final informadas deverá ser informado o código da Modalidade da Contratação (vide tabela XXX). Opcionalmente poderá ser informado código do Modo de Disputa da Contratação (vide tabela XXX), código do IBGE do Município, sigla da Unidade Federativa da Unidade Administrativa do Órgão, CNPJ do Órgão/Entidade, código da Unidade Administrativa do Órgão/Entidade ou código de identificação do Usuário (Sistema de Contratações Públicas que publicou a Contratação) para refinar a consulta.

**Detalhes de Requisição**

| Endpoint                     | Método HTTP | Exemplo de Payload |
|------------------------------|-------------|--------------------|
| /v1/contratacoes/publicacao | GET         | Não se aplica      |

**Exemplo Requisição (cURL)**

```bash
curl -X 'GET' \
  'https://pncp.gov.br/api/consulta/v1/contratacoes/publicacao?dataInicial=20230801&dataFinal=20230802&codigoModalidadeContratacao=8&uf=DF&codigoMunicipiolbge=5300108&cnpj=00059311000126&codigoUnidadeAdministrativa=194035&idUsuario=3&pagina=1' \
  -H 'accept: */*'
```

**Dados de entrada**

*Nota: Dados a serem enviados no cabeçalho da requisição.*

| Campo                         | Tipo    | Obrigatório | Descrição                                                                                                                      |
|-------------------------------|---------|-------------|--------------------------------------------------------------------------------------------------------------------------------|
| dataInicial                   | Data    | Sim         | Data inicial do período a ser consultado no formato AAAAMMDD.                                                                |
| dataFinal                     | Data    | Sim         | Data final do período a ser consultado no formato AAAAMMDD.                                                                    |
| codigoModalidadeContratacao   | Inteiro | Sim         | Código da tabela de domínio referente a Modalidade da Contratação                                                            |
| codigoModoDisputa             | Inteiro | Não         | Código da tabela de domínio referente a Modo de Disputa                                                                        |
| uf                            | String  | Não         | Sigla da Unidade Federativa referente à Unidade Administrativa do órgão                                                        |
| codigoMunicipiolbge           | String  | Não         | Código IBGE do Município da Unidade Administrativa                                                                             |
| cnpj                          | String  | Não         | Cnpj do órgão originário da contratação informado na inclusão (proprietário da contratação)                                  |
| codigoUnidadeAdministrativa   | String  | Não         | Código da Unidade Administrativa do Órgão originário da contratação informado na inclusão (proprietário da contratação)       |
| idUsuario                     | Inteiro | Não         | Identificado do sistema usuário (Sistema de Contratações Públicas) que publicou a contratação.                               |
| pagina                        | Inteiro | Sim         | Número da página que se deseja obter os dados.                                                                                 |
| tamanhoPagina                 | Inteiro | Não         | Por padrão cada página contém no máximo 500 registros, no entanto o tamanho de registros em cada página pode ser ajustado (até o limite de 500 registros) com vistas a tornar a entrega de dados mais rápida. |

**Dados de retorno**

| Id | Campo                         | Tipo      | Descrição                                                                                                          |
|----|-------------------------------|-----------|--------------------------------------------------------------------------------------------------------------------|
| 1  | numeroControlePNCP            | String    | Número de Controle PNCP da Contratação (id Contratação PNCP)                                                       |
| 2  | numeroCompra                  | Texto (50)| Número da Contratação no sistema de origem                                                                       |
| 3  | anoCompra                     | Inteiro   | Ano da Contratação                                                                                                 |
| 4  | processo                      | Texto (50)| Número do processo de Contratação no sistema de origem                                                             |
| 5  | tipolnstrumentoConvocatoriold | Inteiro   | Código do instrumento convocatório da Contratação                                                                  |
| 6  | tipolnstrumentoConvocatorioNome | String  | Nome do instrumento convocatório da Contratação                                                                    |
| 7  | modalidadeld                  | Inteiro   | Código da Modalidade referente à Contratação                                                                       |
| 8  | modalidadeNome                | String    | Modalidade referente à Contratação                                                                                 |
| 9  | modoDisputald                 | Inteiro   | Código do modo de disputa referente à Contratação                                                                  |
| 10 | modoDisputaNome               | String    | Modo de disputa referente à Contratação                                                                          |
| 11 | situacaoComprald              | Inteiro   | Código da situação da Contratação                                                                                  |
| 12 | situacaoCompraNome            | Inteiro   | Situação da Contratação                                                                                            |
| 13 | objetoCompra                  | Texto (5120)| Descrição do Objeto referente à Contratação                                                                      |
| 14 | informacaoComplementar        | Texto (5120)| Informação Complementar do objeto referente à Contratação                                                          |
| 15 | srp                           | Boleano   | Identifica se a compra trata-se de um SRP (Sistema de registro de preços)                                          |
| 16 | amparoLegal                   |           | Dados do amparo legal                                                                                              |
| 16.1| codigo                        | Inteiro   | Código do Amparo Legal                                                                                             |
| 16.2| nome                          | String    | Nome do Amparo Legal                                                                                               |
| 16.3| descricao                     | String    | Descrição do Amparo legal                                                                                          |
| 17 | valorTotalEstimado            | Decimal   | Valor total estimado da Contratação. Precisão de até 4 dígitos decimais; Ex: 100.0001; Obs: Retornará valor zero (0) se atributo orcamentoSigiloso for true e o item não possuir resultado. |
| 18 | valorTotalHomologado          | Decimal   | Valor total homologado com base nos resultados incluídos. Precisão de até 4 dígitos decimais; Ex: 100.0001;          |
| 19 | dataAberturaProposta          | Data e Hora | Data de abertura do recebimento de propostas (horário de Brasília)                                                 |
| 20 | dataEncerramentoProposta      | Data e Hora | Data de encerramento do recebimento de propostas (horário de Brasília)                                             |
| 21 | dataPublicacaoPncp            | Data      | Data da publicação da Contratação no PNCP                                                                         |
| 22 | datalnclusao                  | Data      | Data da inclusão do registro da Contratação no PNCP                                                                |
| 23 | dataAtualizacao               | Data      | Data da última atualização do registro da Contratação                                                              |
| 24 | sequencialCompra              | Inteiro   | Sequencial da Contratação no PNCP; Número sequencial gerado no momento que a contratação foi inserida no PNCP;    |
| 25 | orgaoEntidade                 |           | Dados do Órgão/Entidade                                                                                            |
| 25.1| cnpj                          | String    | CNPJ do Órgão referente à Contratação                                                                            |
| 25.2| razaosocial                   | String    | Razão social do Órgão referente à Contratação                                                                    |
| 25.3| poderld                       | String    | Código do poder a que pertence o Órgão. L - Legislativo; E - Executivo; J - Judiciário                           |
| 25.4| esferald                      | String    | Código da esfera a que pertence o Órgão. F - Federal; E - Estadual; M - Municipal; D - Distrital                  |
| 26 | unidadeOrgao                  |           | Dados da Unidade Administrativa                                                                                    |
| 26.1| codigoUnidade                 | String    | Código da Unidade Administrativa pertencente ao Órgão                                                             |
| 26.2| nomeUnidade                   | String    | Nome da Unidade Administrativa pertencente ao Órgão                                                               |
| 26.3| codigolbge                    | Inteiro   | Código IBGE do município                                                                                           |
| 26.4| municipioNome                 | String    | Nome do município                                                                                                  |
| 26.5| ufSigla                       | String    | Sigla da unidade federativa do município                                                                           |
| 26.6| ufNome                        | String    | Nome da unidade federativa do município                                                                            |
| 27 | orgaoSubRogado                |           | Dados do Órgão/Entidade subrogado                                                                                  |
| 28.1| cnpj                          | String    | CNPJ do Órgão referente à Contratação                                                                            |
| 28.2| razaosocial                   | String    | Razão social do Órgão referente à Contratação                                                                    |
| 28.3| poderld                       | String    | Código do poder a que pertence o Órgão. L - Legislativo; E - Executivo; J - Judiciário                           |
| 28.4| esferald                      | String    | Código da esfera a que pertence o Órgão. F - Federal; E - Estadual; M - Municipal; D - Distrital                  |
| 29 | unidadeSubRogada              |           | Dados da Unidade Administrativa do Órgão subrogado                                                                 |
| 29.1| codigoUnidade                 | String    | Código da Unidade Administrativa pertencente ao Órgão subrogado                                                   |
| 29.2| nomeUnidade                   | String    | Nome da Unidade Administrativa pertencente ao Órgão subrogado                                                     |
| 29.3| codigolbge                    | Inteiro   | Código IBGE do município                                                                                           |
| 29.4| municipioNome                 | String    | Nome do município                                                                                                  |
| 29.5| ufSigla                       | String    | Sigla da unidade federativa do município                                                                           |
| 29.6| ufNome                        | String    | Nome da unidade federativa do município                                                                            |
| 30 | usuarioNome                   | String    | Nome do Usuário/Sistema que enviou a Contratação                                                                 |
| 31 | linkSistemaOrigem             | String    | URL para página/portal do sistema de origem da contratação para recebimento de propostas.                          |
| 32 | justificativaPresencial       | String    | Justificativa pela escolha da modalidade presencial.                                                               |

**Códigos de Retorno**

| Código HTTP | Mensagem             | Tipo    |
|-------------|----------------------|---------|
| 200         | OK                   | Sucesso |
| 204         | No Content           | Sucesso |
| 400         | Bad Request          | Erro    |
| 422         | Unprocessable Entity | Erro    |
| 500         | Internal Server Error| Erro    |

---

## 6.4. Serviço Consultar Contratações com Período de Recebimento de Propostas em Aberto

Serviço que permite consultar contratações publicadas no PNCP por um período informado. Opcionalmente poderá ser informado o código da Modalidade da Contratação código do IBGE do Município, sigla da Unidade Federativa da Unidade Administrativa do Órgão, CNPJ do Órgão/Entidade, código da Unidade Administrativa do Órgão/Entidade ou código de identificação do Usuário (Sistema de Contratações Públicas que publicou a Contratação) para refinar a consulta.

**Detalhes de Requisição**

| Endpoint                 | Método HTTP | Exemplo de Payload |
|--------------------------|-------------|--------------------|
| /v1/contratacoes/proposta | GET         | Não se aplica      |

**Exemplo Requisição (cURL)**

```bash
curl -k -X 'GET' \
  "${BASE_URL}/v1/contratacoes/proposta?dataFinal=20230831&codigoModalidadeContratacao=8&pagina=1" \
  -H "accept: */*"
```

**Dados de entrada**

*Nota: Dados a serem enviados no cabeçalho da requisição.*

| Campo                         | Tipo    | Obrigatório | Descrição                                                                                                       |
|-------------------------------|---------|-------------|-----------------------------------------------------------------------------------------------------------------|
| dataFinal                     | Data    | Sim         | Data final do período a ser consultado no formato AAAAMMDD.                                                     |
| codigoModalidadeContratacao   | Inteiro | Sim         | Código da tabela de domínio Modalidade da Contratação                                                           |
| uf                            | String  | Não         | Sigla da Unidade Federativa referente à Unidade Administrativa do órgão                                         |
| codigoMunicipiolbge           | String  | Não         | Código IBGE do Município da Unidade Administrativa                                                              |
| cnpj                          | String  | Não         | Cnpj do órgão originário da contratação informado na inclusão (proprietário da contratação)                   |
| codigoUnidadeAdministrativa   | String  | Não         | Código da Unidade Administrativa do Órgão originário da contratação informado na inclusão (proprietário da contratação) |
| idUsuario                     | Inteiro | Não         | Identificado do sistema usuário (Sistema de Contratações Públicas) que publicou a contratação.                 |
| pagina                        | Inteiro | Sim         | Número da página que se deseja obter os dados.                                                                  |
| tamanhoPagina                 | Inteiro | Não         | Por padrão cada página contém no máximo 500 registros, no entanto o tamanho de registros em cada página pode ser ajustado (até o limite de 500 registros) com vistas a tornar a entrega de dados mais rápida. |

**Dados de retorno**

| Id | Campo                         | Tipo      | Descrição                                                                                                          |
|----|-------------------------------|-----------|--------------------------------------------------------------------------------------------------------------------|
| 1  | numeroControlePNCP            | String    | Número de Controle PNCP da Contratação (id Contratação PNCP)                                                       |
| 2  | numeroCompra                  | Texto (50)| Número da Contratação no sistema de origem                                                                       |
| 3  | anoCompra                     | Inteiro   | Ano da Contratação                                                                                                 |
| 4  | processo                      | Texto (50)| Número do processo de Contratação no sistema de origem                                                             |
| 5  | tipolnstrumentoConvocatoriold | Inteiro   | Código do instrumento convocatório da Contratação                                                                  |
| 6  | tipolnstrumentoConvocatorioNome | String  | Nome do instrumento convocatório da Contratação                                                                    |
| 7  | modalidadeld                  | Inteiro   | Código da Modalidade referente à Contratação                                                                       |
| 8  | modalidadeNome                | String    | Modalidade referente à Contratação                                                                                 |
| 9  | modoDisputald                 | Inteiro   | Código do modo de disputa referente à Contratação                                                                  |
| 10 | modoDisputaNome               | String    | Modo de disputa referente à Contratação                                                                          |
| 11 | situacaoComprald              | Inteiro   | Código da situação da Contratação                                                                                  |
| 12 | situacaoCompraNome            | Inteiro   | Situação da Contratação                                                                                            |
| 13 | objetoCompra                  | Texto (5120)| Descrição do Objeto referente à Contratação                                                                      |
| 14 | informacaoComplementar        | Texto (5120)| Informação Complementar do objeto referente à Contratação                                                          |
| 15 | srp                           | Boleano   | Identifica se a compra trata-se de um SRP (Sistema de registro de preços)                                          |
| 16 | amparoLegal                   |           | Dados do amparo legal                                                                                              |
| 16.1| codigo                        | Inteiro   | Código do Amparo Legal                                                                                             |
| 16.2| nome                          | String    | Nome do Amparo Legal                                                                                               |
| 16.3| descricao                     | String    | Descrição do Amparo legal                                                                                          |
| 17 | valorTotalEstimado            | Decimal   | Valor total estimado da Contratação. Precisão de até 4 dígitos decimais; Ex: 100.0001; Obs: Retornará valor zero (0) se atributo orcamentoSigiloso for true e o item não possuir resultado. |
| 18 | valorTotalHomologado          | Decimal   | Valor total homologado com base nos resultados incluídos. Precisão de até 4 dígitos decimais; Ex: 100.0001;          |
| 19 | dataAberturaProposta          | Data e Hora | Data de abertura do recebimento de propostas (horário de Brasília)                                                 |
| 20 | dataEncerramentoProposta      | Data e Hora | Data de encerramento do recebimento de propostas (horário de Brasília)                                             |
| 21 | dataPublicacaoPncp            | Data      | Data da publicação da Contratação no PNCP                                                                         |
| 22 | datalnclusao                  | Data      | Data da inclusão do registro da Contratação no PNCP                                                                |

---

## 6.5. Serviço Consultar Atas de Registro de Preço por Período de Vigência

Serviço que permite consultar atas de registro de preços publicadas no PNCP por um período informado.

A partir da data inicial e data final informadas, serão recuperadas as atas cujo período de vigência coincida com o período informado. Opcionalmente poderá ser informado CNPJ do Órgão/Entidade, código da Unidade Administrativa do Órgão/Entidade ou número de identificação do Usuário (Portais de Contratações Públicas).

**Detalhes da Requisição**

| Endpoint | Método HTTP | Exemplo de Payload |
|----------|-------------|--------------------|
| /v1/atas | GET         |                    |

**Exemplo Requisição (cURL)**

```bash
curl -X 'GET' \
  '${BASE_URL}/v1/atas?dataInicial=20230701&dataFinal=20230831&pagina=1' \
  -H 'accept: */*'

ou

curl -X 'GET' \
  '${BASE_URL}/v1/atas?dataInicial=20231024&dataFinal=20241023&idUsuario=36&cnpjOrgao=00394429000100&pagina=1' \
  -H 'accept: */*'
```

**Dados de entrada**

*Nota: Dados a serem enviados no cabeçalho da requisição.*

| Campo                         | Tipo    | Obrigatório | Descrição                                                                                                       |
|-------------------------------|---------|-------------|-----------------------------------------------------------------------------------------------------------------|
| dataInicial                   | Data    | Sim         | Data inicial do período a ser consultado no formato AAAAMMDD.                                                 |
| dataFinal                     | Data    | Sim         | Data final do período a ser consultado no formato AAAAMMDD.                                                   |
| idUsuario                     | Inteiro | Não         | Identificado do sistema usuário (Sistema de Contratações Públicas) que publicou a ata.                          |
| cnpj                          | String  | Não         | Cnpj do órgão originário da contratação informado na inclusão (proprietário da contratação)                   |
| codigoUnidadeAdministrativa   | String  | Não         | Código da Unidade Administrativa do Órgão originário da contratação informado na inclusão (proprietário da contratação) |
| pagina                        | Inteiro | Sim         | Número da página que se deseja obter os dados.                                                                  |
| tamanhoPagina                 | Inteiro | Não         | Por padrão cada página contém no máximo 500 registros, no entanto o tamanho de registros em cada página pode ser ajustado (até o limite de 500 registros) com vistas a tornar a entrega de dados mais rápida. |

**Dados de retorno**

| Id | Campo                         | Tipo    | Descrição                                                                |
|----|-------------------------------|---------|--------------------------------------------------------------------------|
| 1  | Atas                          |         | Agrupador da lista de atas                                               |
| 1.1| numeroControlePNCPAta         | String  | Número de Controle PNCP da Ata (id Ata PNCP)                             |
| 1.2| numeroControlePNCPCompra      | String  | Número de Controle PNCP da Contratação (id Contratação PNCP) que a ata está vinculada |
| 1.3| numeroAtaRegistroPreco        | Texto (50)| Número da Ata no sistema de origem                                       |
| 1.4| anoAta                        | Inteiro | Ano da Ata                                                               |
| 1.5| dataAssinatura                | Data    | Data de assinatura da Ata                                                |
| 1.6| vigencialnicio                | Data    | Data de início de vigência da Ata                                        |
| 1.7| vigenciaFim                   | Data    | Data de fim de vigência da Ata                                           |
| 1.8| dataCancelamento              | Data    | Data de cancelamento da Ata                                              |
| 1.9| cancelado                     | Booleano| Indicador de cancelamento da Ata                                         |
| 1.10| dataPublicacaoPncp            | Data    | Data da publicação da Ata no PNCP                                         |
| 1.11| datalnclusao                  | Data    | Data da inclusão do registro da Ata no PNCP                              |
| 1.12| dataAtualizacao               | Data    | Data da última atualização do registro da Ata                           |
| 1.13| objetoContratacao             | String  | Descrição do Objeto referente à Contratação                              |
| 1.14| cnpjOrgao                     | String  | CNPJ do Órgão referente à Contratação                                  |
| 1.15| nomeOrgao                     | String  | Razão Social do Órgão referente à Contratação                          |
| 1.16| codigoUnidadeOrgao            | String  | Código da Unidade Administrativa do Órgão referente à Contratação      |
| 1.17| nomeUnidadeOrgao              | String  | Nome da Unidade Administrativa do Órgão referente à Contratação        |
| 1.18| cnpjOrgaoSubrogado            | String  | CNPJ do Órgão subrogado referente à Contratação                        |
| 1.19| nomeOrgaoSubrogado            | String  | Razão Social do Órgão subrogado referente à Contratação                |
| 1.20| codigoUnidadeOrgaoSubrogado   | String  | Código da Unidade Administrativa subrogada do Órgão subrogado referente à Contratação |
| 1.21| nomeUnidadeOrgaoSubrogado     | String  | Nome da Unidade Administrativa subrogada do Órgão subrogado referente à Contratação |
| 1.22| usuario                       | String  | Nome do sistema usuário (Sistema de Contratações Públicas) que publicou a ata. |

**Códigos de Retorno**

| Código HTTP | Mensagem    | Tipo    |
|-------------|-------------|---------|
| 200         | OK          | Sucesso |
| 204         | No Content  | Sucesso |
| 400         | Bad Request | Erro    |
| 422         | Unprocessable Entity | Erro    |
| 500         | Internal Server Error| Erro    |

---

## 6.6. Serviço Consultar Contratos por Data de Publicação

Serviço que permite consultar contratos e/ou empenhos com força de contrato publicados no PNCP por um período informado. A partir da data inicial e data final informadas serão recuperados os contratos/empenhos publicados no período. Opcionalmente poderá ser informado CNPJ do Órgão/Entidade, código da Unidade Administrativa do Órgão/Entidade ou número de identificação do Usuário (Portais de Contratações Públicas).

**Detalhes da Requisição**

| Endpoint     | Método HTTP | Exemplo de Payload |
|--------------|-------------|--------------------|
| /v1/contratos| GET         |                    |

**Exemplo Requisição (cURL)**

```bash
curl -k -X GET "${BASE_URL}/v1/contratos?dataInicial=20230801&dataFinal=20230831&pagina=1" /
-H "accept: */*"

ou

curl -k -X GET "${BASE_URL}/v1/contratos?dataInicial=20230801&dataFinal=20230831&cnpjOrgao=00394544000185&pagina=1" /
-H "accept: */*"
```

**Dados de entrada**

*Nota: Dados a serem enviados no cabeçalho da requisição.*

| Campo                         | Tipo    | Obrigatório | Descrição                                                                                                       |
|-------------------------------|---------|-------------|-----------------------------------------------------------------------------------------------------------------|
| dataInicial                   | Data    | Sim         | Data inicial do período a ser consultado no formato AAAAMMDD.                                                 |
| dataFinal                     | Data    | Sim         | Data final do período a ser consultado no formato AAAAMMDD.                                                     |
| cnpjOrgao                     | String  | Não         | Cnpj do órgão originário da contratação informado na inclusão (proprietário do contrato)                        |
| codigoUnidadeAdministrativa   | String  | Não         | Código da Unidade Administrativa do Órgão originário da contratação informado na inclusão (proprietário do contrato) |
| usuariold                     | Inteiro | Não         | Identificado do sistema usuário (Sistema de Contratações Públicas) que publicou o contrato.                     |
| pagina                        | Inteiro | Sim         | Número da página a ser requisitada                                                                              |
| tamanhoPagina                 | Inteiro | Não         | Por padrão cada página contém no máximo 500 registros, no entanto o tamanho de registros em cada página pode ser ajustado (até o limite de 500 registros) com vistas a tornar a entrega de dados mais rápida. |

**Dados de retorno**

| Id | Campo                         | Tipo    | Descrição                                                                                                          |
|----|-------------------------------|---------|--------------------------------------------------------------------------------------------------------------------|
| 1  | numeroControlePNCP            | String  | Número de controle PNCP do contrato (id contrato PNCP)                                                             |
| 2  | numeroControlePNCPCompra      | String  | Número de controle PNCP da contratação relacionada (id contratação PNCP)                                         |
| 3  | numeroContratoEmpenho         | Texto (50)| Número do contrato ou empenho com força de contrato                                                              |
| 4  | anoContrato                   | Inteiro | Ano do contrato                                                                                                    |
| 5  | sequentialContrato            | Inteiro | Número sequencial do contrato (gerado pelo PNCP)                                                                   |
| 6  | processo                      | Texto (50)| Número do processo                                                                                                 |
| 7  | tipoContrato                  |         | Dados do tipo de contrato                                                                                          |
| 7.1| Id                            | Inteiro | Código da tabela de domínio Tipo de contrato                                                                       |
| 7.2| Nome                          | String  | Nome do Tipo de Contrato                                                                                           |
| 8  | categoriaProcesso             |         | Dados da categoria do processo                                                                                     |
| 8.1| Id                            | Inteiro | Código da tabela de domínio Categoria                                                                              |
| 8.2| Nome                          | String  | Nome da Categoria do processo                                                                                      |
| 9  | receita                       | Boleano | Receita ou despesa: True - Receita; False - Despesa;                                                               |
| 10 | objetoContrato                | Texto (5120)| Descrição do objeto do contrato                                                                                    |
| 11 | informacaoComplementar        | Texto (5120)| Informações complementares; Se existir;                                                                            |
| 12 | orgaoEntidade                 |         | Dados do Órgão/Entidade do Contrato                                                                                |
| 12.1| cnpj                          | String  | CNPJ do Órgão referente à Contrato                                                                               |
| 12.2| razaoSocial                   | String  | Razão social do Órgão referente à Contrato                                                                       |
| 12.3| poderld                       | String  | Código do poder a que pertence o Órgão. L - Legislativo; E - Executivo; J - Judiciário                           |
| 12.4| esferald                      | String  | Código da esfera a que pertence o Órgão. F - Federal; E - Estadual; M - Municipal; D - Distrital                  |
| 13 | unidadeOrgao                  |         | Dados da Unidade executora do Órgão do Contrato                                                                    |
| 13.1| codigoUnidade                 | String  | Código da Unidade Executora pertencente ao Órgão                                                                   |
| 13.2| nomeUnidade                   | String  | Nome da Unidade Executora pertencente ao Órgão                                                                     |
| 13.3| codigolbge                    | Inteiro | Código IBGE do município                                                                                           |
| 13.4| municipioNome                 | String  | Nome do município                                                                                                  |
| 13.5| ufSigla                       | String  | Sigla da unidade federativa do município                                                                           |
| 13.6| ufNome                        | String  | Nome da unidade federativa do município                                                                            |
| 14 | orgaoSubRogado                |         | Dados do Órgão/Entidade subrogado do Contrato                                                                      |
| 14.1| cnpj                          | String  | CNPJ do Órgão referente à Contrato                                                                               |
| 14.2| razaoSocial                   | String  | Razão social do Órgão referente à Contrato                                                                       |
| 14.3| poderld                       | String  | Código do poder a que pertence o Órgão. L - Legislativo; E - Executivo; J - Judiciário                           |
| 14.4| esferald                      | String  | Código da esfera a que pertence o Órgão. F - Federal; E - Estadual; M - Municipal; D - Distrital                  |
| 15 | unidadeSubRogada              |         | Dados da Unidade Executora do Órgão subrogado                                                                      |
| 15.1| codigoUnidade                 | String  | Código da Unidade Executora pertencente ao Órgão                                                                   |
| 15.2| nomeUnidade                   | String  | Nome da Unidade Executora pertencente ao Órgão                                                                     |
| 15.3| codigolbge                    | Inteiro | Código IBGE do município                                                                                           |
| 15.4| municipioNome                 | String  | Nome do município                                                                                                  |
| 15.5| ufSigla                       | String  | Sigla da unidade federativa do município                                                                           |
| 15.6| ufNome                        | String  | Nome da unidade federativa do município                                                                            |
| 16 | tipoPessoa                    | Texto (2) | PJ - Pessoa jurídica; PF - Pessoa física; PE - Pessoa estrangeira;                                                 |
| 17 | niFornecedor                  | Texto (30)| Número de identificação do fornecedor/arrematante; CNPJ, CPF ou identificador de empresa estrangeira;          |
| 18 | nomeRazaoSocialFornecedor     | Texto (100)| Nome ou razão social do fornecedor/arrematante                                                                     |
| 19 | tipoPessoaSubContratada       | Texto (2) | PJ - Pessoa jurídica; PF - Pessoa física; PE - Pessoa estrangeira; Somente em caso de subcontratação;             |
| 20 | niFornecedorSubContratado     | Texto (30)| Número de identificação do fornecedor subcontratado; CNPJ, CPF ou identificador de empresa estrangeira; Somente em caso de subcontratação; |
| 21 | nomeFornecedorSubContratado   | Texto (100)| Nome ou razão social do fornecedor subcontratado; Somente em caso de subcontratação;                           |
| 22 | valorInicial                  | Decimal | Valor inicial do contrato. Precisão de até 4 dígitos decimais; Ex: 100.0001;                                       |
| 23 | numeroParcelas                | Inteiro | Número de parcelas                                                                                                 |
| 24 | valorParcela                  | Decimal | Valor da parcela. Precisão de até 4 dígitos decimais; Ex: 100.0001;                                                |
| 25 | valorGlobal                   | Decimal | Valor global do contrato. Precisão de até 4 dígitos decimais; Ex: 100.0001;                                        |
| 26 | valorAcumulado                | Decimal | Valor acumulado do contrato. Precisão de até 4 dígitos decimais; Ex: 100.0001;                                       |
| 27 | dataAssinatura                | Data    | Data de assinatura do contrato                                                                                     |
| 28 | dataVigencialnicio            | Data    | Data de início de vigência do contrato                                                                             |
| 29 | dataVigenciaFim               | Data    | Data do término da vigência do contrato                                                                            |
| 30 | numeroRetificacao             | Inteiro | Número de retificações; Número de vezes que este registro está sendo alterado;                                     |
| 31 | usuarioNome                   | String  | Nome do sistema/portal que enviou o contrato                                                                       |
| 32 | dataPublicacaoPncp            | Data/Hora | Data de publicação do contrato no PNCP                                                                             |
| 33 | dataAtualizacao               | Data/Hora | Data da última atualização do contrato no PNCP                                                                     |
| 34 | identificadorCipi             | String  | Identificador do contrato no Cadastro Integrado de Projetos de Investimento                                        |
| 35 | urlCipi                       | String  | Url com informações do contrato no sistema de Cadastro Integrado de Projetos de Investimento                       |

**Códigos de Retorno**

| Código HTTP | Mensagem             | Tipo    |
|-------------|----------------------|---------|
| 200         | OK                   | Sucesso |
| 204         | No Content           | Sucesso |
| 400         | Bad Request          | Erro    |
| 422         | Unprocessable Entity | Erro    |
| 500         | Internal Server Error| Erro    |

---

## 6.6.1 - Observação:

Em adição ao serviço "6.6. Serviço Consultar Contratos por Data de Publicação" mencionado neste manual, é importante destacar que o Portal Nacional de Contratações Públicas (PNCP) oferece uma gama ampla de funcionalidades via API que permitem uma consulta detalhada sobre CONTRATAÇÕES.

Estas funcionalidades estão minuciosamente descritas no Manual de Integração – Portal Nacional de Contratações Públicas - PNCP, disponível no site oficial www.gov.br. Abaixo, apresentamos uma lista com alguns exemplos de serviços disponíveis:

*   6.5.7. Consultar Documento de um Contrato
*   6.5.9. Consultar Contratos de uma Contratação

Recomendamos a leitura detalhada do Manual de Integração do PNCP para uma compreensão abrangente de todas as funcionalidades e possibilidades oferecidas pela API.

---

## 7. Suporte

Em caso de problemas durante o processo de integração do seu sistema com o PNCP, por favor entre em contato com a Central de Atendimento do Ministério da Gestão e da Inovação em Serviços Públicos (https://portaldeservicos.economia.gov.br) ou pelo telefone 0800 978 9001.

---

## 8. Glossário

O seguinte glossário fornece definições e explicações de termos e siglas específicos utilizados ao longo deste documento. O objetivo é esclarecer qualquer ambiguidade e ajudar o leitor a compreender melhor o conteúdo apresentado.

*   **API (Application Programming Interface):** Interface de Programação de Aplicações. É um conjunto de rotinas e padrões estabelecidos por um software para a utilização das suas funcionalidades por programas que não pretendem envolver-se em detalhes da implementação do software, mas apenas usá-lo.
*   **CNBS (Catálogo Nacional de Bens e Serviços):** Catálogo que lista e categoriza bens e serviços. Em muitos contextos, serve como uma referência padronizada para a classificação e descrição de itens. Mais informações em: https://www.gov.br/compras/pt-br/sistemas/conheca-o-compras/catalogo
*   **CNPJ (Cadastro Nacional da Pessoa Jurídica):** É o registro de empresas e outras entidades na Receita Federal do Brasil.
*   **HTTP (Hypertext Transfer Protocol):** Protocolo de Transferência de Hipertexto. É o protocolo fundamental da web, usado para transferir e exibir páginas da web, entre outros.
*   **JSON (JavaScript Object Notation):** Notação de Objeto JavaScript. É um formato de intercâmbio de dados leve e de fácil leitura e escrita para seres humanos.
*   **ME/EPP:** Microempresa e Empresa de Pequeno Porte. São categorias de empresas definidas pela legislação brasileira com base em seu faturamento.
*   **PDM (Padrão Descritivo de Material):** Refere-se a um padrão ou modelo utilizado para descrever materiais de forma consistente e padronizada, facilitando a identificação, catalogação e gestão de materiais em diversos sistemas e contextos.
*   **PCA:** plano de contratações anual definido na lei 14.133/2021
*   **PNCP (Portal Nacional de Contratações Públicas):** sítio oficial estabelecido pela Lei 14133 para divulgação e gestão de contratações públicas no Brasil. Centraliza informações, editais e contratos, promovendo transparência e eficiência, e é gerido por um comitê nacional.
*   **REST (Representational State Transfer):** Transferência de Estado Representacional. É um estilo arquitetural para desenvolvimento de serviços web. É caracterizado por um conjunto de restrições, incluindo um protocolo cliente/servidor sem estado e um conjunto padrão de métodos HTTP.
*   **SWAGGER:** É uma ferramenta de software de código aberto usada para projetar, construir e documentar serviços web REST.
*   **TIC (Tecnologia da Informação e Comunicação):** Refere-se a qualquer tecnologia que ajuda a produzir, manipular, armazenar, comunicar ou disseminar informação.
*   **URL (Uniform Resource Locator):** Localizador Padrão de Recursos. É um endereço de um recurso na web.
*   **USUÁRIO:** Em contextos de sistemas e aplicações, refere-se à pessoa ou entidade que utiliza o software ou sistema em questão.
</file>

<file path="src/baliza/pncp_task_planner.py">
import calendar
from datetime import date, timedelta
from typing import Any, List, Tuple

from baliza.config import PNCP_ENDPOINTS


class PNCPTaskPlanner:
    """Handles the planning of PNCP data extraction tasks."""

    def __init__(self):
        pass

    def _format_date(self, date_obj: date) -> str:
        """Format date for PNCP API (YYYYMMDD)."""
        return date_obj.strftime("%Y%m%d")

    def _monthly_chunks(
        self, start_date: date, end_date: date
    ) -> List[Tuple[date, date]]:
        """Generate monthly date chunks (start to end of each month)."""
        chunks = []
        current = start_date

        while current <= end_date:
            # Get the first day of the current month
            month_start = current.replace(day=1)

            # Get the last day of the current month
            _, last_day = calendar.monthrange(current.year, current.month)
            month_end = current.replace(day=last_day)

            # Adjust for actual start/end boundaries
            chunk_start = max(month_start, start_date)
            chunk_end = min(month_end, end_date)

            chunks.append((chunk_start, chunk_end))

            # Move to first day of next month
            if current.month == 12:
                current = current.replace(year=current.year + 1, month=1, day=1)
            else:
                current = current.replace(month=current.month + 1, day=1)

        return chunks

    async def plan_tasks(self, start_date: date, end_date: date) -> List[Tuple[str, str, date, Any]]:
        """Populate the control table with all necessary tasks."""
        date_chunks = self._monthly_chunks(start_date, end_date)
        tasks_to_create = []

        for endpoint in PNCP_ENDPOINTS:
            modalidades = endpoint.get(
                "iterate_modalidades", [None]
            )  # None means no modalidade iteration

            for modalidade in modalidades:
                if endpoint.get("requires_single_date", False):
                    # For single-date endpoints, create only one task with the end_date
                    # Special handling for endpoints that need future dates
                    if endpoint.get("requires_future_date", False):
                        # Use a future date for endpoints that need current/future dates
                        future_days = endpoint.get("future_days_offset", 1825)
                        future_date = date.today() + timedelta(days=future_days)
                        task_suffix = (
                            f"_modalidade_{modalidade}"
                            if modalidade is not None
                            else ""
                        )
                        task_id = (
                            f"{endpoint['name']}_{future_date.isoformat()}{task_suffix}"
                        )
                        tasks_to_create.append(
                            (task_id, endpoint["name"], future_date, modalidade)
                        )
                    else:
                        task_suffix = (
                            f"_modalidade_{modalidade}"
                            if modalidade is not None
                            else ""
                        )
                        task_id = (
                            f"{endpoint['name']}_{end_date.isoformat()}{task_suffix}"
                        )
                        tasks_to_create.append(
                            (task_id, endpoint["name"], end_date, modalidade)
                        )
                else:
                    # For range endpoints, use monthly chunking
                    for chunk_start, _ in date_chunks:
                        task_suffix = (
                            f"_modalidade_{modalidade}"
                            if modalidade is not None
                            else ""
                        )
                        task_id = (
                            f"{endpoint['name']}_{chunk_start.isoformat()}{task_suffix}"
                        )
                        tasks_to_create.append(
                            (task_id, endpoint["name"], chunk_start, modalidade)
                        )
        return tasks_to_create
</file>

<file path="dbt_baliza/models/silver/silver_atas.sql">
{{
  config(
    materialized='table'
  )
}}

WITH source AS (
    SELECT *
    FROM {{ ref('bronze_pncp_raw') }}
    WHERE endpoint_category = 'atas'
),

parsed_responses AS (
  SELECT
    id,
    extracted_at,
    endpoint_name,
    endpoint_url,
    data_date,
    run_id,
    total_records,
    total_pages,
    current_page,
    response_json
  FROM source
),

-- Extract individual ata records from the data array
ata_records AS (
  SELECT
    parsed_responses.id AS response_id,
    parsed_responses.extracted_at,
    parsed_responses.endpoint_name,
    parsed_responses.endpoint_url,
    parsed_responses.data_date,
    parsed_responses.run_id,
    parsed_responses.total_records,
    parsed_responses.total_pages,
    parsed_responses.current_page,
    -- Generate a unique key for each ata record
    ROW_NUMBER() OVER (PARTITION BY parsed_responses.id ORDER BY ata_data_table.value) AS record_index,
    -- Extract individual ata data
    ata_data_table.value AS ata_data
  FROM parsed_responses
  CROSS JOIN json_each(json_extract(parsed_responses.response_json, '$.data')) AS ata_data_table
  WHERE json_extract(parsed_responses.response_json, '$.data') IS NOT NULL
)

SELECT
  response_id,
  extracted_at,
  endpoint_name,
  endpoint_url,
  data_date,
  run_id,
  total_records,
  total_pages,
  current_page,
  record_index,

  -- Ata identifiers
  ata_data ->> 'numeroControlePNCP' AS numero_controle_pncp,
  ata_data ->> 'numeroAta' AS numero_ata,
  CAST(ata_data ->> 'anoAta' AS INTEGER) AS ano_ata,

  -- Dates
  TRY_CAST(ata_data ->> 'dataAssinatura' AS DATE) AS data_assinatura,
  TRY_CAST(ata_data ->> 'dataVigenciaInicio' AS DATE) AS data_vigencia_inicio,
  TRY_CAST(ata_data ->> 'dataVigenciaFim' AS DATE) AS data_vigencia_fim,
  TRY_CAST(ata_data ->> 'dataPublicacaoPncp' AS TIMESTAMP) AS data_publicacao_pncp,
  TRY_CAST(ata_data ->> 'dataAtualizacao' AS TIMESTAMP) AS data_atualizacao,

  -- Supplier information
  ata_data ->> 'niFornecedor' AS ni_fornecedor,
  ata_data ->> 'nomeRazaoSocialFornecedor' AS nome_razao_social_fornecedor,

  -- Ata details
  ata_data ->> 'objetoAta' AS objeto_ata,
  ata_data ->> 'informacaoComplementar' AS informacao_complementar,
  CAST(ata_data ->> 'numeroRetificacao' AS INTEGER) AS numero_retificacao,

  -- Organization data (nested JSON)
  ata_data -> 'orgaoEntidade' AS orgao_entidade_json,
  ata_data -> 'unidadeOrgao' AS unidade_orgao_json,

  -- Full ata data as JSON for fallback
  ata_data AS ata_json

FROM ata_records
WHERE ata_data ->> 'numeroControlePNCP' IS NOT NULL
</file>

<file path="dbt_baliza/models/silver/silver_contratos.sql">
{{
  config(
    materialized='table'
  )
}}

WITH source AS (
    SELECT *
    FROM {{ ref('bronze_pncp_raw') }}
    WHERE endpoint_category = 'contratos'
),

parsed_responses AS (
  SELECT
    id,
    extracted_at,
    endpoint_name,
    endpoint_url,
    data_date,
    run_id,
    total_records,
    total_pages,
    current_page,
    response_json
  FROM source
),

-- Extract individual contract records from the data array
contract_records AS (
  SELECT
    parsed_responses.id AS response_id,
    parsed_responses.extracted_at,
    parsed_responses.endpoint_name,
    parsed_responses.endpoint_url,
    parsed_responses.data_date,
    parsed_responses.run_id,
    parsed_responses.total_records,
    parsed_responses.total_pages,
    parsed_responses.current_page,
    -- Generate a unique key for each contract record
    ROW_NUMBER() OVER (PARTITION BY parsed_responses.id ORDER BY contract_data_table.value) AS record_index,
    -- Extract individual contract data
    contract_data_table.value AS contract_data
  FROM parsed_responses
  CROSS JOIN json_each(json_extract(parsed_responses.response_json, '$.data')) AS contract_data_table
  WHERE json_extract(parsed_responses.response_json, '$.data') IS NOT NULL
),

deduplicated_contracts AS (
    SELECT
        *,
        ROW_NUMBER() OVER (
            PARTITION BY contract_data ->> 'numeroControlePNCP'
            ORDER BY
                TRY_CAST(contract_data ->> 'dataAtualizacao' AS TIMESTAMP) DESC
        ) AS rn
    FROM contract_records
)

SELECT
  response_id,
  extracted_at,
  endpoint_name,
  endpoint_url,
  data_date,
  run_id,
  total_records,
  total_pages,
  current_page,
  record_index,
  
  -- Contract identifiers
  contract_data ->> 'numeroControlePNCP' AS numero_controle_pncp,
  contract_data ->> 'numeroControlePncpCompra' AS numero_controle_pncp_compra,
  contract_data ->> 'numeroContratoEmpenho' AS numero_contrato_empenho,
  CAST(contract_data ->> 'anoContrato' AS INTEGER) AS ano_contrato,
  CAST(contract_data ->> 'sequencialContrato' AS INTEGER) AS sequencial_contrato,
  
  -- Dates
  TRY_CAST(contract_data ->> 'dataAssinatura' AS DATE) AS data_assinatura,
  TRY_CAST(contract_data ->> 'dataVigenciaInicio' AS DATE) AS data_vigencia_inicio,
  TRY_CAST(contract_data ->> 'dataVigenciaFim' AS DATE) AS data_vigencia_fim,
  TRY_CAST(contract_data ->> 'dataPublicacaoPncp' AS TIMESTAMP) AS data_publicacao_pncp,
  TRY_CAST(contract_data ->> 'dataAtualizacao' AS TIMESTAMP) AS data_atualizacao,
  TRY_CAST(contract_data ->> 'dataAtualizacaoGlobal' AS TIMESTAMP) AS data_atualizacao_global,
  
  -- Amounts
  CAST(contract_data ->> 'valorInicial' AS DOUBLE) AS valor_inicial,
  CAST(contract_data ->> 'valorGlobal' AS DOUBLE) AS valor_global,
  CAST(contract_data ->> 'valorParcela' AS DOUBLE) AS valor_parcela,
  CAST(contract_data ->> 'valorAcumulado' AS DOUBLE) AS valor_acumulado,
  
  -- Supplier information
  contract_data ->> 'niFornecedor' AS ni_fornecedor,
  contract_data ->> 'tipoPessoa' AS tipo_pessoa,
  contract_data ->> 'nomeRazaoSocialFornecedor' AS nome_razao_social_fornecedor,
  contract_data ->> 'niFornecedorSubContratado' AS ni_fornecedor_subcontratado,
  contract_data ->> 'nomeFornecedorSubContratado' AS nome_fornecedor_subcontratado,
  contract_data ->> 'tipoPessoaSubContratada' AS tipo_pessoa_subcontratada,
  
  -- Contract details
  contract_data ->> 'objetoContrato' AS objeto_contrato,
  contract_data ->> 'informacaoComplementar' AS informacao_complementar,
  contract_data ->> 'processo' AS processo,
  CAST(contract_data ->> 'numeroParcelas' AS INTEGER) AS numero_parcelas,
  CAST(contract_data ->> 'numeroRetificacao' AS INTEGER) AS numero_retificacao,
  CAST(contract_data ->> 'receita' AS BOOLEAN) AS receita,
  
  -- Organization data (nested JSON)
  contract_data -> 'orgaoEntidade' AS orgao_entidade_json,
  contract_data -> 'unidadeOrgao' AS unidade_orgao_json,
  contract_data -> 'orgaoSubRogado' AS orgao_subrogado_json,
  contract_data -> 'unidadeSubRogada' AS unidade_subrogada_json,
  contract_data -> 'tipoContrato' AS tipo_contrato_json,
  contract_data -> 'categoriaProcesso' AS categoria_processo_json,
  
  -- Additional identifiers
  contract_data ->> 'codigoPaisFornecedor' AS codigo_pais_fornecedor,
  contract_data ->> 'identificadorCipi' AS identificador_cipi,
  contract_data ->> 'urlCipi' AS url_cipi,
  contract_data ->> 'usuarioNome' AS usuario_nome,
  
  -- Full contract data as JSON for fallback
  contract_data AS contract_json

FROM deduplicated_contracts
WHERE rn = 1
</file>

<file path="src/baliza/config.py">
"""Configuration constants for the baliza package."""

from baliza.enums import ModalidadeContratacao


# Working endpoints (only the reliable ones) - OpenAPI compliant
PNCP_ENDPOINTS = [
    {
        "name": "contratos_publicacao",
        "path": "/v1/contratos",
        "description": "Contratos por Data de Publicação",
        "date_params": ["dataInicial", "dataFinal"],
        "max_days": 365,  # API limit, but we use monthly chunks
        "supports_date_range": True,
        "page_size": 500,  # OpenAPI spec: max 500 for this endpoint
    },
    {
        "name": "contratos_atualizacao",
        "path": "/v1/contratos/atualizacao",
        "description": "Contratos por Data de Atualização Global",
        "date_params": ["dataInicial", "dataFinal"],
        "max_days": 365,  # API limit, but we use monthly chunks
        "supports_date_range": True,
        "page_size": 500,  # OpenAPI spec: max 500 for this endpoint
    },
    {
        "name": "atas_periodo",
        "path": "/v1/atas",
        "description": "Atas de Registro de Preço por Período de Vigência",
        "date_params": ["dataInicial", "dataFinal"],
        "max_days": 365,  # API limit, but we use monthly chunks
        "supports_date_range": True,
        "page_size": 500,  # OpenAPI spec: max 500 for this endpoint
    },
    {
        "name": "atas_atualizacao",
        "path": "/v1/atas/atualizacao",
        "description": "Atas por Data de Atualização Global",
        "date_params": ["dataInicial", "dataFinal"],
        "max_days": 365,  # API limit, but we use monthly chunks
        "supports_date_range": True,
        "page_size": 500,  # OpenAPI spec: max 500 for this endpoint
    },
    {
        "name": "contratacoes_publicacao",
        "path": "/v1/contratacoes/publicacao",
        "description": "Contratações por Data de Publicação",
        "date_params": ["dataInicial", "dataFinal"],
        "max_days": 365,
        "supports_date_range": True,
        "iterate_modalidades": [m.value for m in ModalidadeContratacao],
        "page_size": 50,  # OpenAPI spec: max 50 for contratacoes endpoints
    },
    {
        "name": "contratacoes_atualizacao",
        "path": "/v1/contratacoes/atualizacao",
        "description": "Contratações por Data de Atualização Global",
        "date_params": ["dataInicial", "dataFinal"],
        "max_days": 365,
        "supports_date_range": True,
        "iterate_modalidades": [m.value for m in ModalidadeContratacao],
        "page_size": 50,  # OpenAPI spec: max 50 for contratacoes endpoints
    },
    {
        "name": "pca_atualizacao",
        "path": "/v1/pca/atualizacao",
        "description": "PCA por Data de Atualização Global",
        "date_params": ["dataInicio", "dataFim"],  # PCA uses different parameter names
        "max_days": 365,
        "supports_date_range": True,
        "page_size": 500,  # OpenAPI spec: max 500 for this endpoint
    },
    {
        "name": "instrumentoscobranca_inclusao",
        "path": "/v1/instrumentoscobranca/inclusao",  # Correct path from OpenAPI spec
        "description": "Instrumentos de Cobrança por Data de Inclusão",
        "date_params": ["dataInicial", "dataFinal"],  # Uses date range
        "max_days": 365,
        "supports_date_range": True,  # Date range endpoint
        "page_size": 100,  # OpenAPI spec: max 100, min 10 for this endpoint
        "min_page_size": 10,  # Minimum page size required
    },
    {
        "name": "contratacoes_proposta",
        "path": "/v1/contratacoes/proposta",
        "description": "Contratações com Recebimento de Propostas Aberto",
        "date_params": ["dataFinal"],
        "max_days": 365,
        "supports_date_range": False,
        "requires_single_date": True,  # This endpoint doesn't use date chunking
        "requires_future_date": True,  # This endpoint needs current/future dates
        "future_days_offset": 1825,  # Use 5 years in the future to capture most active contracts
        # No iterate_modalidades - captures more data without it
        "page_size": 50,  # OpenAPI spec: max 50 for contratacoes endpoints
    },
    # Note: PCA usuario endpoint requires anoPca and idUsuario parameters
    # This is commented out as it requires specific user/org data to be useful
    # {
    #     "name": "pca_usuario",
    #     "path": "/v1/pca/usuario",
    #     "description": "PCA por Usuário e Ano",
    #     "date_params": [],  # Uses anoPca instead of date ranges
    #     "max_days": 0,
    #     "supports_date_range": False,
    #     "requires_specific_params": True,  # Requires anoPca, idUsuario
    #     "extra_params": {"anoPca": 2024, "idUsuario": "example"},
    #     "page_size": 500,
    # },
]

# Configuration constants
PNCP_BASE_URL = "https://pncp.gov.br/api/consulta"
CONCURRENCY = 8  # Concurrent requests limit
PAGE_SIZE = 500  # Maximum page size
REQUEST_TIMEOUT = 30
USER_AGENT = "BALIZA/3.0 (Backup Aberto de Licitacoes)"
</file>

<file path="tests/conftest.py">
import gc
import os
import sys
import tempfile
from pathlib import Path

import duckdb  # Import duckdb
import pytest

# Add src to Python path for all tests
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))


def pytest_configure(config):
    """Configure pytest with custom markers."""
    config.addinivalue_line(
        "markers", "slow: marks tests as slow (may take several seconds)"
    )
    config.addinivalue_line("markers", "integration: marks tests as integration tests")
    config.addinivalue_line("markers", "performance: marks tests as performance tests")
    config.addinivalue_line(
        "markers", "end_to_end: marks tests as complete end-to-end tests"
    )


def pytest_addoption(parser):
    """Add custom command line options."""
    parser.addoption(
        "--run-slow", action="store_true", default=False, help="run slow tests"
    )
    parser.addoption(
        "--run-integration",
        action="store_true",
        default=False,
        help="run integration tests",
    )
    parser.addoption(
        "--run-performance",
        action="store_true",
        default=False,
        help="run performance tests",
    )


def pytest_collection_modifyitems(config, items):
    """Modify test collection based on command line options."""
    if not config.getoption("--run-slow"):
        skip_slow = pytest.mark.skip(reason="need --run-slow option to run")
        for item in items:
            if "slow" in item.keywords:
                item.add_marker(skip_slow)

    if not config.getoption("--run-integration"):
        skip_integration = pytest.mark.skip(
            reason="need --run-integration option to run"
        )
        for item in items:
            if "integration" in item.keywords:
                item.add_marker(skip_integration)

    if not config.getoption("--run-performance"):
        skip_performance = pytest.mark.skip(
            reason="need --run-performance option to run"
        )
        for item in items:
            if "performance" in item.keywords:
                item.add_marker(skip_performance)


@pytest.fixture(scope="session")
def project_root():
    """Get the project root directory."""
    return Path(__file__).parent.parent


@pytest.fixture
def temp_baliza_workspace():
    """Create a temporary workspace that mimics the Baliza project structure."""
    with tempfile.TemporaryDirectory() as tmpdir:
        # Change to temporary directory
        original_cwd = os.getcwd()
        os.chdir(tmpdir)

        # Create project structure
        dirs_to_create = [
            "src/baliza",
            "state",
            "baliza_data",
            "dbt_baliza/models/coverage",
            "dbt_baliza/models/staging",
            "dbt_baliza/models/sources",
            "notebooks",
            ".github/workflows",
            "tests",
        ]

        for dir_path in dirs_to_create:
            Path(dir_path).mkdir(parents=True, exist_ok=True)

        yield tmpdir

        # Restore original directory
        os.chdir(original_cwd)

        # Ensure all DuckDB connections are closed and garbage collected
        gc.collect()


@pytest.fixture
def duckdb_conn():
    """Provides a DuckDB in-memory connection for testing."""
    conn = duckdb.connect(database=":memory:")
    yield conn
    conn.close()
    gc.collect()


@pytest.fixture
def mock_environment_variables():
    """Provide mock environment variables for testing."""
    return {
        "IA_ACCESS_KEY": "test_access_key",
        "IA_SECRET_KEY": "test_secret_key",
        "BALIZA_DATE": "2024-01-15",
    }


@pytest.fixture
def sample_pncp_data():
    """Provide sample PNCP data for testing."""
    return {
        "data": [
            {
                "numeroControlePncpCompra": "12345-2024-001",
                "anoContrato": 2024,
                "dataAssinatura": "20240115",
                "niFornecedor": "12345678000195",
                "nomeRazaoSocialFornecedor": "Empresa Teste LTDA",
                "objetoContrato": "Prestação de serviços de TI",
                "valorInicial": 50000.00,
                "valorGlobal": 50000.00,
                "orgaoEntidade": {
                    "razaoSocial": "Prefeitura Municipal",
                    "cnpj": "11111111000111",
                    "uf": "RO",
                },
                "tipoContrato": {"codigo": "1", "descricao": "Serviços"},
            },
            {
                "numeroControlePncpCompra": "12345-2024-002",
                "anoContrato": 2024,
                "dataAssinatura": "20240116",
                "niFornecedor": "98765432000123",
                "nomeRazaoSocialFornecedor": "Outra Empresa SA",
                "objetoContrato": "Fornecimento de materiais",
                "valorInicial": 75000.00,
                "valorGlobal": 75000.00,
                "orgaoEntidade": {
                    "razaoSocial": "Governo do Estado",
                    "cnpj": "22222222000222",
                    "uf": "RO",
                },
                "tipoContrato": {"codigo": "2", "descricao": "Materiais"},
            },
        ],
        "totalRegistros": 2,
        "totalPaginas": 1,
        "paginaAtual": 1,
    }


@pytest.fixture
def sample_ia_items():
    """Provide sample Internet Archive items for testing."""
    return [
        {
            "identifier": "pncp-contratos-2024-01-15",
            "parquet_urls": [
                "https://archive.org/download/pncp-contratos-2024-01-15/file.parquet"
            ],
            "data_date": "2024-01-15",
            "metadata": {
                "date": "2024-01-15",
                "title": "PNCP Contratos 2024-01-15",
                "collection": "opensource",
            },
        }
    ]
</file>

<file path="tests/README.md">
# 🧪 Baliza Test Suite

This directory contains tests for the BALIZA project.

## 📋 Current Structure

The project uses a modular architecture with the main extractor functionality in `src/baliza/extractor.py` and CLI interface in `src/baliza/cli.py`. The project also includes MCP server functionality for AI integration.

### ✅ **Remaining Files**
- `conftest.py` - Test configuration and fixtures
- `README.md` - This file

## 🚀 Testing the BALIZA System

The project uses a modular architecture with CLI interface and MCP server. Testing is primarily done through manual verification:

### **Manual Testing**
```bash
# Test basic functionality
uv run baliza stats

# Test data extraction
uv run baliza extract --start-date 2024-07-10 --end-date 2024-07-10

# Test MCP server (requires fastmcp dependency)
uv run baliza mcp

# Test extractor module directly
uv run python src/baliza/extractor.py stats
```

### **What is Tested**
- ✅ **CLI Interface**: Command-line interface functionality
- ✅ **Database Operations**: PSA schema creation and data storage
- ✅ **API Connectivity**: PNCP endpoint access
- ✅ **Data Processing**: Response parsing and storage
- ✅ **Error Handling**: HTTP errors and rate limiting
- ✅ **MCP Server**: Model Context Protocol server functionality
- ✅ **Async Operations**: Multi-threaded data extraction

## 🔧 Future Test Improvements

Potential areas for adding tests back:
1. **Unit Tests**: Test individual functions in `extractor.py`
2. **Integration Tests**: Test database operations
3. **API Tests**: Mock PNCP API responses
4. **Performance Tests**: Test with large datasets
5. **MCP Server Tests**: Test Model Context Protocol functionality
6. **E2E Tests**: Test complete extraction workflows

## 📊 Quality Assurance

The modular architecture relies on:
- **Modular design**: Separate CLI, extractor, and MCP server components
- **Raw data storage**: Preserves all API responses for future analysis
- **Unified schema**: Consistent data structure across all endpoints
- **Built-in error handling**: Graceful handling of API failures
- **Async operations**: Efficient multi-threaded data extraction
- **MCP integration**: AI-ready data analysis capabilities

## 🎯 Key Benefits of Current Architecture

1. **Modular Design**: Separate concerns for better maintainability
2. **Extensibility**: Easy to add new features (MCP server, new extractors)
3. **Performance**: Async operations for efficient data extraction
4. **AI Integration**: MCP server enables advanced AI analysis
5. **Robust Error Handling**: Graceful handling of various failure scenarios

---

## 🔍 Manual Verification Checklist

To verify the system works correctly:

- [ ] `baliza stats` shows existing data
- [ ] `baliza extract` can extract new data  
- [ ] Database file is created at `data/baliza.duckdb`
- [ ] Raw responses are stored in `psa.pncp_raw_responses` table
- [ ] API rate limiting works (1 second delay between requests)
- [ ] All HTTP status codes are handled gracefully
- [ ] Progress bars and console output work correctly

For issues or suggestions, please open a GitHub issue.
</file>

<file path=".gitignore">
# Data directories (new structure)
data/
.cache/
.config/

# Database files
*.duckdb
*.duckdb.wal
*.db

# Python
__pycache__/
target/
*.pyc
*.pyo
*.pyd
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
**/*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.venv/
venv/
ENV/
env/

# IDE
.vscode/
.idea/
.user.yml
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
*.log
logs/

# Temporary files
*.tmp
*.temp

# Package files
uv.lock
/site
</file>

<file path="dbt_baliza/models/silver/silver_contratacoes.sql">
{{
  config(
    materialized='incremental',
    unique_key='numero_controle_pncp',
    incremental_strategy='delete+insert'
  )
}}

WITH source AS (
    SELECT
        id,
        extracted_at,
        endpoint_name,
        endpoint_url,
        data_date,
        run_id,
        total_records,
        total_pages,
        current_page,
        response_json
    FROM {{ ref('bronze_pncp_raw') }}
    WHERE endpoint_category = 'contratacoes'
    {% if is_incremental() %}
    AND extracted_at > (SELECT MAX(extracted_at) FROM {{ this }})
    {% endif %}
),

-- Extract individual procurement records from the data array
procurement_records AS (
  SELECT
    source.id AS response_id,
    source.extracted_at,
    source.endpoint_name,
    source.endpoint_url,
    source.data_date,
    source.run_id,
    source.total_records,
    source.total_pages,
    source.current_page,
    -- Generate a unique key for each procurement record
    ROW_NUMBER() OVER (PARTITION BY source.id ORDER BY procurement_data_table.value) AS record_index,
    -- Extract individual procurement data
    procurement_data_table.value AS procurement_data
  FROM source
  CROSS JOIN json_each(json_extract(source.response_json, '$.data')) AS procurement_data_table
  WHERE json_extract(source.response_json, '$.data') IS NOT NULL
)

SELECT
  response_id,
  extracted_at,
  endpoint_name,
  endpoint_url,
  data_date,
  run_id,
  total_records,
  total_pages,
  current_page,
  record_index,
  
  -- Procurement identifiers
  procurement_data ->> 'numeroControlePNCP' AS numero_controle_pncp,
  procurement_data ->> 'numeroCompra' AS numero_compra,
  CAST(procurement_data ->> 'anoCompra' AS INTEGER) AS ano_compra,
  CAST(procurement_data ->> 'sequencialCompra' AS INTEGER) AS sequencial_compra,
  
  -- Dates
  TRY_CAST(procurement_data ->> 'dataPublicacaoPncp' AS TIMESTAMP) AS data_publicacao_pncp,
  TRY_CAST(procurement_data ->> 'dataAberturaProposta' AS TIMESTAMP) AS data_abertura_proposta,
  TRY_CAST(procurement_data ->> 'dataEncerramentoProposta' AS TIMESTAMP) AS data_encerramento_proposta,
  TRY_CAST(procurement_data ->> 'dataInclusao' AS TIMESTAMP) AS data_inclusao,
  TRY_CAST(procurement_data ->> 'dataAtualizacao' AS TIMESTAMP) AS data_atualizacao,
  TRY_CAST(procurement_data ->> 'dataAtualizacaoGlobal' AS TIMESTAMP) AS data_atualizacao_global,
  
  -- Amounts
  CAST(procurement_data ->> 'valorTotalEstimado' AS DOUBLE) AS valor_total_estimado,
  CAST(procurement_data ->> 'valorTotalHomologado' AS DOUBLE) AS valor_total_homologado,
  
  -- Procurement details
  procurement_data ->> 'objetoCompra' AS objeto_compra,
  procurement_data ->> 'informacaoComplementar' AS informacao_complementar,
  procurement_data ->> 'processo' AS processo,
  procurement_data ->> 'linkSistemaOrigem' AS link_sistema_origem,
  procurement_data ->> 'linkProcessoEletronico' AS link_processo_eletronico,
  procurement_data ->> 'justificativaPresencial' AS justificativa_presencial,
  
  -- Procurement method and mode
  CAST(procurement_data ->> 'modalidadeId' AS INTEGER) AS modalidade_id,
  CASE CAST(procurement_data ->> 'modalidadeId' AS INTEGER)
    WHEN 1 THEN 'Leilão - Eletrônico'
    WHEN 2 THEN 'Diálogo Competitivo'
    WHEN 3 THEN 'Concurso'
    WHEN 4 THEN 'Concorrência - Eletrônica'
    WHEN 5 THEN 'Concorrência - Presencial'
    WHEN 6 THEN 'Pregão - Eletrônico'
    WHEN 7 THEN 'Pregão - Presencial'
    WHEN 8 THEN 'Dispensa de Licitação'
    WHEN 9 THEN 'Inexigibilidade'
    WHEN 10 THEN 'Manifestação de Interesse'
    WHEN 11 THEN 'Pré-qualificação'
    WHEN 12 THEN 'Credenciamento'
    WHEN 13 THEN 'Leilão - Presencial'
    ELSE procurement_data ->> 'modalidadeNome'
  END AS modalidade_nome,
  CAST(procurement_data ->> 'modoDisputaId' AS INTEGER) AS modo_disputa_id,
  CASE CAST(procurement_data ->> 'modoDisputaId' AS INTEGER)
    WHEN 1 THEN 'Aberto'
    WHEN 2 THEN 'Fechado'
    WHEN 3 THEN 'Aberto-Fechado'
    WHEN 4 THEN 'Dispensa Com Disputa'
    WHEN 5 THEN 'Não se aplica'
    WHEN 6 THEN 'Fechado-Aberto'
    ELSE procurement_data ->> 'modoDisputaNome'
  END AS modo_disputa_nome,
  
  -- Instrument and framework
  CAST(procurement_data ->> 'tipoInstrumentoConvocatorioCodigo' AS INTEGER) AS tipo_instrumento_convocatorio_codigo,
  CASE CAST(procurement_data ->> 'tipoInstrumentoConvocatorioCodigo' AS INTEGER)
    WHEN 1 THEN 'Edital'
    WHEN 2 THEN 'Aviso de Contratação Direta'
    WHEN 3 THEN 'Ato que autoriza a Contratação Direta'
    ELSE procurement_data ->> 'tipoInstrumentoConvocatorioNome'
  END AS tipo_instrumento_convocatorio_nome,
  
  -- Status and flags
  procurement_data ->> 'situacaoCompraId' AS situacao_compra_id,
  CASE CAST(procurement_data ->> 'situacaoCompraId' AS INTEGER)
    WHEN 1 THEN 'Divulgada no PNCP'
    WHEN 2 THEN 'Revogada'
    WHEN 3 THEN 'Anulada'
    WHEN 4 THEN 'Suspensa'
    ELSE procurement_data ->> 'situacaoCompraNome'
  END AS situacao_compra_nome,
  CAST(procurement_data ->> 'srp' AS BOOLEAN) AS srp,
  CAST(procurement_data ->> 'existeResultado' AS BOOLEAN) AS existe_resultado,
  
  -- Organization data (nested JSON)
  procurement_data -> 'orgaoEntidade' AS orgao_entidade_json,
  procurement_data -> 'unidadeOrgao' AS unidade_orgao_json,
  procurement_data -> 'orgaoSubRogado' AS orgao_subrogado_json,
  procurement_data -> 'unidadeSubRogada' AS unidade_subrogada_json,
  procurement_data -> 'amparoLegal' AS amparo_legal_json,
  procurement_data -> 'fontesOrcamentarias' AS fontes_orcamentarias_json,
  
  -- User information
  procurement_data ->> 'usuarioNome' AS usuario_nome,
  
  -- Full procurement data as JSON for fallback
  procurement_data AS procurement_json

FROM procurement_records
</file>

<file path="dbt_baliza/profiles.yml">
baliza:
  target: dev
  outputs:
    dev:
      type: duckdb
      path: "{{ env_var('DATA_DIR', '../data') }}/baliza.duckdb"
      threads: 4
      keepalives_idle: 0
      search_path: psa
      extensions:
        - httpfs
        - spatial
    
    prod:
      type: duckdb
      path: "{{ env_var('DATA_DIR', '../data') }}/baliza.duckdb"
      threads: 8
      keepalives_idle: 0
      search_path: psa
      extensions:
        - httpfs
        - spatial
</file>

<file path="src/baliza/cli.py">
import asyncio
import json
from datetime import date
from pathlib import Path

import typer
from rich.console import Console

from .extractor import (
    BALIZA_DB_PATH,
    CONCURRENCY,
    DATA_DIR,
    AsyncPNCPExtractor,
    connect_utf8,
)

app = typer.Typer()
console = Console(force_terminal=True, legacy_windows=False, stderr=False)


@app.command()
def extract(
    concurrency: int = typer.Option(CONCURRENCY, help="Number of concurrent requests"),
    force: bool = typer.Option(
        False, "--force", help="Force re-extraction even if data exists"
    ),
):
    """Extract data using true async architecture."""
    start_dt = date(2021, 1, 1)
    end_dt = date.today()

    async def main():
        async with AsyncPNCPExtractor(concurrency=concurrency) as extractor:
            results = await extractor.extract_data(start_dt, end_dt, force)

            # Save results
            results_file = (
                DATA_DIR / f"async_extraction_results_{results['run_id']}.json"
            )
            with Path(results_file).open("w", encoding="utf-8") as f:
                json.dump(results, f, indent=2, default=str)

            console.print(f"Results saved to: {results_file}")

    asyncio.run(main())


from . import mcp_server


@app.command()
def mcp(
    host: str = typer.Option("127.0.0.1", help="The host to bind the MCP server to."),
    port: int = typer.Option(8000, help="The port to run the MCP server on."),
):
    """
    Starts the Model Context Protocol (MCP) server to allow language models
    to interact with the Baliza dataset.
    """
    console.print(f"🚀 Starting Baliza MCP Server at http://{host}:{port}")
    console.print("Press Ctrl+C to stop the server.")

    # This is a simplified call. We might need to adapt it based on
    # how fastmcp's `app.run()` is implemented, potentially passing host/port.
    mcp_server.run_server()


@app.command()
def stats():
    """Show extraction statistics."""
    conn = connect_utf8(str(BALIZA_DB_PATH))

    # Overall stats
    total_responses = conn.execute(
        "SELECT COUNT(*) FROM psa.pncp_raw_responses"
    ).fetchone()[0]
    success_responses = conn.execute(
        "SELECT COUNT(*) FROM psa.pncp_raw_responses WHERE response_code = 200"
    ).fetchone()[0]

    console.print(f"=== Total Responses: {total_responses:,} ===")
    console.print(f"Successful: {success_responses:,}")
    console.print(f"❌ Failed: {total_responses - success_responses:,}")

    if total_responses > 0:
        console.print(f"Success Rate: {success_responses / total_responses * 100:.1f}%")

    # Endpoint breakdown
    endpoint_stats = conn.execute(
        """
        SELECT endpoint_name, COUNT(*) as responses, SUM(total_records) as total_records
        FROM psa.pncp_raw_responses
        WHERE response_code = 200
        GROUP BY endpoint_name
        ORDER BY total_records DESC
    """
    ).fetchall()

    console.print("\n=== Endpoint Statistics ===")
    for name, responses, records in endpoint_stats:
        console.print(f"  {name}: {responses:,} responses, {records:,} records")

    conn.close()


import sys

if __name__ == "__main__":
    # Configure streams for UTF-8
    for std in (sys.stdin, sys.stdout, sys.stderr):
        if std and hasattr(std, "reconfigure"):
            std.reconfigure(encoding="utf-8", errors="surrogateescape")
    app()
</file>

<file path="TODO.md">
# BALIZA TODO - Code Quality & Architecture Improvements

**Sapere aude** — vamos dissecar os trechos que mais fedem a *code‑smell* e sugerir o antídoto.

---

## 🏗️ ARCHITECTURAL IMPROVEMENTS

### 1. Extractor Complexity Reduction - ✅ DONE
**Problem**: `AsyncPNCPExtractor` is a monolithic class with >800 lines mixing concerns.

**Solution**: Split into focused modules:
- ✅ **PNCPClient** - HTTP requests and retry logic
- ✅ **PNCPTaskPlanner** - Task planning and chunking
- ✅ **PNCPWriter** - Database operations and queue processing
- ✅ **AsyncPNCPExtractor** - Main orchestration (now <400 lines)

**Benefits**:
- Signal handlers work cross-platform (Windows/Unix)
- Queue size now properly calculated
- Each module has single responsibility
- Easier testing and maintenance

---

### 2. Circular Import Resolution - ✅ DONE
**Problem**: Circular imports between `extractor.py` ↔ `pncp_client.py` ↔ `pncp_task_planner.py`

**Solution**: Created dedicated modules:
- ✅ **config.py** - PNCP_ENDPOINTS and constants
- ✅ **utils.py** - Shared utilities like `parse_json_robust`
- ✅ **enums.py** - All enum definitions (already existed)

**Benefits**:
- Clean module boundaries
- No more import-time errors
- Better code organization
- Easier to add new features

---

## 🐛 CODE QUALITY FIXES

### 3. Generic Exception Handling - ✅ DONE
| **Issue** | **Problem** | **Impact** | **Solution** |
|-----------|-------------|------------|--------------|
| `except Exception as e:` everywhere | Catches all errors indiscriminately | Silences legitimate failures, hard to debug | Use specific exceptions (`httpx.RequestError`, `json.JSONDecodeError`) and let others bubble up |

**Status**: ✅ Fixed in all modules with proper error handling

---

### 4. Unnecessary `asyncio.sleep()` - ✅ DONE
| **Issue** | **Problem** | **Impact** | **Solution** |
|-----------|-------------|------------|--------------|
| 0.5s-1s sleeps in test loops and progress UI | Artificial delays | Slow CI, poor UX | Use `rich.refresh_per_second` for progress; remove from tests |

**Status**: ✅ Removed unnecessary sleeps, optimized progress display

---

### 5. Global Stream Reconfiguration - ✅ DONE
```python
# OLD - BAD
for std in (sys.stdin, sys.stdout, sys.stderr):
    std.reconfigure(encoding="utf-8", errors="surrogateescape")
```

**Problem**: Side-effect on import; breaks libs assuming original encoding.

**Solution**: ✅ Moved to `if __name__ == "__main__":` block - DuckDB handles UTF-8 properly without this.

---

### 6. Manual Retry Logic - ✅ DONE
```python
# OLD - BAD
delay = (2**attempt) * random.uniform(0.5, 1.5)  # noqa: S311
```

**Problems**:
- Reinventing the wheel (tenacity exists)
- `random.uniform` without seed = non-deterministic tests

**Solution**: ✅ Using `tenacity` library:
```python
from tenacity import retry, stop_after_attempt, wait_exponential_jitter
@retry(stop=stop_after_attempt(3), wait=wait_exponential_jitter())
async def _fetch(...):
    ...
```

---

### 7. JSON Parsing Verbosity - ✅ DONE
**Problem**: `parse_json_robust` prints to console instead of logging.

**Solution**: ✅ Clean implementation in `utils.py`:
```python
def parse_json_robust(content: str) -> Any:
    try:
        return orjson.loads(content)
    except orjson.JSONDecodeError as e:
        logger.warning(f"orjson failed, fallback to json: {e}")
        return json.loads(content)
```

---

### 8. Memory-Inefficient Parquet Loading - ✅ DONE
```python
# OLD - BAD
for parquet_file in parquet_dir.glob("*.parquet"):
    con.execute(f"CREATE VIEW {table_name} AS SELECT * FROM '{parquet_file}'")
```

**Problems**:
- Loads all files into memory
- Doesn't scale (1GB+ crashes)
- Unnecessary - DuckDB has late-binding

**Solution**: ✅ Use DuckDB's native glob support:
```sql
CREATE OR REPLACE VIEW contratos AS
SELECT * FROM read_parquet('data/parquet/contratos/*.parquet');
```

---

### 9. Path Sanitization Weakness - ✅ DONE
```python
# OLD - WEAK
if ".." in dataset_name or "/" in dataset_name:
    return {"error": "Invalid dataset name"}
```

**Problem**: Still allows `%2e%2e` (URL-encoded path traversal).

**Solution**: ✅ Use `pathlib.Path.resolve()` + parent directory checking for robust path validation.

---

## 🧪 TESTING IMPROVEMENTS

### 10. Network Dependencies in Unit Tests - ⚠️ PENDING
**Problem**: All `test_*` files hit real PNCP API.

**Consequences**:
- Flaky tests due to network issues
- Rate limiting problems
- Slow CI/CD

**Solution**: Use `respx` or `pytest-httpx` for mocking:
```python
import respx
import httpx

@respx.mock
async def test_fetch_contracts():
    respx.get("https://pncp.gov.br/api/consulta/v1/contratos").mock(
        return_value=httpx.Response(200, json={"data": []})
    )
    # Test logic here
```

**Action Items**:
- [ ] Add `respx` to test dependencies
- [ ] Create mock responses for common endpoints
- [ ] Keep one small E2E test for happy path
- [ ] Mock all other tests

---

## 📊 PERFORMANCE & SCALABILITY

### 11. DuckDB Integration Strategy - ✅ MOSTLY DONE

#### What DuckDB Already Handles Well:
| **Feature** | **DuckDB Status** | **Notes** |
|-------------|------------------|-----------|
| **Read Parquet/CSV from `s3://`** | ✅ Yes | Via `httpfs` extension |
| **Multi-file glob reads** | ✅ Yes | `read_parquet('s3://bucket/prefix/*.parquet')` |
| **Read-only S3 databases** | ✅ Yes | Perfect for analytics |

#### Where `fsspec[s3]`/`s3fs` Still Adds Value:
| **Use Case** | **Why fsspec Needed** | **Priority** |
|--------------|----------------------|--------------|
| **Upload/append to S3/IA** | DuckDB only writes locally | High |
| **Advanced caching** | Avoid excessive HEAD calls | Medium |
| **Multi-storage support** | Unified API for S3/HTTP/GCS | Medium |
| **Test mocking** | `fsspec.implementations.memory` for unit tests | High |
| **Dynamic credentials** | IAM roles, STS, presigned URLs | Low |

#### Practical Strategy:
1. ✅ **Analytics queries** → Pure DuckDB (`read_parquet('s3://…')`)
2. ⚠️ **Data pipeline writes** → `pyarrow`/`polars` + fsspec
3. ⚠️ **Testing** → `fsspec.filesystem('memory')` for mocked storage

---

## 🎯 PRIORITY ROADMAP

### 🔥 HIGH PRIORITY (Next Sprint)
1. **Testing Infrastructure** - Replace real API calls with mocks
2. **Data Pipeline** - Implement fsspec for S3 uploads
3. **Documentation** - Update README with new architecture

### 🟡 MEDIUM PRIORITY (Future Sprints)
1. **Monitoring** - Add metrics and observability
2. **Configuration** - Environment-based config system
3. **Error Recovery** - Better handling of partial failures

### 🟢 LOW PRIORITY (Backlog)
1. **Multi-storage** - Support for other cloud providers
2. **Credential Management** - Advanced auth strategies
3. **Performance Tuning** - Optimize for large-scale extraction

---

## 📚 ARCHITECTURAL PRINCIPLES

### ✅ ACHIEVED
- **Single Responsibility**: Each module has one clear purpose
- **Dependency Inversion**: Abstract interfaces, concrete implementations
- **Open/Closed**: Easy to extend without modifying existing code
- **DRY**: No code duplication across modules

### 🎯 GUIDING PRINCIPLES
- **Fail Fast**: Let errors bubble up rather than hiding them
- **Explicit > Implicit**: Clear parameter passing, no magic
- **Testable**: Every component can be tested in isolation
- **Observable**: Proper logging and metrics throughout

---

## 🏆 SUMMARY

> **Errare humanum est; perseverare diabolicum** — Most code is now robust and well-architected. The major architectural issues have been resolved through proper module separation and dependency management.

**Key Achievements**:
- ✅ Eliminated circular imports
- ✅ Separated concerns into focused modules  
- ✅ Implemented proper error handling
- ✅ Added production-ready retry logic
- ✅ Optimized memory usage for large datasets

**Remaining Work**:
- ⚠️ Test infrastructure (mocking real API calls)
- ⚠️ S3 upload pipeline via fsspec
- ⚠️ Comprehensive documentation

**Philosophy**: *"Fortes fortuna adiuvat"* — Use DuckDB where it excels; bring `fsspec` only for what's missing. Keep the hot-path lean and the extension points flexible.

---

## 📝 REFERENCES

[1]: https://duckdb.org/docs/extensions/httpfs.html
[2]: https://duckdb.org/docs/data/parquet.html
[3]: https://github.com/duckdb/duckdb/discussions/6517
</file>

<file path="src/baliza/mcp_server.py">
import asyncio
import json
import logging
from pathlib import Path

import duckdb
from fastmcp import FastMCP

from baliza.enums import get_all_enum_metadata

# Initialize the FastMCP server
app = FastMCP()
logger = logging.getLogger(__name__)

# Define the mapping of logical table names to their Parquet glob patterns
# Assumes data/parquet/<table>/*.parquet structure
PARQUET_TABLE_MAPPING = {
    "contratos": "contratos/*.parquet",
    "atas": "atas/*.parquet",
    # Add other datasets as needed
}


# --- Resources ---


async def _available_datasets_logic() -> str:
    """Returns a list of available datasets for querying."""
    datasets = [
        {"name": "contratos", "description": "Dados sobre contratos públicos."},
        {"name": "atas", "description": "Dados sobre atas de registro de preço."},
    ]
    return json.dumps(datasets)


@app.resource("mcp://baliza/available_datasets")
async def available_datasets() -> str:
    return await _available_datasets_logic()


async def _dataset_schema_logic(dataset_name: str, base_dir: str | None = None) -> str:
    """Returns the schema for a given dataset."""
    data_dir = Path(base_dir) if base_dir else Path("data/parquet")
    
    # Use the mapping to get the correct glob pattern
    parquet_glob_pattern = PARQUET_TABLE_MAPPING.get(dataset_name)
    if not parquet_glob_pattern:
        return json.dumps({"error": f"Dataset '{dataset_name}' not found in mapping."})

    # Construct the full path for DuckDB's read_parquet
    full_parquet_path = data_dir / parquet_glob_pattern

    # Robust path sanitization
    try:
        resolved_path = full_parquet_path.resolve(strict=True)
        if not resolved_path.is_relative_to(data_dir.resolve()):
            return json.dumps({"error": "Invalid dataset path."})
    except FileNotFoundError:
        return json.dumps({"error": f"Dataset '{dataset_name}' not found."})
    except Exception as e:
        logger.error(f"Path resolution error for {dataset_name}: {e}")
        return json.dumps({"error": "Invalid dataset name."})

    try:
        con = duckdb.connect(database=":memory:")
        # Use read_parquet directly with the glob pattern
        schema = con.execute(f"DESCRIBE SELECT * FROM read_parquet('{resolved_path!s}')").fetchdf()
        return schema.to_json(orient="records")
    except duckdb.Error as e:
        logger.error(f"Failed to get schema for {dataset_name}: {e}")
        return json.dumps({"error": str(e)})


@app.resource("mcp://baliza/dataset_schema/{dataset_name}")
async def dataset_schema(dataset_name: str) -> str:
    return await _dataset_schema_logic(dataset_name)


async def _enum_metadata_logic() -> str:
    """Returns metadata for all enums."""
    metadata = get_all_enum_metadata()
    return json.dumps(metadata)


@app.resource("mcp://baliza/enum_metadata")
async def enum_metadata() -> str:
    return await _enum_metadata_logic()


# --- Tools ---


async def _execute_sql_query_logic(query: str, base_dir: str | None = None) -> str:
    """Executes a read-only SQL query against the procurement dataset."""
    # Security Validation: Only allow SELECT statements
    if not query.strip().upper().startswith("SELECT"):
        return json.dumps({"error": "Only SELECT queries are allowed."})

    try:
        con = duckdb.connect(database=":memory:")

        parquet_dir = Path(base_dir) if base_dir else Path("data/parquet")
        if parquet_dir.exists():
            for table_name, glob_pattern in PARQUET_TABLE_MAPPING.items():
                full_parquet_path = parquet_dir / glob_pattern
                # Robust path sanitization for view creation
                try:
                    resolved_path = full_parquet_path.resolve(strict=True)
                    if not resolved_path.is_relative_to(parquet_dir.resolve()):
                        logger.error(f"Attempted path traversal: {full_parquet_path}")
                        continue # Skip this view if path is invalid
                except FileNotFoundError:
                    logger.warning(f"Parquet path not found: {full_parquet_path}")
                    continue # Skip if file does not exist
                except Exception as e:
                    logger.error(f"Path resolution error for {full_parquet_path}: {e}")
                    continue # Skip on other path errors

                # Create a view for each logical table using read_parquet with glob
                con.execute(
                    f"CREATE OR REPLACE VIEW {table_name} AS SELECT * FROM read_parquet('{resolved_path!s}')"
                )

        result = con.execute(query).fetchdf()
        return result.to_json(orient="records")

    except duckdb.Error as e:
        logger.error(f"Query failed: {query} - {e}")
        return json.dumps({"error": f"Query failed: {e!s}"})


@app.tool("mcp://baliza/execute_sql_query")
async def execute_sql_query(query: str) -> str:
    return await _execute_sql_query_logic(query)


def run_server():
    """
    Runs the MCP server. This function will be called by the CLI.
    """
    app.run()


async def _run_tests():
    """A simple test runner to validate functionality."""
    import shutil
    import tempfile

    import pandas as pd

    print("--- Running MCP Server Tests ---")
    test_dir = tempfile.mkdtemp()
    parquet_dir = Path(test_dir) / "parquet"
    parquet_dir.mkdir()

    # Create dummy data in subdirectories to match the new structure
    (parquet_dir / "contratos").mkdir()
    (parquet_dir / "atas").mkdir()

    try:
        # Create dummy data for 'contratos'
        contracts_df = pd.DataFrame(
            {
                "id": [1, 2],
                "valor": [100.0, 200.0],
                "fornecedor": ["Empresa A", "Empresa B"],
            }
        )
        contracts_df.to_parquet(parquet_dir / "contratos" / "part-00000.parquet")
        print("✅ [1/7] Dummy data for 'contratos' created.")

        # Create dummy data for 'atas'
        atas_df = pd.DataFrame(
            {
                "id": [101, 102],
                "numero": ["ATA-001", "ATA-002"],
            }
        )
        atas_df.to_parquet(parquet_dir / "atas" / "part-00000.parquet")
        print("✅ [2/7] Dummy data for 'atas' created.")

        # 3. Test available_datasets_logic
        datasets_str = await _available_datasets_logic()
        datasets = json.loads(datasets_str)
        assert len(datasets) > 0
        assert any(d["name"] == "contratos" for d in datasets)
        assert any(d["name"] == "atas" for d in datasets)
        print("✅ [3/7] `available_datasets` logic passed.")

        # 4. Test _dataset_schema_logic
        schema_str = await _dataset_schema_logic("contratos", base_dir=str(parquet_dir))
        schema = json.loads(schema_str)
        assert "id" in [c["column_name"] for c in schema]
        print("✅ [4/7] `dataset_schema` logic passed.")

        # 5. Test _enum_metadata_logic
        metadata_str = await _enum_metadata_logic()
        metadata = json.loads(metadata_str)
        assert "ModalidadeContratacao" in metadata
        assert "values" in metadata["ModalidadeContratacao"]
        print("✅ [5/7] `enum_metadata` logic passed.")

        # 6. Test _dataset_schema_logic with path traversal attempt
        invalid_schema_str = await _dataset_schema_logic("../invalid", base_dir=str(parquet_dir))
        invalid_schema = json.loads(invalid_schema_str)
        assert "error" in invalid_schema
        assert "Invalid dataset path." in invalid_schema["error"]
        print("✅ [6/7] `_dataset_schema_logic` path traversal prevention passed.")

        # 7. Test _execute_sql_query_logic (success)
        result_str = await _execute_sql_query_logic(
            "SELECT * FROM contratos", base_dir=str(parquet_dir)
        )
        result = json.loads(result_str)
        assert len(result) == 2
        assert result[0]["fornecedor"] == "Empresa A"
        print("✅ [7/7] `execute_sql_query` logic passed.")

    finally:
        shutil.rmtree(test_dir)
        print("\n--- Tests Finished ---")


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "test":
        asyncio.run(_run_tests())
    else:
        run_server()
</file>

<file path=".github/workflows/baliza_daily_run.yml">
name: Baliza Daily Data Fetch & Upload

on:
  workflow_dispatch: # Allows manual triggering
  schedule:
    # Runs at 02:15 BRT (America/Sao_Paulo time), which is 05:15 UTC.
    - cron: '15 5 * * *'

jobs:
  fetch_and_upload_pncp_data:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install Baliza and dependencies
        run: |
          pip install .
          pip install internetarchive duckdb
        shell: bash

      - name: Run Baliza extract for recent data
        id: baliza_run
        timeout-minutes: 120
        run: |
          echo "Running baliza extract for the last 2 days..."
          baliza extract --start-date $(date -d "yesterday" +%Y-%m-%d) --end-date $(date +%Y-%m-%d)
        shell: bash

      - name: Export new data to Parquet
        id: export_parquet
        run: |
          mkdir -p data/parquet
          python scripts/export_to_parquet.py
        shell: bash

      - name: Configure Internet Archive CLI
        env:
          IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
          IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
        run: |
          ia configure --access ${{ secrets.IA_ACCESS_KEY }} --secret ${{ secrets.IA_SECRET_KEY }}
        shell: bash

      - name: Upload new Parquet data to Internet Archive
        env:
          IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
          IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
        run: |
          IA_IDENTIFIER="baliza-pncp-parquet"
          ia upload $IA_IDENTIFIER data/parquet/ \
            --metadata="title:Dados do PNCP em Formato Parquet (Particionado)" \
            --metadata="description:Backup diário e particionado dos dados do Portal Nacional de Contratações Públicas (PNCP), extraídos pelo projeto BALIZA." \
            --metadata="collection:opensource" \
            --metadata="creator:BALIZA Project" \
            --retries=3 --verbose
        shell: bash

      - name: Upload database as artifact
        uses: actions/upload-artifact@v4
        with:
          name: baliza-database
          path: data/baliza.duckdb
          retention-days: 1

  build_coverage_data:
    needs: fetch_and_upload_pncp_data
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download database artifact
        uses: actions/download-artifact@v4
        with:
          name: baliza-database
          path: data/

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install .[analytics]
        shell: bash

      - name: Run DBT coverage analysis
        run: |
          # The dbt project is configured to use the DB at 'data/baliza.duckdb'
          dbt run --project-dir dbt_baliza --profiles-dir dbt_baliza
        shell: bash

      - name: Upload coverage data artifacts
        # This step needs to be adapted to the new dbt project structure
        # For now, we assume it works as intended
        run: echo "Skipping coverage artifact upload for now"


  deploy_pages:
    needs: [fetch_and_upload_pncp_data, build_coverage_data]
    runs-on: ubuntu-latest
    permissions:
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download coverage data
        uses: actions/download-artifact@v4
        with:
          name: coverage-data
          path: site/data/

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: './docs'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
</file>

<file path="dbt_baliza/dbt_project.yml">
name: 'dbt_baliza'
version: '1.0.0'
config-version: 2

# This setting configures which "profile" dbt uses for this project.
profile: 'baliza'

# These configurations specify where dbt should look for different types of files.
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

clean-targets:
  - "target"
  - "dbt_packages"

# Configuring models
models:
  dbt_baliza:
    # Bronze layer
    bronze:
      +materialized: table
      +schema: bronze
    
    # Silver layer
    silver:
      +materialized: table
      +schema: silver
    
    # Gold layer
    gold:
      +materialized: table
      +schema: gold

# Variables
vars:
  data_dir: ../data
  # Schema for raw data
  psa_schema: 'psa'
  
  # Date range for processing (can be overridden at runtime)
  start_date: '2024-01-01'
  end_date: '2024-12-31'
  
  # Endpoint configurations
  endpoints:
    contratos_publicacao: 'contratos_publicacao'
    contratos_atualizacao: 'contratos_atualizacao'
    contratacoes_publicacao: 'contratacoes_publicacao'
    contratacoes_atualizacao: 'contratacoes_atualizacao'
    contratacoes_proposta: 'contratacoes_proposta'
    atas_periodo: 'atas_periodo'
    atas_atualizacao: 'atas_atualizacao'
    instrumentos_cobranca: 'instrumentos_cobranca'
    pca_atualizacao: 'pca_atualizacao'

# Tests
tests:
  +schema: tests

# Snapshots
snapshots:
  +schema: snapshots

# Seeds
seeds:
  +schema: psa
</file>

<file path="src/baliza/pncp_client.py">
import asyncio
import logging
from typing import Any

import httpx
from tenacity import retry, stop_after_attempt, wait_exponential_jitter

from baliza.utils import parse_json_robust
from baliza.config import PNCP_BASE_URL, REQUEST_TIMEOUT, USER_AGENT

logger = logging.getLogger(__name__)


class PNCPClient:
    """Handles HTTP requests to the PNCP API with retry logic and back-pressure."""

    def __init__(self, concurrency: int):
        self.concurrency = concurrency
        self.semaphore = asyncio.Semaphore(concurrency)
        self.client: httpx.AsyncClient | None = None

    async def __aenter__(self):
        """Async context manager entry."""
        await self._init_client()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit with graceful cleanup."""
        if self.client:
            await self.client.aclose()

    async def _init_client(self):
        """Initialize HTTP client with optimal settings and HTTP/2 fallback."""
        try:
            # Try with HTTP/2 first
            self.client = httpx.AsyncClient(
                base_url=PNCP_BASE_URL,
                timeout=REQUEST_TIMEOUT,
                headers={
                    "User-Agent": USER_AGENT,
                    "Accept-Encoding": "gzip, br",
                    "Accept": "application/json",
                },
                http2=True,
                limits=httpx.Limits(
                    max_connections=self.concurrency,
                    max_keepalive_connections=self.concurrency,
                ),
            )
            logger.info("HTTP/2 client initialized")

            # Verify HTTP/2 is actually working
            await self._verify_http2_status()

        except ImportError:
            # Fallback to HTTP/1.1 if h2 not available
            self.client = httpx.AsyncClient(
                base_url=PNCP_BASE_URL,
                timeout=REQUEST_TIMEOUT,
                headers={
                    "User-Agent": USER_AGENT,
                    "Accept-Encoding": "gzip, br",
                    "Accept": "application/json",
                },
                limits=httpx.Limits(
                    max_connections=self.concurrency,
                    max_keepalive_connections=self.concurrency,
                ),
            )
            logger.warning("HTTP/2 not available, using HTTP/1.1")

    async def _verify_http2_status(self):
        """Verify that HTTP/2 is actually being used."""
        try:
            # Make a test request to check protocol
            response = await self.client.get("/", timeout=5)

            # Check if HTTP/2 was actually used
            if hasattr(response, "http_version") and response.http_version == "HTTP/2":
                logger.info("HTTP/2 protocol confirmed")
            else:
                protocol = getattr(response, "http_version", "HTTP/1.1")
                logger.warning(
                    "Using protocol: {protocol} (fallback from HTTP/2)",
                    protocol=protocol,
                )

        except httpx.RequestError as e:
            logger.exception(f"HTTP/2 verification failed: {e}")

    @retry(stop=stop_after_attempt(3), wait=wait_exponential_jitter())
    async def fetch_with_backpressure(
        self, url: str, params: dict[str, Any], task_id: str | None = None
    ) -> dict[str, Any]:
        """Fetch with semaphore back-pressure and retry logic."""
        async with self.semaphore:
            response = await self.client.get(url, params=params)

            # Common success data
            if response.status_code in [200, 204]:
                content_text = response.text
                data = parse_json_robust(content_text) if content_text else {}
                return {
                    "success": True,
                    "status_code": response.status_code,
                    "data": data,
                    "headers": dict(response.headers),
                    "total_records": data.get("totalRegistros", 0),
                    "total_pages": data.get("totalPaginas", 1),
                    "content": content_text,
                    "task_id": task_id,  # Pass through task_id
                    "url": url,
                    "params": params,
                }

            # Handle failures
            if 400 <= response.status_code < 500:
                # Don't retry client errors
                return {
                    "success": False,
                    "status_code": response.status_code,
                    "error": f"HTTP {response.status_code}",
                    "content": response.text,
                    "headers": dict(response.headers),
                    "task_id": task_id,
                }

            # Final failure after retries
            return {
                "success": False,
                "status_code": response.status_code,
                "error": f"HTTP {response.status_code} after {3} attempts",
                "content": response.text,
                "headers": dict(response.headers),
                "task_id": task_id,
            }
</file>

<file path="src/baliza/extractor.py">
"""PNCP Data Extractor V2 - True Async Architecture
Based on steel-man pseudocode: endpoint 
365-day ranges 
async pagination
"""

import asyncio
import calendar
import contextlib
import json
import logging
import random
import re
import signal
import sys
import time
import uuid
from datetime import date, datetime
from enum import Enum

# Import configuration from the config module
from baliza.config import PNCP_ENDPOINTS, PNCP_BASE_URL, CONCURRENCY, PAGE_SIZE, REQUEST_TIMEOUT, USER_AGENT
from pathlib import Path
from typing import Any

import duckdb
import httpx
import orjson
import typer
from filelock import FileLock, Timeout
from rich.console import Console
from rich.progress import (
    BarColumn,
    Progress,
    TextColumn,
    TimeElapsedColumn,
)
from tenacity import retry, stop_after_attempt, wait_exponential_jitter

from baliza.pncp_client import PNCPClient
from baliza.pncp_task_planner import PNCPTaskPlanner
from baliza.pncp_writer import PNCPWriter, connect_utf8, BALIZA_DB_PATH, DATA_DIR

# Configure standard logging com UTF-8
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)

console = Console(force_terminal=True, legacy_windows=False, stderr=False)
logger = logging.getLogger(__name__)


# JSON parsing moved to utils.py to avoid circular imports
from baliza.utils import parse_json_robust




class AsyncPNCPExtractor:
    """True async PNCP extractor with semaphore back-pressure."""

    def __init__(self, concurrency: int = CONCURRENCY):
        self.concurrency = concurrency
        self.client = PNCPClient(concurrency=concurrency)
        self.task_planner = PNCPTaskPlanner() # Instantiate the task planner
        self.writer = PNCPWriter() # Instantiate the writer
        self.run_id = str(uuid.uuid4())

        # Statistics
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.total_records = 0

        # Queue-based processing
        queue_size = max(32, concurrency * 10)
        self.page_queue: asyncio.Queue[dict[str, Any] | None] = asyncio.Queue(
            maxsize=queue_size
        )
        self.writer_running = False

        # Graceful shutdown handling
        self.shutdown_event = asyncio.Event()
        self.running_tasks = set()

    def setup_signal_handlers(self):
        """Setup signal handlers for graceful shutdown - Windows compatible."""

        def signal_handler(signum, frame):
            console.print(
                "\n⚠️ [yellow]Received Ctrl+C, initiating graceful shutdown...[/yellow]"
            )
            self.shutdown_event.set()
            # Cancel all running tasks
            for task in self.running_tasks:
                if not task.done():
                    task.cancel()

        # Windows-compatible signal handlers
        try:
            if hasattr(signal, "SIGINT"):
                signal.signal(signal.SIGINT, signal_handler)
            if hasattr(signal, "SIGTERM"):
                signal.signal(signal.SIGTERM, signal_handler)
        except (ValueError, AttributeError) as e:
            logger.warning(f"Could not setup signal handlers: {e}")

    async def __aenter__(self):
        """Async context manager entry."""
        await self.client.__aenter__()
        await self.writer.__aenter__()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit with graceful cleanup."""
        await self.client.__aexit__(exc_type, exc_val, exc_tb)
        await self.writer.__aexit__(exc_type, exc_val, exc_tb)
        await self._graceful_shutdown()

    async def _graceful_shutdown(self):
        """Graceful shutdown of all connections and resources."""
        try:
            # Signal writer to stop gracefully
            if hasattr(self, "writer_running") and self.writer_running:
                await self.page_queue.put(None)  # Send sentinel

            console.print(
                "✅ [bold green]Graceful shutdown completed successfully![/bold green]"
            )

        except Exception as e:
            console.print(f"⚠️ Shutdown error: {e}")

    async def _fetch_with_backpressure(
        self, url: str, params: dict[str, Any], task_id: str | None = None
    ) -> dict[str, Any]:
        """Fetch with semaphore back-pressure and retry logic."""
        self.total_requests += 1
        response = await self.client.fetch_with_backpressure(url, params, task_id)

        if response["success"]:
            self.successful_requests += 1
        else:
            self.failed_requests += 1
        return response

    async def _plan_tasks(self, start_date: date, end_date: date):
        """Phase 1: Populate the control table with all necessary tasks."""
        console.print("Phase 1: Planning tasks...")
        tasks_to_create = await self.task_planner.plan_tasks(start_date, end_date)

        if tasks_to_create:
            # Schema migration - update constraint to include modalidade
            try:
                # Check if we need to migrate the constraint
                existing_constraints = self.writer.conn.execute(
                    "SELECT constraint_name FROM information_schema.table_constraints WHERE table_name = 'pncp_extraction_tasks' AND constraint_type = 'UNIQUE'"
                ).fetchall()

                # If we have the old constraint, we need to migrate
                for constraint in existing_constraints:
                    if constraint[0] == "unique_task":
                        # Check if constraint includes modalidade
                        constraint_cols = self.writer.conn.execute(
                            "SELECT column_name FROM information_schema.key_column_usage WHERE constraint_name = 'unique_task' AND table_name = 'pncp_extraction_tasks'"
                        ).fetchall()

                        if (
                            len(constraint_cols) == 2
                        ):  # Old constraint (endpoint_name, data_date)
                            # Drop old constraint and recreate with modalidade
                            self.writer.conn.execute(
                                "ALTER TABLE psa.pncp_extraction_tasks DROP CONSTRAINT unique_task"
                            )
                            self.writer.conn.execute(
                                "ALTER TABLE psa.pncp_extraction_tasks ADD CONSTRAINT unique_task UNIQUE (endpoint_name, data_date, modalidade)"
                            )
                            self.writer.conn.commit()
                            break

            except duckdb.Error:
                # If migration fails, continue - the new schema will handle it
                pass

            self.writer.conn.executemany(
                """
                INSERT INTO psa.pncp_extraction_tasks (task_id, endpoint_name, data_date, modalidade)
                VALUES (?, ?, ?, ?)
                ON CONFLICT (task_id) DO NOTHING
                """,
                tasks_to_create,
            )
            self.writer.conn.commit()
        console.print(
            f"Planning complete. {len(tasks_to_create)} potential tasks identified."
        )

    async def _discover_tasks(self, progress: Progress):
        """Phase 2: Get metadata for all PENDING tasks."""
        pending_tasks = self.writer.conn.execute(
            "SELECT task_id, endpoint_name, data_date, modalidade FROM psa.pncp_extraction_tasks WHERE status = 'PENDING'"
        ).fetchall()

        if not pending_tasks:
            console.print("Phase 2: Discovery - No pending tasks to discover.")
            return

        discovery_progress = progress.add_task(
            "[cyan]Phase 2: Discovery", total=len(pending_tasks)
        )

        discovery_jobs = []
        for task_id, endpoint_name, data_date, modalidade in pending_tasks:
            # Mark as DISCOVERING
            self.writer.conn.execute(
                "UPDATE psa.pncp_extraction_tasks SET status = 'DISCOVERING', updated_at = now() WHERE task_id = ?",
                [task_id],
            )

            endpoint = next(
                (ep for ep in PNCP_ENDPOINTS if ep["name"] == endpoint_name), None
            )
            if not endpoint:
                continue

            # Respect minimum page size requirements
            page_size = endpoint.get("page_size", PAGE_SIZE)
            min_page_size = endpoint.get("min_page_size", 1)
            actual_page_size = max(page_size, min_page_size)

            params = {
                "tamanhoPagina": actual_page_size,
                "pagina": 1,
            }
            if endpoint["supports_date_range"]:
                params[endpoint["date_params"][0]] = self.task_planner._format_date(data_date)
                params[endpoint["date_params"][1]] = self.task_planner._format_date(
                    self.task_planner._monthly_chunks(data_date, data_date)[0][1]
                )
            elif endpoint.get("requires_single_date", False):
                # For single-date endpoints, use the data_date directly (should be end_date)
                # The data_date should already be correct (future date if needed) from task planning
                params[endpoint["date_params"][0]] = self.task_planner._format_date(data_date)
            else:
                # For endpoints that don't support date ranges, use end of month chunk
                params[endpoint["date_params"][0]] = self.task_planner._format_date(
                    self.task_planner._monthly_chunks(data_date, data_date)[0][1]
                )

            # Add modalidade if this task has one
            if modalidade is not None:
                params["codigoModalidadeContratacao"] = modalidade

            discovery_jobs.append(
                self._fetch_with_backpressure(endpoint["path"], params, task_id=task_id)
            )

        self.writer.conn.commit()  # Commit status change to DISCOVERING

        for future in asyncio.as_completed(discovery_jobs):
            response = await future
            task_id = response.get("task_id")

            if response["success"]:
                total_records = response.get("total_records", 0)
                total_pages = response.get("total_pages", 1)

                # If total_pages is 0, it means no records, so it's 1 page of empty results.
                if total_pages == 0:
                    total_pages = 1

                missing_pages = list(range(2, total_pages + 1))

                self.writer.conn.execute(
                    """
                    UPDATE psa.pncp_extraction_tasks
                    SET status = ?, total_pages = ?, total_records = ?, missing_pages = ?, updated_at = now()
                    WHERE task_id = ?
                    """,
                    [
                        "FETCHING" if missing_pages else "COMPLETE",
                        total_pages,
                        total_records,
                        json.dumps(missing_pages),
                        task_id,
                    ],
                )

                # Enqueue page 1 response
                # Task ID format: {endpoint_name}_{YYYY-MM-DD} or {endpoint_name}_{YYYY-MM-DD}_modalidade_{N}
                # Since endpoint names can contain underscores, we need to extract the date part from the end
                match = re.match(
                    r"^(.+)_(\d{4}-\d{2}-\d{2})(?:_modalidade_\d+)?$", task_id
                )
                if match:
                    endpoint_name_part = match.group(1)
                    data_date_str = match.group(2)
                    data_date = datetime.fromisoformat(data_date_str).date()

                page_1_response = {
                    "endpoint_url": f"{PNCP_BASE_URL}{response['url']}",
                    "endpoint_name": endpoint_name_part,
                    "request_parameters": response["params"],
                    "response_code": response["status_code"],
                    "response_content": response["content"],
                    "response_headers": response["headers"],
                    "data_date": data_date,
                    "run_id": self.run_id,
                    "total_records": total_records,  # This might not be accurate for pages > 1
                    "total_pages": total_pages,  # This might not be accurate for pages > 1
                    "current_page": 1,
                    "page_size": endpoint.get("page_size", PAGE_SIZE),
                }
                await self.page_queue.put(page_1_response)

            else:
                error_message = f"HTTP {response.get('status_code')}: {response.get('error', 'Unknown')}"
                self.writer.conn.execute(
                    "UPDATE psa.pncp_extraction_tasks SET status = 'FAILED', last_error = ?, updated_at = now() WHERE task_id = ?",
                    [error_message, task_id],
                )

            self.writer.conn.commit()
            progress.update(discovery_progress, advance=1)

    async def _fetch_page(
        self,
        endpoint_name: str,
        data_date: date,
        modalidade: int | None,
        page_number: int,
    ):
        """Helper to fetch a single page and enqueue it."""
        endpoint = next(
            (ep for ep in PNCP_ENDPOINTS if ep["name"] == endpoint_name), None
        )
        if not endpoint:
            return

        # Respect minimum page size requirements
        page_size = endpoint.get("page_size", PAGE_SIZE)
        min_page_size = endpoint.get("min_page_size", 1)
        actual_page_size = max(page_size, min_page_size)

        params = {
            "tamanhoPagina": actual_page_size,
            "pagina": page_number,
        }

        if endpoint["supports_date_range"]:
            params[endpoint["date_params"][0]] = self.task_planner._format_date(data_date)
            params[endpoint["date_params"][1]] = self.task_planner._format_date(
                self.task_planner._monthly_chunks(data_date, data_date)[0][1]
            )
        elif endpoint.get("requires_single_date", False):
            # For single-date endpoints, use the data_date directly (should be end_date)
            # The data_date should already be correct (future date if needed) from task planning
            params[endpoint["date_params"][0]] = self.task_planner._format_date(data_date)
        else:
            # For endpoints that don't support date ranges, use end of month chunk
            params[endpoint["date_params"][0]] = self.task_planner._format_date(
                self.task_planner._monthly_chunks(data_date, data_date)[0][1]
            )

        # Add modalidade if this endpoint uses it
        if modalidade is not None:
            params["codigoModalidadeContratacao"] = modalidade

        response = await self._fetch_with_backpressure(endpoint["path"], params)

        # Enqueue the response for the writer worker
        page_response = {
            "endpoint_url": f"{PNCP_BASE_URL}{endpoint['path']}",
            "endpoint_name": endpoint_name,
            "request_parameters": params,
            "response_code": response["status_code"],
            "response_content": response["content"],
            "response_headers": response["headers"],
            "data_date": data_date,
            "run_id": self.run_id,
            "total_records": response.get(
                "total_records", 0
            ),  # This might not be accurate for pages > 1
            "total_pages": response.get(
                "total_pages", 0
            ),  # This might not be accurate for pages > 1
            "current_page": page_number,
            "page_size": endpoint.get("page_size", PAGE_SIZE),
        }
        await self.page_queue.put(page_response)
        return response

    async def _execute_tasks(self, progress: Progress):
        """Phase 3: Fetch all missing pages for FETCHING and PARTIAL tasks."""

        # Use unnest to get a list of all pages to fetch
        pages_to_fetch_query = """
SELECT t.task_id, t.endpoint_name, t.data_date, t.modalidade, CAST(p.page_number AS INTEGER) as page_number
FROM psa.pncp_extraction_tasks t,
     unnest(json_extract(t.missing_pages, '$')::INTEGER[]) AS p(page_number)
WHERE t.status IN ('FETCHING', 'PARTIAL');
        """
        pages_to_fetch = self.writer.conn.execute(pages_to_fetch_query).fetchall()

        if not pages_to_fetch:
            console.print("Phase 3: Execution - No pages to fetch.")
            return

        # Group pages by endpoint only
        endpoint_pages = {}
        for (
            task_id,
            endpoint_name,
            data_date,
            modalidade,
            page_number,
        ) in pages_to_fetch:
            if endpoint_name not in endpoint_pages:
                endpoint_pages[endpoint_name] = []
            endpoint_pages[endpoint_name].append(
                (task_id, data_date, modalidade, page_number)
            )

        # Create progress bars for each endpoint with beautiful colors
        progress_bars = {}
        endpoint_colors = {
            "contratos_publicacao": "green",
            "contratos_atualizacao": "blue",
            "atas_periodo": "cyan",
            "atas_atualizacao": "bright_cyan",
            "contratacoes_publicacao": "yellow",
            "contratacoes_atualizacao": "magenta",
            "pca_atualizacao": "bright_blue",
            "instrumentoscobranca_inclusao": "bright_green",
            "contratacoes_proposta": "bright_yellow",
        }

        console.print("\n🚀 [bold blue]PNCP Data Extraction Progress[/bold blue]\n")

        for endpoint_name, pages in endpoint_pages.items():
            # Get endpoint description and color
            endpoint_desc = next(
                (
                    ep["description"]
                    for ep in PNCP_ENDPOINTS
                    if ep["name"] == endpoint_name
                ),
                endpoint_name,
            )
            color = endpoint_colors.get(endpoint_name, "white")

            # Create beautiful, colorful progress description
            task_description = (
                f"[{color}]{endpoint_desc}[/{color}] - [dim]{len(pages):,} pages[/dim]"
            )
            progress_bars[endpoint_name] = progress.add_task(
                task_description, total=len(pages)
            )

        # Execute all fetches
        fetch_tasks = []
        for endpoint_name, pages in endpoint_pages.items():
            for task_id, data_date, modalidade, page_number in pages:
                # Check for shutdown before creating new tasks
                if self.shutdown_event.is_set():
                    console.print(
                        "⚠️ [yellow]Shutdown requested, stopping task creation...[/yellow]"
                    )
                    break

                task = asyncio.create_task(
                    self._fetch_page_with_progress(
                        endpoint_name,
                        data_date,
                        modalidade,
                        page_number,
                        progress,
                        progress_bars[endpoint_name],
                    )
                )
                fetch_tasks.append(task)
                self.running_tasks.add(task)

        # Wait for all tasks to complete with graceful shutdown support
        try:
            await asyncio.gather(*fetch_tasks, return_exceptions=True)
        except asyncio.CancelledError:
            console.print(
                "⚠️ [yellow]Tasks cancelled during shutdown, cleaning up...[/yellow]"
            )
            raise
        finally:
            # Clean up completed tasks
            for task in fetch_tasks:
                self.running_tasks.discard(task)

        # Print beautiful overall summary
        total_pages = sum(len(pages) for pages in endpoint_pages.values())
        console.print(
            f"\n✅ [bold green]Overall: {total_pages:,} pages completed successfully![/bold green]"
        )
        console.print("")

    async def _fetch_page_with_progress(
        self,
        endpoint_name: str,
        data_date: date,
        modalidade: int | None,
        page_number: int,
        progress: Progress,
        progress_bar_id: int,
    ):
        """Fetch a page and update the progress bar with graceful shutdown support."""
        try:
            # Check for shutdown signal
            if self.shutdown_event.is_set():
                console.print(
                    "⚠️ [yellow]Shutdown requested, skipping page fetch...[/yellow]"
                )
                return

            await self._fetch_page(endpoint_name, data_date, modalidade, page_number)
            progress.update(progress_bar_id, advance=1)
        except asyncio.CancelledError:
            console.print("⚠️ [yellow]Page fetch cancelled during shutdown[/yellow]")
            raise
        except Exception as e:
            logger.error(
                f"Failed to fetch page {page_number} for {endpoint_name} {data_date} modalidade {modalidade}: {e}"
            )
            progress.update(
                progress_bar_id, advance=1
            )  # Still advance to show completion

    async def _reconcile_tasks(self):
        """Phase 4: Update task status based on downloaded data."""
        console.print("Phase 4: Reconciling tasks...")

        tasks_to_reconcile = self.writer.conn.execute(
            "SELECT task_id, endpoint_name, data_date, modalidade, total_pages FROM psa.pncp_extraction_tasks WHERE status IN ('FETCHING', 'PARTIAL')"
        ).fetchall()

        for (
            task_id,
            endpoint_name,
            data_date,
            modalidade,
            total_pages,
        ) in tasks_to_reconcile:
            # Find out which pages were successfully downloaded for this task
            # We need to check the request_parameters for modalidade if it exists
            if modalidade is not None:
                downloaded_pages_result = self.writer.conn.execute(
                    """
                    SELECT DISTINCT current_page
                    FROM psa.pncp_raw_responses
                    WHERE endpoint_name = ? AND data_date = ? AND response_code = 200
                    AND json_extract(request_parameters, '$.codigoModalidadeContratacao') = ?
                    """,
                    [endpoint_name, data_date, modalidade],
                ).fetchall()
            else:
                downloaded_pages_result = self.writer.conn.execute(
                    """
                    SELECT DISTINCT current_page
                    FROM psa.pncp_raw_responses
                    WHERE endpoint_name = ? AND data_date = ? AND response_code = 200
                    AND json_extract(request_parameters, '$.codigoModalidadeContratacao') IS NULL
                    """,
                    [endpoint_name, data_date],
                ).fetchall()

            downloaded_pages = {row[0] for row in downloaded_pages_result}

            # Generate the full set of expected pages
            all_pages = set(range(1, total_pages + 1))

            # Calculate the new set of missing pages
            new_missing_pages = sorted(all_pages - downloaded_pages)

            if not new_missing_pages:
                # All pages are downloaded
                self.writer.conn.execute(
                    "UPDATE psa.pncp_extraction_tasks SET status = 'COMPLETE', missing_pages = '[]', updated_at = now() WHERE task_id = ?",
                    [task_id],
                )
            else:
                # Some pages are still missing
                self.writer.conn.execute(
                    "UPDATE psa.pncp_extraction_tasks SET status = 'PARTIAL', missing_pages = ?, updated_at = now() WHERE task_id = ?",
                    [json.dumps(new_missing_pages), task_id],
                )

        self.writer.conn.commit()
        console.print("Reconciliation complete.")

    async def extract_data(
        self, start_date: date, end_date: date, force: bool = False
    ) -> dict[str, Any]:
        """Main extraction method using a task-based, phased architecture."""
        logger.info(
            f"Extraction started: {start_date.isoformat()} to {end_date.isoformat()}, "
            f"concurrency={self.concurrency}, run_id={self.run_id}, force={force}"
        )
        start_time = time.time()

        if force:
            console.print(
                "[yellow]Force mode enabled - will reset tasks and re-extract all data.[/yellow]"
            )
            self.writer.conn.execute("DELETE FROM psa.pncp_extraction_tasks")
            self.writer.conn.execute("DELETE FROM psa.pncp_raw_responses")
            self.writer.conn.commit()

        # Setup signal handlers now that we're in async context
        self.setup_signal_handlers()

        # Start writer worker
        self.writer_running = True
        writer_task = asyncio.create_task(self.writer.writer_worker(self.page_queue, commit_every=100))
        self.running_tasks.add(writer_task)

        # --- Main Execution Flow ---

        # Phase 1: Planning
        await self._plan_tasks(start_date, end_date)

        with Progress(
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
            TextColumn("•"),
            TextColumn("{task.completed}/{task.total}"),
            TimeElapsedColumn(),
            console=console,
            refresh_per_second=10,
        ) as progress:
            # Phase 2: Discovery
            await self._discover_tasks(progress)

            # Phase 3: Execution
            await self._execute_tasks(progress)

        # Wait for writer to process all enqueued pages
        try:
            await self.page_queue.join()
            await self.page_queue.put(None)  # Send sentinel
            await writer_task
        except asyncio.CancelledError:
            console.print("⚠️ [yellow]Writer task cancelled during shutdown[/yellow]")
            # Ensure writer task is cancelled
            if not writer_task.done():
                writer_task.cancel()
                try:
                    await writer_task
                except asyncio.CancelledError:
                    pass
        finally:
            self.running_tasks.discard(writer_task)

        # Phase 4: Reconciliation
        await self._reconcile_tasks()

        # --- Final Reporting ---
        duration = time.time() - start_time

        # Fetch final stats from the control table
        total_tasks = self.writer.conn.execute(
            "SELECT COUNT(*) FROM psa.pncp_extraction_tasks"
        ).fetchone()[0]
        complete_tasks = self.writer.conn.execute(
            "SELECT COUNT(*) FROM psa.pncp_extraction_tasks WHERE status = 'COMPLETE'"
        ).fetchone()[0]
        failed_tasks = self.writer.conn.execute(
            "SELECT COUNT(*) FROM psa.pncp_extraction_tasks WHERE status = 'FAILED'"
        ).fetchone()[0]

        # Fetch stats from raw responses
        total_records_sum = (
            self.writer.conn.execute(
                "SELECT SUM(total_records) FROM psa.pncp_extraction_tasks WHERE status = 'COMPLETE'"
            ).fetchone()[0]
            or 0
        )

        total_results = {
            "run_id": self.run_id,
            "start_date": start_date,
            "end_date": end_date,
            "total_tasks": total_tasks,
            "complete_tasks": complete_tasks,
            "failed_tasks": failed_tasks,
            "total_records_extracted": total_records_sum,
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "failed_requests": self.failed_requests,
            "duration": duration,
        }

        console.print("\n🎉 Extraction Complete!")
        console.print(
            f"Total Tasks: {total_tasks:,} ({complete_tasks:,} complete, {failed_tasks:,} failed)"
        )
        console.print(f"Total Records: {total_records_sum:,}")
        console.print(f"Duration: {duration:.1f}s")

        return total_results


def _get_current_month_end() -> str:
    """Get the last day of the current month as YYYY-MM-DD."""
    today = date.today()
    # Get last day of current month safely
    _, last_day = calendar.monthrange(today.year, today.month)
    month_end = today.replace(day=last_day)
    return month_end.strftime("%Y-%m-%d")


# CLI interface
app = typer.Typer()


@app.command()
def extract(
    start_date: str = "2021-01-01",
    end_date: str = None,
    concurrency: int = CONCURRENCY,
    force: bool = False,
):
    """Extract data using true async architecture."""
    start_dt = datetime.strptime(start_date, "%Y-%m-%d").date()
    # Use current month end if no end_date provided
    if end_date is None:
        end_date = _get_current_month_end()
    end_dt = datetime.strptime(end_date, "%Y-%m-%d").date()

    async def main():
        async with AsyncPNCPExtractor(concurrency=concurrency) as extractor:
            results = await extractor.extract_data(start_dt, end_dt, force)

            # Save results
            results_file = (
                DATA_DIR / f"async_extraction_results_{results['run_id']}.json"
            )
            with Path(results_file).open("w", encoding="utf-8") as f:
                json.dump(results, f, indent=2, default=str)

            console.print(f"Results saved to: {results_file}")

    asyncio.run(main())


@app.command()
def stats():
    """Show extraction statistics."""
    conn = connect_utf8(str(BALIZA_DB_PATH))

    # Overall stats
    total_responses = conn.execute(
        "SELECT COUNT(*) FROM psa.pncp_raw_responses"
    ).fetchone()[0]
    success_responses = conn.execute(
        "SELECT COUNT(*) FROM psa.pncp_raw_responses WHERE response_code = 200"
    ).fetchone()[0]

    console.print(f"=== Total Responses: {total_responses:,} ===")
    console.print(f"Successful: {success_responses:,}")
    console.print(f"❌ Failed: {total_responses - success_responses:,}")

    if total_responses > 0:
        console.print(f"Success Rate: {success_responses / total_responses * 100:.1f}%")

    # Endpoint breakdown
    endpoint_stats = conn.execute(
        """
        SELECT endpoint_name, COUNT(*) as responses, SUM(total_records) as total_records
        FROM psa.pncp_raw_responses
        WHERE response_code = 200
        GROUP BY endpoint_name
        ORDER BY total_records DESC
    """
    ).fetchall()

    console.print("\n=== Endpoint Statistics ===")
    for name, responses, records in endpoint_stats:
        console.print(f"  {name}: {responses:,} responses, {records:,} records")

    conn.close()


if __name__ == "__main__":
    # 1. Trave o runtime em UTF-8 - reconfigure streams logo no início
    for std in (sys.stdin, sys.stdout, sys.stderr):
        std.reconfigure(encoding="utf-8", errors="surrogateescape")
    app()
</file>

<file path="README.md">
<div align="center">
  <img src="assets/logo.png" alt="Logo do BALIZA: Um farol de dados sobre um mar de informações, com o nome BALIZA abaixo" width="400">
  <br>
  <h3>Backup Aberto de Licitações Zelando pelo Acesso</h3>
  <p><strong>Guardando a memória das compras públicas no Brasil.</strong></p>
  <p>
    <a href="https://github.com/franklinbaldo/baliza/blob/main/LICENSE"><img src="https://img.shields.io/github/license/franklinbaldo/baliza?style=for-the-badge" alt="Licença"></a>
    <a href="https://github.com/franklinbaldo/baliza/actions/workflows/baliza_daily_run.yml"><img src="https://img.shields.io/github/actions/workflow/status/franklinbaldo/baliza/baliza_daily_run.yml?branch=main&label=Build%20Di%C3%A1rio&style=for-the-badge" alt="Status do Build"></a>
    <a href="https://pypi.org/project/baliza/"><img src="https://img.shields.io/pypi/v/baliza?style=for-the-badge" alt="Versão no PyPI"></a>
  </p>
</div>

> **BALIZA** é uma ferramenta de código aberto que extrai, armazena e estrutura dados do Portal Nacional de Contratações Públicas (PNCP), criando um backup histórico confiável para análises e auditoria da maior plataforma de compras públicas do país.

---

## 🚀 Para Análise de Dados (Comece Aqui)

Seu objetivo é **analisar os dados** de contratações públicas, sem a necessidade de executar o processo de extração. Com o BALIZA, você pode fazer isso em segundos, diretamente no seu navegador ou ambiente de análise preferido.

<a href="https://colab.research.google.com/github/colab-examples/colab-badge-example/blob/main/colab-badge-example.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

O banco de dados completo e atualizado diariamente está hospedado no [Internet Archive](https://archive.org/details/baliza-pncp) em formato DuckDB, e pode ser consultado remotamente.

**Exemplo de Análise Rápida com Python:**
Não é preciso baixar nada! Apenas instale as bibliotecas e execute o código.

```python
# Instale as bibliotecas necessárias
# !pip install duckdb pandas

import duckdb

# Conecte-se remotamente ao banco de dados no Internet Archive
# NOTA: Substitua 'baliza-latest.duckdb' pelo nome do arquivo mais recente disponível no IA
DB_URL = "https://archive.org/download/baliza-pncp/baliza-latest.duckdb"

con = duckdb.connect(database=DB_URL, read_only=True)

# Exemplo: Top 10 órgãos por valor total de contratos (camada GOLD)
top_orgaos = con.sql("""
    SELECT
        nome_orgao,
        SUM(valor_total_contrato) AS valor_total
    FROM mart_procurement_analytics
    GROUP BY nome_orgao
    ORDER BY valor_total DESC
    LIMIT 10;
""").to_df()

print(top_orgaos)
```

- ✅ **Zero Setup:** Comece a analisar em menos de um minuto.
- ✅ **Sempre Atualizado:** Acesse os dados mais recentes coletados pelo workflow diário.
- ✅ **Integração Total:** Funciona perfeitamente com Pandas, Polars, Jupyter Notebooks e outras ferramentas do ecossistema PyData.


## 🎯 O Problema: A Memória Volátil da Transparência

O Portal Nacional de Contratações Públicas (PNCP) é um avanço, mas sua API **não garante um histórico permanente dos dados**. Informações podem ser alteradas ou desaparecer, comprometendo análises de longo prazo, auditorias e o controle social.

## ✨ A Solução: Um Backup para o Controle Social

O BALIZA atua como uma **âncora de dados para o PNCP**. Ele sistematicamente coleta, armazena e estrutura os dados, garantindo que a memória das contratações públicas brasileiras seja preservada e acessível a todos.

-   🛡️ **Resiliência:** Cria um backup imune a mudanças na API ou indisponibilidades do portal.
-   🕰️ **Séries Históricas:** Constrói um acervo completo e cronológico.
-   🔍 **Dados Estruturados para Análise:** Transforma respostas JSON em tabelas limpas e prontas para SQL.
-   🌍 **Aberto por Natureza:** Utiliza formatos abertos (DuckDB, Parquet), garantindo que os dados sejam seus, para sempre.


## 🔧 Para Desenvolvedores e Coletores de Dados

Seu objetivo é **executar o processo de extração** para criar ou atualizar o banco de dados localmente.

**Pré-requisitos:**
- Python 3.11+
- [uv](https://github.com/astral-sh/uv) (um instalador de pacotes Python extremamente rápido)

**Instalação e Execução:**
```bash
# 1. Clone o repositório
git clone https://github.com/franklinbaldo/baliza.git
cd baliza

# 2. Instale as dependências com uv
uv sync

# 3. Execute a extração (isso pode levar horas!)
# Por padrão, extrai de 2021 até o mês atual
uv run baliza extract
```

**Principais Comandos:**
| Comando | Descrição |
|---|---|
| `uv run baliza extract` | Inicia a extração de dados do PNCP. |
| `uv run baliza extract --concurrency 4` | Limita o número de requisições paralelas. |
| `uv run dbt run --profiles-dir dbt_baliza` | Executa os modelos de transformação do dbt. |
| `uv run baliza stats` | Mostra estatísticas sobre os dados já baixados. |


## ⚙️ Como Funciona

O BALIZA opera com uma arquitetura de extração em fases, garantindo que o processo seja robusto e possa ser retomado em caso de falhas.

```mermaid
flowchart TD
    A[API do PNCP] -->|1. Requisições| B{BALIZA};
    subgraph BALIZA [Processo de Extração]
        direction LR
        B1(Planejamento) --> B2(Descoberta) --> B3(Execução) --> B4(Reconciliação);
    end
    B -->|2. Armazenamento| C{DuckDB Local};
    C -- "3. Transformação (dbt)" --> D[Tabelas Limpas e Analíticas];
    D -->|4. Análise| E(Jornalistas, Pesquisadores, Cidadãos);
```
_**Legenda:** O BALIZA orquestra a coleta da API do PNCP, armazena os dados brutos em um banco DuckDB e, com dbt, os transforma em insumos para análise._


## 🤖 Servidor de Análise com IA (MCP)

O BALIZA inclui um servidor compatível com o **Model Context Protocol (MCP)** da Anthropic. Isso permite que modelos de linguagem, como o Claude, se conectem diretamente aos seus dados de licitações para realizar análises complexas, consultas e visualizações de forma segura.

**Como Funciona:**
Em vez de você fazer uma pergunta diretamente, você inicia um servidor local. Um LLM compatível com MCP pode então se conectar a este servidor para usar as "ferramentas" que ele oferece, como a capacidade de executar consultas SQL no seu banco de dados.

**Exemplo de Uso:**
```bash
# 1. Inicie o servidor MCP
# O servidor ficará em execução, aguardando conexões de um LLM
uv run baliza mcp

# 2. Conecte seu LLM ao servidor
# Use uma ferramenta como o MCP Workbench da Anthropic ou configure um
# cliente LLM para se conectar a http://127.0.0.1:8000.
```

O servidor expõe as seguintes capacidades ao LLM:
- **`baliza/available_datasets`**: Lista os conjuntos de dados disponíveis.
- **`baliza/dataset_schema`**: Descreve as colunas e tipos de dados de um dataset.
- **`baliza/execute_sql_query`**: Executa uma consulta SQL de leitura (`SELECT`) nos dados.

- 🧠 **Análise Profunda:** Permite que o LLM explore os dados de forma autônoma para responder a perguntas complexas.
- 🔒 **Segurança em Primeiro Lugar:** O servidor só permite consultas de leitura (`SELECT`), impedindo qualquer modificação nos dados.
- ⚙️ **Padrão Aberto:** Baseado no Model Context Protocol, garantindo interoperabilidade.

Para saber mais sobre a arquitetura, leia nosso [**Guia Teórico do MCP**](./docs/mcp_guide.md).


## 🏗️ Arquitetura e Tecnologias

| Camada | Tecnologias | Propósito |
|---|---|---|
| **Coleta** | Python, asyncio, httpx, tenacity | Extração eficiente, assíncrona e resiliente. |
| **Armazenamento** | DuckDB | Banco de dados analítico local, rápido e sem servidor. |
| **Transformação** | dbt (Data Build Tool) | Transforma dados brutos em modelos de dados limpos e confiáveis. |
| **Interface** | Typer, Rich | CLI amigável, informativa e com ótima usabilidade. |
| **Dependências**| uv (da Astral) | Gerenciamento de pacotes e ambientes virtuais de alta performance. |

## 🗺️ Roadmap do Projeto

-   [✅] **Fase 1: Fundação** - Extração resiliente, armazenamento em DuckDB, CLI funcional.
-   [⏳] **Fase 2: Expansão e Acessibilidade** - Modelos dbt analíticos, exportação para Parquet, documentação aprimorada.
-   [🗺️] **Fase 3: Ecossistema e Análise** - Dashboards de cobertura, sistema de plugins, tutoriais.
-   [💡] **Futuro:** Painel de monitoramento de dados, detecção de anomalias, integração com mais fontes.

## 🙌 Como Contribuir

**Sua ajuda é fundamental para fortalecer o controle social no Brasil!**

1.  **Reporte um Bug:** Encontrou um problema? [Abra uma issue](https://github.com/franklinbaldo/baliza/issues).
2.  **Sugira uma Melhoria:** Tem uma ideia? Adoraríamos ouvi-la nas issues.
3.  **Desenvolva:** Faça um fork, crie uma branch e envie um Pull Request.
4.  **Dissemine:** Use os dados, crie análises, publique reportagens e compartilhe o projeto!

## 📜 Licença

Este projeto é licenciado sob a **Licença MIT**. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
</file>

<file path="pyproject.toml">
[project]
name = "baliza"
version = "0.1.0"
description = "BALIZA: Backup Aberto de Licitações Zelando pelo Acesso - Historical archive of Brazilian public procurement data"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "typer",
    "duckdb", # Native Parquet support with built-in compression
    "httpx", # HTTP client for API requests
    "h2", # HTTP/2 support for httpx
    "pandas>=2.3.1",
    "orjson", # Fast JSON parsing with fallback
    "aiolimiter>=1.2.1",
    "filelock", # File locking to prevent database conflicts
    "anthropic", # Client for Claude LLM
    "fastmcp", # MCP Server library
    "pyarrow", # Parquet engine for pandas and duckdb
    "tenacity>=9.1.2",
]

[project.scripts]
baliza = "baliza.cli:app"

[project.optional-dependencies]
dev = [
    "pytest",
    "pytest-mock",
]
analytics = [
    "dbt-core>=1.7.0",
    "dbt-duckdb>=1.7.0",
]

[dependency-groups]
dev = [
    "mypy>=1.16.1",
    "pre-commit>=4.2.0",
    "pytest>=8.4.1",
    "pytest-mock>=3.14.1",
    "ruff>=0.12.3",
    "mkdocs-material>=9.1.21",
    "mkdocs-gen-files>=0.5.0",
    "mkdocs-literate-nav>=0.6.0",
]

# Ruff configuration for linting and formatting
[tool.ruff]
target-version = "py311"
line-length = 88

# Exclude specific files/directories
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".git-rewrite",
    ".hg",
    ".mypy_cache",
    ".nox",
    ".pants.d",
    ".pytype",
    ".ruff_cache",
    ".svn",
    ".tox",
    ".venv",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "venv",
    "migrations",
    "*.pyi",
]

# Output configuration
output-format = "grouped"

[tool.ruff.lint]
select = [
    # Error
    "E",
    # Warning  
    "W",
    # Pyflakes
    "F",
    # pycodestyle
    "E", "W",
    # mccabe
    "C90",
    # isort
    "I",
    # pep8-naming
    "N",
    # pyupgrade
    "UP",
    # flake8-bugbear
    "B",
    # flake8-bandit
    "S",
    # flake8-blind-except
    "BLE",
    # flake8-comprehensions
    "C4",
    # flake8-debugger
    "T10",
    # flake8-simplify
    "SIM",
    # flake8-unused-arguments
    "ARG",
    # flake8-use-pathlib
    "PTH",
    # pandas-vet
    "PD",
    # tryceratops
    "TRY",
    # Ruff-specific rules
    "RUF",
]

ignore = [
    # Too aggressive
    "S101",  # Use of assert
    "S603",  # subprocess call - check for execution of untrusted input
    "S607",  # Starting a process with a partial executable path
    "TRY003", # Avoid specifying long messages outside the exception class
    "B008",  # Do not perform function calls in argument defaults
    "S608",  # Possible SQL injection vector (we use DuckDB safely)
    "BLE001", # Do not catch blind exception (sometimes needed)
    # Conflicts with formatter
    "E501",  # Line too long
    "W191",  # Indentation contains tabs
    "E111",  # Indentation is not a multiple of 4
    "E114",  # Indentation is not a multiple of 4 (comment)
    "E117",  # Over-indented
    "D206",  # Docstring should be indented with spaces
    "D300",  # Use """triple double quotes"""
    "Q000",  # Single quotes found but double quotes preferred
    "Q001",  # Single quote multiline found but triple quotes preferred
    "Q002",  # Single quote docstring found but triple quotes preferred
    "Q003",  # Change outer quotes to avoid escaping inner quotes
    "COM812", # Missing trailing comma
    "COM819", # Prohibited trailing comma
    "ISC001", # Implicitly concatenated string literals on one line
    "ISC002", # Implicitly concatenated string literals over continuation lines
]

[tool.ruff.lint.mccabe]
# Maximum cyclomatic complexity
max-complexity = 10

[tool.ruff.lint.isort]
known-first-party = ["baliza"]
known-third-party = [
    "duckdb",
    "httpx",
    "typer",
    "pytest",
    "rich",
]
section-order = [
    "future",
    "standard-library", 
    "third-party",
    "first-party",
    "local-folder"
]

[tool.ruff.lint.pep8-naming]
# Allow Pydantic's `@validator` decorator to trigger class method treatment.
classmethod-decorators = ["classmethod", "pydantic.validator"]

[tool.ruff.lint.flake8-bandit]
# S101: Use of assert
check-typed-exception = true

[tool.ruff.lint.pyupgrade]
# Preserve types, even if a file imports `from __future__ import annotations`.
keep-runtime-typing = true

# Mypy configuration for type checking
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true
show_error_codes = true

# Be less strict for some patterns
[[tool.mypy.overrides]]
module = [
    "tests.*",
    "scripts.*"
]
disallow_untyped_defs = false
disallow_incomplete_defs = false
disallow_untyped_decorators = false

# External library stubs
[[tool.mypy.overrides]]
module = [
    "duckdb.*",
    "httpx.*",
    "typer.*",
    "rich.*"
]
ignore_missing_imports = true

# Coverage configuration for pytest-cov
[tool.coverage.run]
source = ["src"]
omit = [
    "*/tests/*",
    "*/test_*",
    "*/__pycache__/*",
    "*/migrations/*",
    "*/venv/*",
    "*/.venv/*"
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:",
    "if __name__ == .__main__.:",
    "class .*\\bProtocol\\):",
    "@(abc\\.)?abstractmethod",
]

[tool.coverage.html]
directory = "htmlcov"

# Build system configuration
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

# Package discovery
[tool.setuptools.packages.find]
where = ["src"]
include = ["baliza*"]
exclude = ["tests*"]
</file>

</files>
