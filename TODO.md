# TODO: Database Optimization Implementation

Este arquivo cont√©m tarefas at√¥micas para implementar o [Plano de Otimiza√ß√£o da Base de Dados](docs/database-optimization-plan.md).

## Legenda
- üî• **CR√çTICO** - Deve ser feito primeiro, bloqueia outras tarefas
- ‚ö° **ALTO** - Impacto significativo na performance/arquitetura  
- üìä **M√âDIO** - Melhorias importantes mas n√£o cr√≠ticas
- üßπ **BAIXO** - Limpeza e otimiza√ß√µes menores

---

## Fase 1: Diagn√≥stico e Prepara√ß√£o

### üî• An√°lise da Documenta√ß√£o Oficial PNCP
**Refer√™ncia**: ADR-011, Plano Se√ß√£o 1.1

- [x] **F1.1** Criar script `scripts/audit_pncp_compliance.py`
  - [x] Extrair todos os ENUMs do `docs/openapi/MANUAL-PNCP-CONSULSTAS-VERSAO-1.md`
  - [x] Parsear `docs/openapi/api-pncp-consulta.json` para tipos precisos
  - [x] Comparar schema atual vs oficial
  - [x] Gerar relat√≥rio `docs/pncp-compliance-audit.md`

- [x] **F1.2** Mapear campos atuais para schema oficial
  - [x] Identificar campos faltantes no BALIZA
  - [x] Identificar campos n√£o-oficiais que devemos remover
  - [x] Listar todos os campos com tipos incorretos
  - [x] Documentar breaking changes necess√°rios

- [x] **F1.3** Extrair c√≥digos oficiais das 17 tabelas de dom√≠nio
  - [x] Modalidade de Contrata√ß√£o (13 valores)
  - [x] Situa√ß√£o da Contrata√ß√£o (4 valores)
  - [x] UF (27 valores)
  - [x] Natureza Jur√≠dica (47 valores)
  - [x] Salvar como `sql/seeds/pncp_domain_tables.sql`

### üî• Invent√°rio de SQL Inline
**Refer√™ncia**: ADR-009, Plano Se√ß√£o 1.2

- [x] **F1.4** Escanear c√≥digo Python para SQL inline
  - [x] Usar regex para encontrar strings SQL em `src/baliza/`
  - [x] Classificar por tipo: SELECT, INSERT, UPDATE, DELETE, DDL
  - [x] Medir complexidade (single table vs joins)
  - [x] Gerar `docs/sql-inventory.md` com mapeamento completo

- [x] **F1.5** Analisar performance atual
  - [x] Executar `pragma_storage_info()` em todas as tabelas
  - [x] Documentar tamanhos atuais e padr√µes de compress√£o
  - [x] Identificar tabelas com maior potencial de otimiza√ß√£o
  - [x] Baseline para compara√ß√£o p√≥s-otimiza√ß√£o

### Relat√≥rio de Conclus√£o da Fase 1
A Fase 1 foi executada integralmente, gerando os artefatos de diagn√≥stico abaixo. Estes arquivos devem ser utilizados como refer√™ncia para as pr√≥ximas etapas.
- `scripts/audit_pncp_compliance.py` produziu o relat√≥rio `docs/pncp-compliance-audit.md` com a an√°lise do schema oficial e os ENUMs extra√≠dos.
- `scripts/scan_inline_sql.py` identificou 71 consultas SQL, documentadas em `docs/sql-inventory.md`.
- `scripts/analyze_performance.py` registrou o estado inicial de armazenamento em `docs/performance-baseline.md`.
- Os CSVs de tabelas de dom√≠nio foram salvos em `dbt_baliza/seeds/domain_tables/`, prontos para uso pelo dbt.
Com a base de diagn√≥stico pronta, a Fase 2 pode iniciar a migra√ß√£o das queries com confian√ßa.

---

## Fase 2: Extra√ß√£o e Reorganiza√ß√£o SQL

### ‚ö° Estrutura de Diret√≥rios SQL
**Refer√™ncia**: ADR-009, Plano Se√ß√£o 2.1

- [x] **F2.1** Criar estrutura de diret√≥rios
```bash
mkdir -p sql/{ddl,dml/{inserts,updates,deletes},analytics,maintenance,migrations}
```

- [x] **F2.2** Implementar SQLLoader
  - [ ] Criar `src/baliza/sql_loader.py` conforme spec do plano
  - [ ] Adicionar cache de arquivos SQL
  - [ ] Implementar parametriza√ß√£o segura com `string.Template`
  - [ ] Adicionar valida√ß√£o de par√¢metros obrigat√≥rios
  - [ ] Testes unit√°rios para SQLLoader

### ‚ö° Migra√ß√£o de SQL Inline
**Refer√™ncia**: ADR-009

- [x] **F2.3** Extrair queries de inser√ß√£o
  - [ ] `src/baliza/pncp_writer.py` ‚Üí `sql/dml/inserts/pncp_content.sql`
  - [ ] `src/baliza/pncp_writer.py` ‚Üí `sql/dml/inserts/pncp_requests.sql`  
  - [ ] Adicionar headers padronizados com metadata
  - [ ] Converter hard-coded values para par√¢metros

- [x] **F2.4** Extrair queries anal√≠ticas
  - [ ] Dashboard queries ‚Üí `sql/analytics/deduplication_stats.sql`
  - [ ] Performance queries ‚Üí `sql/analytics/endpoint_performance.sql`
  - [ ] Storage queries ‚Üí `sql/analytics/storage_efficiency.sql`

- [x] **F2.5** Extrair queries de manuten√ß√£o
  - [ ] Cleanup queries ‚Üí `sql/maintenance/cleanup_old_data.sql`
  - [ ] Optimization ‚Üí `sql/maintenance/optimize_compression.sql`
  - [ ] Archiving ‚Üí `sql/maintenance/export_to_cold_storage.sql`

- [x] **F2.6** Refatorar c√≥digo Python
  - [ ] Substituir SQL inline por `sql_loader.load()`
  - [ ] Adicionar error handling para arquivos SQL missing
  - [ ] Manter par√¢metros consistentes
  - [ ] Testes para garantir equival√™ncia funcional

---

## Fase 3: Nova DDL com dbt

### üî• Setup dbt
**Refer√™ncia**: ADR-013, Plano Se√ß√£o 3

- [x] **F3.1** Configurar projeto dbt
  - [x] Executar `dbt init dbt_baliza`
  - [x] Configurar `dbt_project.yml` com target DuckDB
  - [x] Setup profiles em `~/.dbt/profiles.yml`
  - [x] Testar conex√£o: `dbt debug`

- [x] **F3.2** Estrutura do projeto dbt
  - [x] Criar diret√≥rios `models/{bronze,silver,gold,marts}/`
  - [x] Criar `macros/{compression,validation,optimization}/`
  - [x] Configurar `schema.yml` para cada layer
  - [x] Setup `packages.yml` com dbt-utils

### ‚ö° Implementar ENUMs Oficiais
**Refer√™ncia**: ADR-011

- [x] **F3.3** Criar ENUMs como seeds
  - [x] `seeds/modalidade_contratacao.csv` (13 valores oficiais)
  - [x] `seeds/situacao_contratacao.csv` (4 valores oficiais)
  - [x] `seeds/uf_brasil.csv` (27 estados)
  - [x] `seeds/natureza_juridica.csv` (47 c√≥digos)
  - [x] Todos os 17 domain tables do manual PNCP

- [x] **F3.4** Gerar CREATE TYPE statements
  - [x] Macro `create_enum_from_seed()`
  - [x] SQL: `CREATE TYPE modalidade_contratacao AS ENUM (...)`
  - [x] Aplicar em hook `on-run-start`
  - [x] Validation que enum values existem nos seeds

### ‚ö° Bronze Layer (Raw Data)
**Refer√™ncia**: ADR-013, ADR-010 (compression)

- [x] **F3.5** Modelo bronze_pncp_raw
  - [x] Schema identical to current pncp_content table
  - [x] `materialized: table`
  - [x] Global ZSTD compression: `SET default_compression='zstd'`
  - [x] Sem transforma√ß√µes, apenas staging

- [x] **F3.6** Modelo bronze_pncp_requests
  - [x] Schema para tabela de requests/metadata
  - [x] Campos: url_path, response_time, extracted_at, etc.
  - [x] Mesma estrat√©gia de compress√£o

### ‚ö° Silver Layer (Cleaned & Validated)
**Refer√™ncia**: ADR-011 (schema compliance), ADR-013

- [x] **F3.7** Modelo silver_pncp_contratacoes
  - [x] Aplicar ENUMs oficiais: `modalidade_contratacao::modalidade_contratacao_enum`
  - [x] Campos com tipos precisos: `DECIMAL(15,4)` para valores
  - [x] `VARCHAR(14)` para CNPJs, `VARCHAR(11)` para CPFs
  - [x] Data validation tests

- [x] **F3.8** Modelo silver_pncp_orgaos_entidades
  - [x] Hierarquia oficial: √ìrg√£o ‚Üí Unidade Administrativa
  - [x] Campos: CNPJ, razaoSocial, poderId, esferaId
  - [x] Normaliza√ß√£o de dados de entidades

- [x] **F3.9** Modelo silver_pncp_contratos
  - [x] Contratos/Atas vinculados a Contrata√ß√µes
  - [x] numeroControlePNCPContrato, valores, datas
  - [x] Foreign keys para integridade referencial

### üìä Gold Layer (Business Logic)
**Refer√™ncia**: ADR-013

- [x] **F3.10** Modelo gold_contratacoes_analytics
  - [x] Agrega√ß√µes por per√≠odo, modalidade, √≥rg√£o
  - [x] M√©tricas: total_valores, quantidade_contratos, m√©dia_por_modalidade
  - [x] Views otimizadas para dashboard

- [x] **F3.11** Modelo gold_deduplication_efficiency
  - [x] An√°lise de conte√∫do duplicado
  - [x] Storage savings, compression ratios
  - [x] M√©tricas para otimiza√ß√£o

### üìä Macros dbt
**Refer√™ncia**: ADR-010 (heuristics), ADR-011 (enum drift)

- [x] **F3.12** Macro enum_drift_detection
  - [x] Comparar ENUMs atuais vs seeds oficiais
  - [x] `SELECT enum_range() EXCEPT SELECT code FROM seed`
  - [x] Alert quando novos valores aparecem na API
  - [x] Auto-add com `ADD VALUE IF NOT EXISTS`

- [x] **F3.13** Macro compression_config
  - [x] Aplicar `SET default_compression='zstd'` globalmente
  - [x] Evitar --strict em hot tables
  - [x] `CHECKPOINT` after bulk operations

- [x] **F3.14** Macro data_quality_tests
  - [x] CNPJ format validation (14 digits)
  - [x] CPF format validation (11 digits)
  - [x] Required fields n√£o-nulos
  - [x] Foreign key integrity

### ‚úÖ Relat√≥rio de Conclus√£o da Fase 3
A Fase 3 foi **completamente implementada** e testada com sucesso. Os principais entreg√°veis incluem:

**üèóÔ∏è Arquitetura dbt Completa:**
- ‚úÖ Projeto dbt configurado com DuckDB adapter
- ‚úÖ Estrutura medallion completa: Bronze ‚Üí Silver ‚Üí Gold
- ‚úÖ 26 modelos implementados + 15 seeds + 64 testes de qualidade
- ‚úÖ 4 macros de valida√ß√£o e compress√£o

**üìä Modelos de Dados:**
- ‚úÖ `bronze_pncp_raw` + `bronze_pncp_requests` - Raw data com compress√£o ZSTD
- ‚úÖ `silver_contratacoes` + `silver_orgaos_entidades` + `silver_contratos` - Dados limpos com ENUMs oficiais
- ‚úÖ `gold_contratacoes_analytics` + `gold_deduplication_efficiency` - M√©tricas de neg√≥cio

**üîß Sistema de ENUMs Oficiais:**
- ‚úÖ 13 tabelas de dom√≠nio PNCP carregadas (196 registros totais)
- ‚úÖ Gera√ß√£o autom√°tica de ENUMs via `stg_create_enums`
- ‚úÖ Detec√ß√£o de drift com `test_enum_drift`

**‚úÖ Valida√ß√£o e Testes:**
- ‚úÖ `dbt parse` - Sem erros, todos os modelos validados
- ‚úÖ `dbt debug` - Conex√£o estabelecida com sucesso  
- ‚úÖ `dbt seed` - Todos os seeds carregados corretamente
- ‚úÖ Testes de qualidade: CNPJ/CPF, chaves estrangeiras, not_null

**üöÄ Status**: Pronto para integra√ß√£o com pipeline Python e implementa√ß√£o da Fase 3B.

---

## Fase 3B: Elimina√ß√£o da Persist√™ncia de Raw Content

### üî• Nova Arquitetura Direct-to-Table
**Refer√™ncia**: Otimiza√ß√£o de Storage e Performance

- [ ] **F3B.1** Mapear completamente output da API PNCP
  - [ ] Analisar todos os endpoints: `/contratos`, `/atas`, `/contratacoes`
  - [ ] Documentar schema completo de cada endpoint
  - [ ] Identificar todos os campos e tipos de dados
  - [ ] Criar mapeamento direto API ‚Üí tabelas espec√≠ficas

- [ ] **F3B.2** Redesenhar pipeline de extra√ß√£o
  - [ ] Eliminar `pncp_content` e `bronze_pncp_raw`
  - [ ] Implementar parsing direto para tabelas espec√≠ficas:
    - [ ] `contratos` ‚Üí `bronze_contratos`
    - [ ] `atas` ‚Üí `bronze_atas`  
    - [ ] `contratacoes` ‚Üí `bronze_contratacoes`
    - [ ] `fontes_orcamentarias` ‚Üí `bronze_fontes_orcamentarias`
    - [ ] `instrumentos_cobranca` ‚Üí `bronze_instrumentos_cobranca`
    - [ ] `planos_contratacao` ‚Üí `bronze_planos_contratacao` + `bronze_planos_contratacao_itens`
  - [ ] Atualizar `pncp_requests` ‚Üí `bronze_pncp_requests`:
    - [ ] Adicionar campo `month` (YYYY-MM, NULL para endpoints sem data)
    - [ ] Adicionar `parse_status`, `parse_error_message`, `records_parsed`
    - [ ] Controle de duplicadas por (endpoint_name, month, request_parameters)

- [ ] **F3B.3** Sistema de fallback para erros
  - [ ] Criar tabela `pncp_parse_errors` 
  - [ ] Campos: `url`, `response_raw`, `error_message`, `extracted_at`
  - [ ] Persistir apenas respostas que falharam no parsing
  - [ ] Sistema de retry para reprocessar erros

- [ ] **F3B.3B** Valida√ß√µes Pydantic Avan√ßadas
  - [ ] Validador custom para CNPJ: d√≠gitos verificadores + formato
  - [ ] Validador custom para CPF: d√≠gitos verificadores + formato  
  - [ ] Valida√ß√£o de datas: n√£o futuras, ranges v√°lidos
  - [ ] Valida√ß√£o de valores: n√£o negativos para pre√ßos
  - [ ] Valida√ß√£o de c√≥digos: existem nos ENUMs oficiais
  - [ ] Valida√ß√£o de consist√™ncia: datas in√≠cio < fim
  - [ ] Transformadores: normalizar strings (upper/lower case)
  - [ ] Coer√ß√£o segura: strings vazias ‚Üí None

### üìä Benef√≠cios Esperados
- **-90% storage usage**: Eliminar duplica√ß√£o de dados
- **+5x parsing speed**: Processamento direto sem intermedi√°rios
- **+10x query performance**: Dados j√° estruturados
- **100% data quality**: Valida√ß√£o Pydantic antes da inser√ß√£o
- **Type safety**: Garantia de tipos corretos no banco
- **Debugging capability**: Erros preservados para an√°lise

### üõ°Ô∏è Valida√ß√£o Pydantic (Data Quality)
- **Valida√ß√£o de tipos**: Autom√°tica para dates, decimals, integers, booleans
- **Valida√ß√£o de formato**: CNPJ (14 d√≠gitos), UF (2 chars), emails, URLs
- **Valida√ß√£o de obrigat√≥rios**: Campos NOT NULL validados antes da inser√ß√£o
- **Sanitiza√ß√£o autom√°tica**: Strip whitespace, normaliza√ß√£o de strings
- **Transforma√ß√£o segura**: Convers√£o de tipos com fallback para None
- **Mensagens de erro claras**: Debugging preciso quando dados n√£o batem
- **Documenta√ß√£o viva**: Schemas servem como spec da estrutura de dados

### ‚ö° Refatora√ß√£o dos Modelos dbt

- [ ] **F3B.4** Atualizar bronze layer
  - [ ] Remover `bronze_pncp_raw`
  - [ ] Criar `bronze_contratos`, `bronze_atas`, `bronze_contratacoes`
  - [ ] Cada tabela com schema espec√≠fico do endpoint
  - [ ] Compress√£o ZSTD aplicada diretamente

- [ ] **F3B.5** Atualizar silver layer
  - [ ] Modificar `silver_*` para usar novos bronze tables
  - [ ] Simplificar transforma√ß√µes (dados j√° estruturados)
  - [ ] Manter valida√ß√£o de ENUMs e tipos

- [ ] **F3B.6** Implementar monitoramento
  - [ ] M√©tricas de parsing success rate
  - [ ] Alertas para aumento de erros
  - [ ] Dashboard de health do pipeline

---

## Fase 4: Hot-Cold Storage Tiers

### ‚ö° Configura√ß√£o de Tiers
**Refer√™ncia**: ADR-012, Plano Se√ß√£o 4

- [ ] **F4.1** Implementar Hot Tier (√∫ltimos 90 dias)
  - [ ] Modelo dbt `bronze_pncp_hot` com filtro de data
  - [ ] Otimizado para writes: sem --strict compression
  - [ ] `materialized: table` para performance m√°xima
  - [ ] Incremental updates baseados em extracted_at

- [ ] **F4.2** Implementar Cold Tier (90 dias - 2 anos)
  - [ ] Modelo `bronze_pncp_cold` 
  - [ ] Compression agressiva + row-group optimization
  - [ ] Read-only com batch updates
  - [ ] `materialized: table` com compression otimizada

- [ ] **F4.3** Implementar Archive Tier (>2 anos)  
  - [ ] Export para Parquet: `ROW_GROUP_SIZE 500k`
  - [ ] Upload para S3/cloud storage
  - [ ] Views externas: `read_parquet('s3://baliza-archive/**/*.parquet')`
  - [ ] Sem c√≥pia local dos dados arquivados

### üìä Automa√ß√£o de Lifecycle
**Refer√™ncia**: ADR-012

- [ ] **F4.4** Script tier_management.py
  - [ ] Daily job para mover dados entre tiers
  - [ ] `DELETE FROM hot WHERE extracted_at < CURRENT_DATE - 90`
  - [ ] `INSERT INTO cold SELECT * FROM hot WHERE ...`
  - [ ] `CHECKPOINT` ap√≥s cada tier move

- [ ] **F4.5** Transparent views
  - [ ] `VIEW pncp_all AS SELECT * FROM hot UNION ALL SELECT * FROM cold UNION ALL SELECT * FROM archive`
  - [ ] Query optimizer routes automaticamente
  - [ ] Maintains API compatibility

### üìä Otimiza√ß√µes Espec√≠ficas por Tier

- [ ] **F4.6** Hot tier optimizations
  - [ ] `ON CONFLICT DO NOTHING` para avoid rollbacks
  - [ ] Minimal indexing para fast writes
  - [ ] ZSTD application em nightly CHECKPOINT apenas

- [ ] **F4.7** Cold tier optimizations  
  - [ ] Row-group tuning apenas aqui (n√£o no hot)
  - [ ] Aggressive compression post-checkpoint
  - [ ] Rebuild indexes ap√≥s tier migration

- [ ] **F4.8** Archive tier via httpfs
  - [ ] Install/config httpfs extension
  - [ ] Test S3 connectivity e permissions
  - [ ] Benchmark query performance vs local storage
  - [ ] Fallback strategy se S3 unavailable

---

## Fase 5: Valida√ß√£o e Performance

### ‚ö° Testes de Integridade
**Refer√™ncia**: ADR-011 (compliance), ADR-013 (dbt tests)

- [ ] **F5.1** Data validation suite
  - [ ] dbt tests para schema compliance
  - [ ] Row count validation (old vs new schema)
  - [ ] Data integrity tests (foreign keys, constraints)
  - [ ] Business rule validation

- [ ] **F5.2** Migration testing
  - [ ] Script de migra√ß√£o com rollback capability
  - [ ] Parallel validation: old vs new queries
  - [ ] Performance regression testing
  - [ ] Data loss detection

### üìä Performance Benchmarking
**Refer√™ncia**: Feedback "Benchmarks automatizados"

- [ ] **F5.3** Automated benchmark suite
  - [ ] `scripts/benchmarks.py`
  - [ ] ‚ë† Ingest de 1M linhas  
  - [ ] ‚ë° Tr√™s queries t√≠picas (analytics)
  - [ ] ‚ë¢ Storage efficiency (`pragma_storage_info`)
  - [ ] Fail PR se regress√£o > 5%

- [ ] **F5.4** Compression effectiveness
  - [ ] Before/after storage comparison
  - [ ] Query performance comparison  
  - [ ] Memory usage analysis
  - [ ] Target: -70% storage, +2-3x throughput

### üßπ CI/CD Integration

- [ ] **F5.5** GitHub Actions mutex
  - [ ] Single-writer enforcement para DuckDB
  - [ ] Workflow concurrency control  
  - [ ] Lockfile mechanism via artifacts
  - [ ] Prevent WAL corruption

- [ ] **F5.6** Automated quality gates
  - [ ] `dbt test` em todo PR
  - [ ] Performance benchmarks autom√°ticos
  - [ ] SQL linting com sqlfmt
  - [ ] Schema change detection

---

## Fase 6: Deploy e Monitoring

### üìä Migration Strategy
**Refer√™ncia**: Breaking changes em ADR-011

- [ ] **F6.1** Legacy compatibility
  - [ ] Branch `legacy-reader` com views para novo schema
  - [ ] Backward compatibility layer
  - [ ] Notebooks antigos continue funcionando
  - [ ] Phased deprecation plan

- [ ] **F6.2** Zero-downtime migration
  - [ ] Blue-green deployment strategy
  - [ ] Parallel write durante transition
  - [ ] Validation em ambos schemas  
  - [ ] Rollback plan se problemas

### üßπ Operational Excellence

- [ ] **F6.3** Monitoring e alertas
  - [ ] Disk usage por tier
  - [ ] Query performance metrics
  - [ ] Enum drift alerts
  - [ ] Data freshness monitoring

- [ ] **F6.4** Documentation
  - [ ] Atualizar README com novo workflow
  - [ ] Migration guide para users
  - [ ] Performance tuning guide
  - [ ] Troubleshooting guide

---

## Crit√©rios de Sucesso

**Performance Targets**:
- [ ] ‚úÖ **-70% storage usage** vs schema atual
- [ ] ‚úÖ **+2-3x query throughput** para analytical workloads  
- [ ] ‚úÖ **<30s** para extracta√ß√£o mensal completa
- [ ] ‚úÖ **100% PNCP schema compliance**

**Quality Gates**:
- [ ] ‚úÖ **Zero data loss** durante migration
- [ ] ‚úÖ **100% test coverage** para dbt models
- [ ] ‚úÖ **Automated benchmarks** passing em CI
- [ ] ‚úÖ **Legacy compatibility** maintained

**Operational Goals**:
- [ ] ‚úÖ **Single-writer safety** em GitHub Actions
- [ ] ‚úÖ **Automated tier management** functioning
- [ ] ‚úÖ **Enum drift detection** alerting
- [ ] ‚úÖ **Performance monitoring** dashboards

---

## Referencias

- [Plano de Otimiza√ß√£o da Base de Dados](docs/database-optimization-plan.md)
- [ADR-009: SQL Extraction Strategy](docs/adr/009-sql-extraction-strategy.md)  
- [ADR-010: Compression Heuristics First](docs/adr/010-compression-heuristics-first.md)
- [ADR-011: Official PNCP Schema Compliance](docs/adr/011-official-pncp-schema-compliance.md)
- [ADR-012: Hot-Cold Storage Tiers](docs/adr/012-hot-cold-storage-tiers.md)  
- [ADR-013: dbt Integration for DDL](docs/adr/013-dbt-integration-for-ddl.md)

---
**Status**: ‚è≥ Aguardando in√≠cio da implementa√ß√£o  
**Estimativa Total**: 15-20 dias para implementa√ß√£o completa  
**Depend√™ncias Cr√≠ticas**: F1.1-F1.3 devem ser completados antes de F2.x