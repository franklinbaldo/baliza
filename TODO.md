# TODO: Database Optimization Implementation

Este arquivo contÃ©m tarefas atÃ´micas para implementar o [Plano de OtimizaÃ§Ã£o da Base de Dados](docs/database-optimization-plan.md).

## Legenda
- ðŸ”¥ **CRÃTICO** - Deve ser feito primeiro, bloqueia outras tarefas
- âš¡ **ALTO** - Impacto significativo na performance/arquitetura  
- ðŸ“Š **MÃ‰DIO** - Melhorias importantes mas nÃ£o crÃ­ticas
- ðŸ§¹ **BAIXO** - Limpeza e otimizaÃ§Ãµes menores

---

## Fase 1: DiagnÃ³stico e PreparaÃ§Ã£o

### ðŸ”¥ AnÃ¡lise da DocumentaÃ§Ã£o Oficial PNCP
**ReferÃªncia**: ADR-011, Plano SeÃ§Ã£o 1.1

- [x] **F1.1** Criar script `scripts/audit_pncp_compliance.py`
  - [x] Extrair todos os ENUMs do `docs/openapi/MANUAL-PNCP-CONSULSTAS-VERSAO-1.md`
  - [x] Parsear `docs/openapi/api-pncp-consulta.json` para tipos precisos
  - [x] Comparar schema atual vs oficial
  - [x] Gerar relatÃ³rio `docs/pncp-compliance-audit.md`

- [x] **F1.2** Mapear campos atuais para schema oficial
  - [x] Identificar campos faltantes no BALIZA
  - [x] Identificar campos nÃ£o-oficiais que devemos remover
  - [x] Listar todos os campos com tipos incorretos
  - [x] Documentar breaking changes necessÃ¡rios

- [x] **F1.3** Extrair cÃ³digos oficiais das 17 tabelas de domÃ­nio
  - [x] Modalidade de ContrataÃ§Ã£o (13 valores)
  - [x] SituaÃ§Ã£o da ContrataÃ§Ã£o (4 valores)
  - [x] UF (27 valores)
  - [x] Natureza JurÃ­dica (47 valores)
  - [x] Salvar como `sql/seeds/pncp_domain_tables.sql`

### ðŸ”¥ InventÃ¡rio de SQL Inline
**ReferÃªncia**: ADR-009, Plano SeÃ§Ã£o 1.2

- [x] **F1.4** Escanear cÃ³digo Python para SQL inline
  - [x] Usar regex para encontrar strings SQL em `src/baliza/`
  - [x] Classificar por tipo: SELECT, INSERT, UPDATE, DELETE, DDL
  - [x] Medir complexidade (single table vs joins)
  - [x] Gerar `docs/sql-inventory.md` com mapeamento completo

- [x] **F1.5** Analisar performance atual
  - [x] Executar `pragma_storage_info()` em todas as tabelas
  - [x] Documentar tamanhos atuais e padrÃµes de compressÃ£o
  - [x] Identificar tabelas com maior potencial de otimizaÃ§Ã£o
  - [x] Baseline para comparaÃ§Ã£o pÃ³s-otimizaÃ§Ã£o

### RelatÃ³rio de ConclusÃ£o da Fase 1
A Fase 1 foi executada integralmente, gerando os artefatos de diagnÃ³stico abaixo. Estes arquivos devem ser utilizados como referÃªncia para as prÃ³ximas etapas.
- `scripts/audit_pncp_compliance.py` produziu o relatÃ³rio `docs/pncp-compliance-audit.md` com a anÃ¡lise do schema oficial e os ENUMs extraÃ­dos.
- `scripts/scan_inline_sql.py` identificou 71 consultas SQL, documentadas em `docs/sql-inventory.md`.
- `scripts/analyze_performance.py` registrou o estado inicial de armazenamento em `docs/performance-baseline.md`.
- Os CSVs de tabelas de domÃ­nio foram salvos em `dbt_baliza/seeds/domain_tables/`, prontos para uso pelo dbt.
Com a base de diagnÃ³stico pronta, a Fase 2 pode iniciar a migraÃ§Ã£o das queries com confianÃ§a.

---

## Fase 2: ExtraÃ§Ã£o e ReorganizaÃ§Ã£o SQL

### âš¡ Estrutura de DiretÃ³rios SQL
**ReferÃªncia**: ADR-009, Plano SeÃ§Ã£o 2.1

- [x] **F2.1** Criar estrutura de diretÃ³rios
```bash
mkdir -p sql/{ddl,dml/{inserts,updates,deletes},analytics,maintenance,migrations}
```

- [x] **F2.2** Implementar SQLLoader
  - [ ] Criar `src/baliza/sql_loader.py` conforme spec do plano
  - [ ] Adicionar cache de arquivos SQL
  - [ ] Implementar parametrizaÃ§Ã£o segura com `string.Template`
  - [ ] Adicionar validaÃ§Ã£o de parÃ¢metros obrigatÃ³rios
  - [ ] Testes unitÃ¡rios para SQLLoader

### âš¡ MigraÃ§Ã£o de SQL Inline
**ReferÃªncia**: ADR-009

- [x] **F2.3** Extrair queries de inserÃ§Ã£o
  - [ ] `src/baliza/pncp_writer.py` â†’ `sql/dml/inserts/pncp_content.sql`
  - [ ] `src/baliza/pncp_writer.py` â†’ `sql/dml/inserts/pncp_requests.sql`  
  - [ ] Adicionar headers padronizados com metadata
  - [ ] Converter hard-coded values para parÃ¢metros

- [x] **F2.4** Extrair queries analÃ­ticas
  - [ ] Dashboard queries â†’ `sql/analytics/deduplication_stats.sql`
  - [ ] Performance queries â†’ `sql/analytics/endpoint_performance.sql`
  - [ ] Storage queries â†’ `sql/analytics/storage_efficiency.sql`

- [x] **F2.5** Extrair queries de manutenÃ§Ã£o
  - [ ] Cleanup queries â†’ `sql/maintenance/cleanup_old_data.sql`
  - [ ] Optimization â†’ `sql/maintenance/optimize_compression.sql`
  - [ ] Archiving â†’ `sql/maintenance/export_to_cold_storage.sql`

- [x] **F2.6** Refatorar cÃ³digo Python
  - [ ] Substituir SQL inline por `sql_loader.load()`
  - [ ] Adicionar error handling para arquivos SQL missing
  - [ ] Manter parÃ¢metros consistentes
  - [ ] Testes para garantir equivalÃªncia funcional

---

## Fase 3: Nova DDL com dbt

### ðŸ”¥ Setup dbt
**ReferÃªncia**: ADR-013, Plano SeÃ§Ã£o 3

- [x] **F3.1** Configurar projeto dbt
  - [x] Executar `dbt init dbt_baliza`
  - [x] Configurar `dbt_project.yml` com target DuckDB
  - [x] Setup profiles em `~/.dbt/profiles.yml`
  - [x] Testar conexÃ£o: `dbt debug`

- [x] **F3.2** Estrutura do projeto dbt
  - [x] Criar diretÃ³rios `models/{bronze,silver,gold,marts}/`
  - [x] Criar `macros/{compression,validation,optimization}/`
  - [x] Configurar `schema.yml` para cada layer
  - [x] Setup `packages.yml` com dbt-utils

### âš¡ Implementar ENUMs Oficiais
**ReferÃªncia**: ADR-011

- [x] **F3.3** Criar ENUMs como seeds
  - [x] `seeds/modalidade_contratacao.csv` (13 valores oficiais)
  - [x] `seeds/situacao_contratacao.csv` (4 valores oficiais)
  - [x] `seeds/uf_brasil.csv` (27 estados)
  - [x] `seeds/natureza_juridica.csv` (47 cÃ³digos)
  - [x] Todos os 17 domain tables do manual PNCP

- [x] **F3.4** Gerar CREATE TYPE statements
  - [x] Macro `create_enum_from_seed()`
  - [x] SQL: `CREATE TYPE modalidade_contratacao AS ENUM (...)`
  - [x] Aplicar em hook `on-run-start`
  - [x] Validation que enum values existem nos seeds

### âš¡ Bronze Layer (Raw Data)
**ReferÃªncia**: ADR-013, ADR-010 (compression)

- [x] **F3.5** Modelo bronze_pncp_raw
  - [x] Schema identical to current pncp_content table
  - [x] `materialized: table`
  - [x] Global ZSTD compression: `SET default_compression='zstd'`
  - [x] Sem transformaÃ§Ãµes, apenas staging

- [x] **F3.6** Modelo bronze_pncp_requests
  - [x] Schema para tabela de requests/metadata
  - [x] Campos: url_path, response_time, extracted_at, etc.
  - [x] Mesma estratÃ©gia de compressÃ£o

### âš¡ Silver Layer (Cleaned & Validated)
**ReferÃªncia**: ADR-011 (schema compliance), ADR-013

- [x] **F3.7** Modelo silver_pncp_contratacoes
  - [x] Aplicar ENUMs oficiais: `modalidade_contratacao::modalidade_contratacao_enum`
  - [x] Campos com tipos precisos: `DECIMAL(15,4)` para valores
  - [x] `VARCHAR(14)` para CNPJs, `VARCHAR(11)` para CPFs
  - [x] Data validation tests

- [x] **F3.8** Modelo silver_pncp_orgaos_entidades
  - [x] Hierarquia oficial: Ã“rgÃ£o â†’ Unidade Administrativa
  - [x] Campos: CNPJ, razaoSocial, poderId, esferaId
  - [x] NormalizaÃ§Ã£o de dados de entidades

- [x] **F3.9** Modelo silver_pncp_contratos
  - [x] Contratos/Atas vinculados a ContrataÃ§Ãµes
  - [x] numeroControlePNCPContrato, valores, datas
  - [x] Foreign keys para integridade referencial

### ðŸ“Š Gold Layer (Business Logic)
**ReferÃªncia**: ADR-013

- [x] **F3.10** Modelo gold_contratacoes_analytics
  - [x] AgregaÃ§Ãµes por perÃ­odo, modalidade, Ã³rgÃ£o
  - [x] MÃ©tricas: total_valores, quantidade_contratos, mÃ©dia_por_modalidade
  - [x] Views otimizadas para dashboard

- [x] **F3.11** Modelo gold_deduplication_efficiency
  - [x] AnÃ¡lise de conteÃºdo duplicado
  - [x] Storage savings, compression ratios
  - [x] MÃ©tricas para otimizaÃ§Ã£o

### ðŸ“Š Macros dbt
**ReferÃªncia**: ADR-010 (heuristics), ADR-011 (enum drift)

- [x] **F3.12** Macro enum_drift_detection
  - [x] Comparar ENUMs atuais vs seeds oficiais
  - [x] `SELECT enum_range() EXCEPT SELECT code FROM seed`
  - [x] Alert quando novos valores aparecem na API
  - [x] Auto-add com `ADD VALUE IF NOT EXISTS`

- [x] **F3.13** Macro compression_config
  - [x] Aplicar `SET default_compression='zstd'` globalmente
  - [x] Evitar --strict em hot tables
  - [x] `CHECKPOINT` after bulk operations

- [x] **F3.14** Macro data_quality_tests
  - [x] CNPJ format validation (14 digits)
  - [x] CPF format validation (11 digits)
  - [x] Required fields nÃ£o-nulos
  - [x] Foreign key integrity

### âœ… RelatÃ³rio de ConclusÃ£o da Fase 3
A Fase 3 foi **completamente implementada** e testada com sucesso. Os principais entregÃ¡veis incluem:

**ðŸ—ï¸ Arquitetura dbt Completa:**
- âœ… Projeto dbt configurado com DuckDB adapter
- âœ… Estrutura medallion completa: Bronze â†’ Silver â†’ Gold
- âœ… 26 modelos implementados + 15 seeds + 64 testes de qualidade
- âœ… 4 macros de validaÃ§Ã£o e compressÃ£o

**ðŸ“Š Modelos de Dados:**
- âœ… `bronze_pncp_raw` + `bronze_pncp_requests` - Raw data com compressÃ£o ZSTD
- âœ… `silver_contratacoes` + `silver_orgaos_entidades` + `silver_contratos` - Dados limpos com ENUMs oficiais
- âœ… `gold_contratacoes_analytics` + `gold_deduplication_efficiency` - MÃ©tricas de negÃ³cio

**ðŸ”§ Sistema de ENUMs Oficiais:**
- âœ… 13 tabelas de domÃ­nio PNCP carregadas (196 registros totais)
- âœ… GeraÃ§Ã£o automÃ¡tica de ENUMs via `stg_create_enums`
- âœ… DetecÃ§Ã£o de drift com `test_enum_drift`

**âœ… ValidaÃ§Ã£o e Testes:**
- âœ… `dbt parse` - Sem erros, todos os modelos validados
- âœ… `dbt debug` - ConexÃ£o estabelecida com sucesso  
- âœ… `dbt seed` - Todos os seeds carregados corretamente
- âœ… Testes de qualidade: CNPJ/CPF, chaves estrangeiras, not_null

**ðŸš€ Status**: Pronto para integraÃ§Ã£o com pipeline Python e implementaÃ§Ã£o da Fase 3B.

---

## Fase 3B: EliminaÃ§Ã£o da PersistÃªncia de Raw Content

### ðŸ”¥ Nova Arquitetura Direct-to-Table
**ReferÃªncia**: OtimizaÃ§Ã£o de Storage e Performance

- [ ] **F3B.1** Mapear completamente output da API PNCP
  - [ ] Analisar todos os endpoints: `/contratos`, `/atas`, `/contratacoes`
  - [ ] Documentar schema completo de cada endpoint
  - [ ] Identificar todos os campos e tipos de dados
  - [ ] Criar mapeamento direto API â†’ tabelas especÃ­ficas

- [ ] **F3B.2** Redesenhar pipeline de extraÃ§Ã£o
  - [ ] Eliminar `pncp_content` e `bronze_pncp_raw`
  - [ ] Implementar parsing direto para tabelas especÃ­ficas:
    - [ ] `contratos` â†’ `bronze_contratos`
    - [ ] `atas` â†’ `bronze_atas`  
    - [ ] `contratacoes` â†’ `bronze_contratacoes`
    - [ ] `fontes_orcamentarias` â†’ `bronze_fontes_orcamentarias`
    - [ ] `instrumentos_cobranca` â†’ `bronze_instrumentos_cobranca`
    - [ ] `planos_contratacao` â†’ `bronze_planos_contratacao` + `bronze_planos_contratacao_itens`
  - [ ] Atualizar `pncp_requests` â†’ `bronze_pncp_requests`:
    - [ ] Adicionar campo `month` (YYYY-MM, NULL para endpoints sem data)
    - [ ] Adicionar `parse_status`, `parse_error_message`, `records_parsed`
    - [ ] Controle de duplicadas por (endpoint_name, month, request_parameters)

- [ ] **F3B.3** Sistema de fallback para erros
  - [ ] Criar tabela `pncp_parse_errors` 
  - [ ] Campos: `url`, `response_raw`, `error_message`, `extracted_at`
  - [ ] Persistir apenas respostas que falharam no parsing
  - [ ] Sistema de retry para reprocessar erros

### ðŸ“Š BenefÃ­cios Esperados
- **-90% storage usage**: Eliminar duplicaÃ§Ã£o de dados
- **+5x parsing speed**: Processamento direto sem intermediÃ¡rios
- **+10x query performance**: Dados jÃ¡ estruturados
- **Debugging capability**: Erros preservados para anÃ¡lise

### âš¡ RefatoraÃ§Ã£o dos Modelos dbt

- [ ] **F3B.4** Atualizar bronze layer
  - [ ] Remover `bronze_pncp_raw`
  - [ ] Criar `bronze_contratos`, `bronze_atas`, `bronze_contratacoes`
  - [ ] Cada tabela com schema especÃ­fico do endpoint
  - [ ] CompressÃ£o ZSTD aplicada diretamente

- [ ] **F3B.5** Atualizar silver layer
  - [ ] Modificar `silver_*` para usar novos bronze tables
  - [ ] Simplificar transformaÃ§Ãµes (dados jÃ¡ estruturados)
  - [ ] Manter validaÃ§Ã£o de ENUMs e tipos

- [ ] **F3B.6** Implementar monitoramento
  - [ ] MÃ©tricas de parsing success rate
  - [ ] Alertas para aumento de erros
  - [ ] Dashboard de health do pipeline

---

## Fase 4: Hot-Cold Storage Tiers

### âš¡ ConfiguraÃ§Ã£o de Tiers
**ReferÃªncia**: ADR-012, Plano SeÃ§Ã£o 4

- [ ] **F4.1** Implementar Hot Tier (Ãºltimos 90 dias)
  - [ ] Modelo dbt `bronze_pncp_hot` com filtro de data
  - [ ] Otimizado para writes: sem --strict compression
  - [ ] `materialized: table` para performance mÃ¡xima
  - [ ] Incremental updates baseados em extracted_at

- [ ] **F4.2** Implementar Cold Tier (90 dias - 2 anos)
  - [ ] Modelo `bronze_pncp_cold` 
  - [ ] Compression agressiva + row-group optimization
  - [ ] Read-only com batch updates
  - [ ] `materialized: table` com compression otimizada

- [ ] **F4.3** Implementar Archive Tier (>2 anos)  
  - [ ] Export para Parquet: `ROW_GROUP_SIZE 500k`
  - [ ] Upload para S3/cloud storage
  - [ ] Views externas: `read_parquet('s3://baliza-archive/**/*.parquet')`
  - [ ] Sem cÃ³pia local dos dados arquivados

### ðŸ“Š AutomaÃ§Ã£o de Lifecycle
**ReferÃªncia**: ADR-012

- [ ] **F4.4** Script tier_management.py
  - [ ] Daily job para mover dados entre tiers
  - [ ] `DELETE FROM hot WHERE extracted_at < CURRENT_DATE - 90`
  - [ ] `INSERT INTO cold SELECT * FROM hot WHERE ...`
  - [ ] `CHECKPOINT` apÃ³s cada tier move

- [ ] **F4.5** Transparent views
  - [ ] `VIEW pncp_all AS SELECT * FROM hot UNION ALL SELECT * FROM cold UNION ALL SELECT * FROM archive`
  - [ ] Query optimizer routes automaticamente
  - [ ] Maintains API compatibility

### ðŸ“Š OtimizaÃ§Ãµes EspecÃ­ficas por Tier

- [ ] **F4.6** Hot tier optimizations
  - [ ] `ON CONFLICT DO NOTHING` para avoid rollbacks
  - [ ] Minimal indexing para fast writes
  - [ ] ZSTD application em nightly CHECKPOINT apenas

- [ ] **F4.7** Cold tier optimizations  
  - [ ] Row-group tuning apenas aqui (nÃ£o no hot)
  - [ ] Aggressive compression post-checkpoint
  - [ ] Rebuild indexes apÃ³s tier migration

- [ ] **F4.8** Archive tier via httpfs
  - [ ] Install/config httpfs extension
  - [ ] Test S3 connectivity e permissions
  - [ ] Benchmark query performance vs local storage
  - [ ] Fallback strategy se S3 unavailable

---

## Fase 5: ValidaÃ§Ã£o e Performance

### âš¡ Testes de Integridade
**ReferÃªncia**: ADR-011 (compliance), ADR-013 (dbt tests)

- [ ] **F5.1** Data validation suite
  - [ ] dbt tests para schema compliance
  - [ ] Row count validation (old vs new schema)
  - [ ] Data integrity tests (foreign keys, constraints)
  - [ ] Business rule validation

- [ ] **F5.2** Migration testing
  - [ ] Script de migraÃ§Ã£o com rollback capability
  - [ ] Parallel validation: old vs new queries
  - [ ] Performance regression testing
  - [ ] Data loss detection

### ðŸ“Š Performance Benchmarking
**ReferÃªncia**: Feedback "Benchmarks automatizados"

- [ ] **F5.3** Automated benchmark suite
  - [ ] `scripts/benchmarks.py`
  - [ ] â‘  Ingest de 1M linhas  
  - [ ] â‘¡ TrÃªs queries tÃ­picas (analytics)
  - [ ] â‘¢ Storage efficiency (`pragma_storage_info`)
  - [ ] Fail PR se regressÃ£o > 5%

- [ ] **F5.4** Compression effectiveness
  - [ ] Before/after storage comparison
  - [ ] Query performance comparison  
  - [ ] Memory usage analysis
  - [ ] Target: -70% storage, +2-3x throughput

### ðŸ§¹ CI/CD Integration

- [ ] **F5.5** GitHub Actions mutex
  - [ ] Single-writer enforcement para DuckDB
  - [ ] Workflow concurrency control  
  - [ ] Lockfile mechanism via artifacts
  - [ ] Prevent WAL corruption

- [ ] **F5.6** Automated quality gates
  - [ ] `dbt test` em todo PR
  - [ ] Performance benchmarks automÃ¡ticos
  - [ ] SQL linting com sqlfmt
  - [ ] Schema change detection

---

## Fase 6: Deploy e Monitoring

### ðŸ“Š Migration Strategy
**ReferÃªncia**: Breaking changes em ADR-011

- [ ] **F6.1** Legacy compatibility
  - [ ] Branch `legacy-reader` com views para novo schema
  - [ ] Backward compatibility layer
  - [ ] Notebooks antigos continue funcionando
  - [ ] Phased deprecation plan

- [ ] **F6.2** Zero-downtime migration
  - [ ] Blue-green deployment strategy
  - [ ] Parallel write durante transition
  - [ ] Validation em ambos schemas  
  - [ ] Rollback plan se problemas

### ðŸ§¹ Operational Excellence

- [ ] **F6.3** Monitoring e alertas
  - [ ] Disk usage por tier
  - [ ] Query performance metrics
  - [ ] Enum drift alerts
  - [ ] Data freshness monitoring

- [ ] **F6.4** Documentation
  - [ ] Atualizar README com novo workflow
  - [ ] Migration guide para users
  - [ ] Performance tuning guide
  - [ ] Troubleshooting guide

---

## CritÃ©rios de Sucesso

**Performance Targets**:
- [ ] âœ… **-70% storage usage** vs schema atual
- [ ] âœ… **+2-3x query throughput** para analytical workloads  
- [ ] âœ… **<30s** para extractaÃ§Ã£o mensal completa
- [ ] âœ… **100% PNCP schema compliance**

**Quality Gates**:
- [ ] âœ… **Zero data loss** durante migration
- [ ] âœ… **100% test coverage** para dbt models
- [ ] âœ… **Automated benchmarks** passing em CI
- [ ] âœ… **Legacy compatibility** maintained

**Operational Goals**:
- [ ] âœ… **Single-writer safety** em GitHub Actions
- [ ] âœ… **Automated tier management** functioning
- [ ] âœ… **Enum drift detection** alerting
- [ ] âœ… **Performance monitoring** dashboards

---

## Referencias

- [Plano de OtimizaÃ§Ã£o da Base de Dados](docs/database-optimization-plan.md)
- [ADR-009: SQL Extraction Strategy](docs/adr/009-sql-extraction-strategy.md)  
- [ADR-010: Compression Heuristics First](docs/adr/010-compression-heuristics-first.md)
- [ADR-011: Official PNCP Schema Compliance](docs/adr/011-official-pncp-schema-compliance.md)
- [ADR-012: Hot-Cold Storage Tiers](docs/adr/012-hot-cold-storage-tiers.md)  
- [ADR-013: dbt Integration for DDL](docs/adr/013-dbt-integration-for-ddl.md)

---
**Status**: â³ Aguardando inÃ­cio da implementaÃ§Ã£o  
**Estimativa Total**: 15-20 dias para implementaÃ§Ã£o completa  
**DependÃªncias CrÃ­ticas**: F1.1-F1.3 devem ser completados antes de F2.x