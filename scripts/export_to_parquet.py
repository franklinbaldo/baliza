import duckdb
import os
from datetime import date, timedelta

def export_new_data_to_parquet(db_path="data/baliza.duckdb", output_dir="data/parquet"):
    """
    Connects to the DuckDB database generated by a Baliza run,
    extracts the data for the most recent extraction date, and exports it
    to partitioned Parquet files.

    The partitioning is done by endpoint, year, and month.
    """
    if not os.path.exists(db_path):
        print(f"Database file not found at {db_path}. Nothing to export.")
        return

    con = duckdb.connect(database=db_path, read_only=True)

    # The table name where Baliza stores raw responses
    table_name = "raw_pncp"

    # We'll export data from yesterday, as the daily run is configured to fetch recent data.
    target_date = date.today() - timedelta(days=1)
    print(f"Targeting data for date: {target_date.strftime('%Y-%m-%d')}")

    # Export the raw data for the target date to partitioned Parquet files
    print(f"Exporting raw data from {target_date.strftime('%Y-%m-%d')} to Parquet...")

    # The raw data is stored in a JSON blob. We extract metadata for partitioning.
    # The `data` column is the JSON blob from the PNCP API.
    sql_query = f"""
    COPY (
        SELECT
            json_extract_string(data, '$.dataPublicacao') as data_publicacao,
            endpoint,
            data,
            CAST(strftime(CAST(json_extract_string(data, '$.dataPublicacao') AS DATE), '%Y') AS INTEGER) as ano_publicacao,
            CAST(strftime(CAST(json_extract_string(data, '$.dataPublicacao') AS DATE), '%m') AS INTEGER) as mes_publicacao
        FROM {table_name}
        WHERE CAST(json_extract_string(data, '$.dataPublicacao') AS DATE) = '{target_date.strftime('%Y-%m-%d')}'
    ) TO '{output_dir}' (
        FORMAT PARQUET,
        PARTITION_BY (endpoint, ano_publicacao, mes_publicacao),
        OVERWRITE_OR_IGNORE 1,
        FILENAME_PATTERN "data_{{i}}"
    );
    """

    try:
        con.execute(sql_query)
        print(f"Successfully exported data to {output_dir}")
    except Exception as e:
        print(f"Failed to export data to Parquet. Error: {e}")
    finally:
        con.close()

if __name__ == "__main__":
    # Make sure the script is executable and has the correct path context
    # when running in the GitHub Actions workflow.
    export_new_data_to_parquet()
