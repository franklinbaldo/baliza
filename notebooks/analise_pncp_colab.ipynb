{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üìä An√°lise de Dados PNCP - Portal Nacional de Contrata√ß√µes P√∫blicas\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/franklinbaldo/baliza/blob/main/notebooks/analise_pncp_colab.ipynb)\n",
        "\n",
        "Este notebook fornece acesso direto aos dados de contrata√ß√µes p√∫blicas preservados no **Internet Archive** pelo projeto [Baliza](https://github.com/franklinbaldo/baliza).\n",
        "\n",
        "## üéØ O que voc√™ pode fazer:\n",
        "- ‚úÖ Analisar **milh√µes de contratos p√∫blicos** desde 2021\n",
        "- ‚úÖ Criar **visualiza√ß√µes interativas** com Plotly\n",
        "- ‚úÖ Detectar **padr√µes suspeitos** em contrata√ß√µes\n",
        "- ‚úÖ An√°lises **geogr√°ficas e temporais**\n",
        "- ‚úÖ Comparar **√≥rg√£os e fornecedores**\n",
        "- ‚úÖ Exportar dados para **pesquisa acad√™mica**\n",
        "\n",
        "## üìö Fonte dos Dados:\n",
        "- **PNCP**: Portal Nacional de Contrata√ß√µes P√∫blicas\n",
        "- **Preserva√ß√£o**: Internet Archive (permanente)\n",
        "- **Formato**: Parquet (otimizado para an√°lise)\n",
        "- **Atualiza√ß√£o**: Di√°ria via GitHub Actions\n",
        "\n",
        "---\n",
        "**‚ö†Ô∏è Importante**: Este notebook funciona 100% no Google Colab sem necessidade de configura√ß√£o local!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üîß Configura√ß√£o do Ambiente\n",
        "\n",
        "Instala as depend√™ncias necess√°rias e configura o acesso aos dados do Internet Archive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Instalar depend√™ncias necess√°rias\n",
        "!pip install -q pandas plotly duckdb requests internetarchive seaborn folium\n",
        "\n",
        "print(\"‚úÖ Depend√™ncias instaladas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import duckdb\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configura√ß√µes do Plotly para melhor visualiza√ß√£o\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "print(\"üì¶ Bibliotecas importadas com sucesso!\")\n",
        "print(f\"üêº Pandas: {pd.__version__}\")\n",
        "print(f\"ü¶Ü DuckDB: {duckdb.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_access"
      },
      "source": [
        "## üåê Acesso aos Dados do Internet Archive\n",
        "\n",
        "Vamos descobrir e carregar os dados PNCP preservados no Internet Archive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "discover_data"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def discover_baliza_data():\n",
        "    \"\"\"Descobre dados Baliza dispon√≠veis no Internet Archive.\"\"\"\n",
        "    print(\"üîç Descobrindo dados Baliza no Internet Archive...\")\n",
        "    \n",
        "    # API do Internet Archive para buscar itens Baliza\n",
        "    search_url = \"https://archive.org/advancedsearch.php\"\n",
        "    params = {\n",
        "        'q': 'title:baliza-* AND mediatype:data',\n",
        "        'fl': 'identifier,title,description,date,item_size',\n",
        "        'sort[]': 'date desc',\n",
        "        'rows': 50,\n",
        "        'page': 1,\n",
        "        'output': 'json'\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(search_url, params=params, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        items = data.get('response', {}).get('docs', [])\n",
        "        \n",
        "        print(f\"üìä Encontrados {len(items)} itens Baliza no Internet Archive\")\n",
        "        \n",
        "        # Mostrar os 5 mais recentes\n",
        "        if items:\n",
        "            print(\"\\nüìã Itens mais recentes:\")\n",
        "            for i, item in enumerate(items[:5]):\n",
        "                identifier = item.get('identifier', 'N/A')\n",
        "                title = item.get('title', 'N/A')\n",
        "                date = item.get('date', 'N/A')\n",
        "                size_mb = int(item.get('item_size', 0)) / (1024*1024) if item.get('item_size') else 0\n",
        "                print(f\"  {i+1}. {identifier} ({date}) - {size_mb:.1f} MB\")\n",
        "        \n",
        "        return items\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao descobrir dados: {e}\")\n",
        "        return []\n",
        "\n",
        "# Descobrir dados dispon√≠veis\n",
        "baliza_items = discover_baliza_data()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "get_parquet_files"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def get_parquet_files_from_item(identifier):\n",
        "    \"\"\"Obt√©m lista de arquivos Parquet de um item do IA.\"\"\"\n",
        "    files_url = f\"https://archive.org/metadata/{identifier}\"\n",
        "    \n",
        "    try:\n",
        "        response = requests.get(files_url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        metadata = response.json()\n",
        "        \n",
        "        parquet_files = []\n",
        "        files = metadata.get('files', [])\n",
        "        \n",
        "        for file_info in files:\n",
        "            if file_info.get('name', '').endswith('.parquet'):\n",
        "                parquet_files.append({\n",
        "                    'name': file_info['name'],\n",
        "                    'size': int(file_info.get('size', 0)),\n",
        "                    'url': f\"https://archive.org/download/{identifier}/{file_info['name']}\"\n",
        "                })\n",
        "        \n",
        "        return parquet_files\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao obter arquivos de {identifier}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Obter arquivos Parquet do item mais recente\n",
        "if baliza_items:\n",
        "    latest_item = baliza_items[0]['identifier']\n",
        "    print(f\"\\nüìÅ Buscando arquivos Parquet em: {latest_item}\")\n",
        "    \n",
        "    parquet_files = get_parquet_files_from_item(latest_item)\n",
        "    \n",
        "    if parquet_files:\n",
        "        print(f\"\\n‚úÖ Encontrados {len(parquet_files)} arquivos Parquet:\")\n",
        "        for i, file_info in enumerate(parquet_files[:5]):\n",
        "            size_mb = file_info['size'] / (1024*1024)\n",
        "            print(f\"  {i+1}. {file_info['name']} ({size_mb:.1f} MB)\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Nenhum arquivo Parquet encontrado\")\n",
        "        parquet_files = []\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Nenhum item Baliza encontrado\")\n",
        "    parquet_files = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_data"
      },
      "source": [
        "## üìä Carregamento dos Dados\n",
        "\n",
        "Carrega uma amostra dos dados para an√°lise. Para datasets grandes, usamos apenas parte dos dados para performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load_sample_data"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_sample_data(max_files=3, sample_size=100000):\n",
        "    \"\"\"Carrega amostra dos dados PNCP do Internet Archive.\"\"\"\n",
        "    \n",
        "    if not parquet_files:\n",
        "        print(\"‚ùå Nenhum arquivo Parquet dispon√≠vel\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    print(f\"üì• Carregando dados de {min(max_files, len(parquet_files))} arquivos...\")\n",
        "    \n",
        "    # Conectar ao DuckDB\n",
        "    conn = duckdb.connect(':memory:')\n",
        "    \n",
        "    # Lista para armazenar DataFrames\n",
        "    dfs = []\n",
        "    \n",
        "    for i, file_info in enumerate(parquet_files[:max_files]):\n",
        "        try:\n",
        "            print(f\"  üìÑ Carregando {file_info['name']}...\")\n",
        "            \n",
        "            # Usar DuckDB para ler Parquet direto da URL\n",
        "            url = file_info['url']\n",
        "            \n",
        "            # Carregar amostra do arquivo\n",
        "            query = f\"\"\"\n",
        "            SELECT * FROM '{url}'\n",
        "            USING SAMPLE {sample_size} ROWS\n",
        "            \"\"\"\n",
        "            \n",
        "            df = conn.execute(query).df()\n",
        "            \n",
        "            if not df.empty:\n",
        "                df['arquivo_origem'] = file_info['name']\n",
        "                dfs.append(df)\n",
        "                print(f\"    ‚úÖ {len(df):,} registros carregados\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"    ‚ö†Ô∏è Erro ao carregar {file_info['name']}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    if dfs:\n",
        "        # Combinar todos os DataFrames\n",
        "        combined_df = pd.concat(dfs, ignore_index=True, sort=False)\n",
        "        \n",
        "        print(f\"\\n‚úÖ Dataset carregado com sucesso!\")\n",
        "        print(f\"üìä Total de registros: {len(combined_df):,}\")\n",
        "        print(f\"üìã Colunas dispon√≠veis: {len(combined_df.columns)}\")\n",
        "        \n",
        "        return combined_df\n",
        "    else:\n",
        "        print(\"‚ùå Nenhum dado p√¥de ser carregado\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Carregar amostra dos dados\n",
        "print(\"üöÄ Iniciando carregamento dos dados PNCP...\")\n",
        "df_contratos = load_sample_data(max_files=2, sample_size=50000)\n",
        "\n",
        "if not df_contratos.empty:\n",
        "    print(f\"\\nüìà Primeiras estat√≠sticas:\")\n",
        "    print(f\"  üìÖ Per√≠odo: {df_contratos.get('dataAssinatura', pd.Series()).min()} a {df_contratos.get('dataAssinatura', pd.Series()).max()}\")\n",
        "    \n",
        "    if 'valorGlobal' in df_contratos.columns:\n",
        "        valor_total = df_contratos['valorGlobal'].sum() / 1_000_000\n",
        "        print(f\"  üí∞ Valor total (amostra): R$ {valor_total:,.0f} milh√µes\")\n",
        "    \n",
        "    if 'uf_sigla' in df_contratos.columns or any('uf' in col.lower() for col in df_contratos.columns):\n",
        "        uf_col = next((col for col in df_contratos.columns if 'uf' in col.lower()), None)\n",
        "        if uf_col:\n",
        "            ufs = df_contratos[uf_col].nunique()\n",
        "            print(f\"  üó∫Ô∏è Estados representados: {ufs}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Continuando com dados de exemplo para demonstra√ß√£o...\")\n",
        "    # Criar dados de exemplo se n√£o conseguir carregar do IA\n",
        "    np.random.seed(42)\n",
        "    df_contratos = pd.DataFrame({\n",
        "        'numeroControlePncpCompra': [f'PNCP{i:06d}' for i in range(1000)],\n",
        "        'valorGlobal': np.random.lognormal(10, 2, 1000),\n",
        "        'dataAssinatura': pd.date_range('2024-01-01', periods=1000, freq='D'),\n",
        "        'nomeRazaoSocialFornecedor': [f'Empresa {i%50}' for i in range(1000)],\n",
        "        'orgao_razao_social': [f'√ìrg√£o {i%20}' for i in range(1000)],\n",
        "        'uf_sigla': np.random.choice(['RO', 'SP', 'RJ', 'MG', 'RS'], 1000)\n",
        "    })\n",
        "    print(f\"üìä Usando dados de exemplo: {len(df_contratos):,} registros\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_exploration"
      },
      "source": [
        "## üîç Explora√ß√£o Inicial dos Dados\n",
        "\n",
        "Vamos entender a estrutura e qualidade dos dados carregados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "data_overview"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vis√£o geral do dataset\n",
        "print(\"üìã ESTRUTURA DO DATASET\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Registros: {len(df_contratos):,}\")\n",
        "print(f\"Colunas: {len(df_contratos.columns)}\")\n",
        "print(f\"Mem√≥ria: {df_contratos.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
        "\n",
        "print(\"\\nüìä PRINCIPAIS COLUNAS:\")\n",
        "print(\"-\" * 30)\n",
        "for col in df_contratos.columns[:15]:  # Primeiras 15 colunas\n",
        "    dtype = df_contratos[col].dtype\n",
        "    null_pct = (df_contratos[col].isnull().sum() / len(df_contratos)) * 100\n",
        "    print(f\"  {col[:30]:<30} | {str(dtype):<12} | {null_pct:5.1f}% nulos\")\n",
        "\n",
        "if len(df_contratos.columns) > 15:\n",
        "    print(f\"  ... e mais {len(df_contratos.columns) - 15} colunas\")\n",
        "\n",
        "# Mostrar amostra dos dados\n",
        "print(\"\\nüîç AMOSTRA DOS DADOS:\")\n",
        "print(\"-\" * 20)\n",
        "display(df_contratos.head())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "data_quality"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# An√°lise de qualidade dos dados\n",
        "print(\"üîç AN√ÅLISE DE QUALIDADE DOS DADOS\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Campos essenciais para an√°lise\n",
        "essential_fields = [\n",
        "    'numeroControlePncpCompra', 'valorGlobal', 'dataAssinatura',\n",
        "    'nomeRazaoSocialFornecedor', 'orgao_razao_social'\n",
        "]\n",
        "\n",
        "# Verificar quais campos existem\n",
        "available_fields = [field for field in essential_fields if field in df_contratos.columns]\n",
        "missing_fields = [field for field in essential_fields if field not in df_contratos.columns]\n",
        "\n",
        "print(f\"‚úÖ Campos dispon√≠veis: {len(available_fields)}/{len(essential_fields)}\")\n",
        "for field in available_fields:\n",
        "    completeness = (1 - df_contratos[field].isnull().mean()) * 100\n",
        "    print(f\"  üìä {field}: {completeness:.1f}% completo\")\n",
        "\n",
        "if missing_fields:\n",
        "    print(f\"\\n‚ö†Ô∏è Campos ausentes: {missing_fields}\")\n",
        "    print(\"   Usando campos alternativos dispon√≠veis...\")\n",
        "\n",
        "# Identificar colunas de valor\n",
        "value_columns = [col for col in df_contratos.columns if 'valor' in col.lower()]\n",
        "print(f\"\\nüí∞ Colunas de valor encontradas: {value_columns}\")\n",
        "\n",
        "# Identificar colunas de data\n",
        "date_columns = [col for col in df_contratos.columns if 'data' in col.lower() or 'date' in col.lower()]\n",
        "print(f\"üìÖ Colunas de data encontradas: {date_columns}\")\n",
        "\n",
        "# Identificar colunas geogr√°ficas\n",
        "geo_columns = [col for col in df_contratos.columns if any(geo in col.lower() for geo in ['uf', 'estado', 'municipio', 'cidade'])]\n",
        "print(f\"üó∫Ô∏è Colunas geogr√°ficas encontradas: {geo_columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_preparation"
      },
      "source": [
        "## üîß Prepara√ß√£o dos Dados\n",
        "\n",
        "Limpeza e transforma√ß√£o dos dados para an√°lise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prepare_data"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def prepare_data(df):\n",
        "    \"\"\"Prepara os dados para an√°lise.\"\"\"\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    print(\"üîß Preparando dados para an√°lise...\")\n",
        "    \n",
        "    # 1. Padronizar nomes de colunas importantes\n",
        "    column_mapping = {}\n",
        "    \n",
        "    # Encontrar coluna de valor principal\n",
        "    valor_col = None\n",
        "    for col in ['valorGlobal', 'valor_global_brl', 'valor_total']:\n",
        "        if col in df_clean.columns:\n",
        "            valor_col = col\n",
        "            break\n",
        "    \n",
        "    if valor_col:\n",
        "        column_mapping[valor_col] = 'valor_contrato'\n",
        "    \n",
        "    # Encontrar coluna de data\n",
        "    data_col = None\n",
        "    for col in ['dataAssinatura', 'data_assinatura', 'data_contrato']:\n",
        "        if col in df_clean.columns:\n",
        "            data_col = col\n",
        "            break\n",
        "    \n",
        "    if data_col:\n",
        "        column_mapping[data_col] = 'data_assinatura'\n",
        "    \n",
        "    # Encontrar coluna de UF\n",
        "    uf_col = None\n",
        "    for col in ['uf_sigla', 'UF', 'estado_sigla']:\n",
        "        if col in df_clean.columns:\n",
        "            uf_col = col\n",
        "            break\n",
        "    \n",
        "    if uf_col:\n",
        "        column_mapping[uf_col] = 'uf'\n",
        "    \n",
        "    # Aplicar mapeamento\n",
        "    df_clean = df_clean.rename(columns=column_mapping)\n",
        "    \n",
        "    # 2. Converter tipos de dados\n",
        "    if 'valor_contrato' in df_clean.columns:\n",
        "        df_clean['valor_contrato'] = pd.to_numeric(df_clean['valor_contrato'], errors='coerce')\n",
        "        df_clean = df_clean[df_clean['valor_contrato'] > 0]  # Remover valores inv√°lidos\n",
        "    \n",
        "    if 'data_assinatura' in df_clean.columns:\n",
        "        df_clean['data_assinatura'] = pd.to_datetime(df_clean['data_assinatura'], errors='coerce')\n",
        "        # Adicionar colunas derivadas\n",
        "        df_clean['ano'] = df_clean['data_assinatura'].dt.year\n",
        "        df_clean['mes'] = df_clean['data_assinatura'].dt.month\n",
        "        df_clean['mes_ano'] = df_clean['data_assinatura'].dt.to_period('M').astype(str)\n",
        "    \n",
        "    # 3. Limpeza de campos texto\n",
        "    text_columns = df_clean.select_dtypes(include=['object']).columns\n",
        "    for col in text_columns:\n",
        "        if df_clean[col].dtype == 'object':\n",
        "            df_clean[col] = df_clean[col].astype(str).str.strip().str.upper()\n",
        "            df_clean[col] = df_clean[col].replace(['NAN', 'NONE', 'NULL', ''], pd.NA)\n",
        "    \n",
        "    # 4. Criar categorias de valor\n",
        "    if 'valor_contrato' in df_clean.columns:\n",
        "        df_clean['categoria_valor'] = pd.cut(\n",
        "            df_clean['valor_contrato'],\n",
        "            bins=[0, 50000, 200000, 1000000, 10000000, float('inf')],\n",
        "            labels=['At√© R$ 50k', 'R$ 50k-200k', 'R$ 200k-1M', 'R$ 1M-10M', 'Acima R$ 10M'],\n",
        "            include_lowest=True\n",
        "        )\n",
        "    \n",
        "    print(f\"‚úÖ Dados preparados: {len(df_clean):,} registros v√°lidos\")\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "# Preparar os dados\n",
        "df_clean = prepare_data(df_contratos)\n",
        "\n",
        "# Mostrar resumo dos dados limpos\n",
        "print(\"\\nüìä RESUMO DOS DADOS PREPARADOS:\")\n",
        "print(f\"  üìà Registros v√°lidos: {len(df_clean):,}\")\n",
        "\n",
        "if 'valor_contrato' in df_clean.columns:\n",
        "    valor_total = df_clean['valor_contrato'].sum() / 1_000_000\n",
        "    valor_medio = df_clean['valor_contrato'].mean()\n",
        "    print(f\"  üí∞ Valor total: R$ {valor_total:,.0f} milh√µes\")\n",
        "    print(f\"  üí∞ Valor m√©dio: R$ {valor_medio:,.0f}\")\n",
        "\n",
        "if 'data_assinatura' in df_clean.columns:\n",
        "    data_min = df_clean['data_assinatura'].min()\n",
        "    data_max = df_clean['data_assinatura'].max()\n",
        "    print(f\"  üìÖ Per√≠odo: {data_min.strftime('%Y-%m-%d')} a {data_max.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "if 'uf' in df_clean.columns:\n",
        "    ufs_count = df_clean['uf'].nunique()\n",
        "    print(f\"  üó∫Ô∏è Estados: {ufs_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analysis_temporal"
      },
      "source": [
        "## üìà An√°lise Temporal\n",
        "\n",
        "An√°lise da evolu√ß√£o das contrata√ß√µes ao longo do tempo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "temporal_analysis"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "if 'data_assinatura' in df_clean.columns and 'valor_contrato' in df_clean.columns:\n",
        "    # An√°lise temporal - evolu√ß√£o mensal\n",
        "    monthly_data = df_clean.groupby('mes_ano').agg({\n",
        "        'valor_contrato': ['count', 'sum', 'mean'],\n",
        "        'numeroControlePncpCompra': 'nunique'  # ou primeira coluna dispon√≠vel\n",
        "    }).round(2)\n",
        "    \n",
        "    monthly_data.columns = ['total_contratos', 'valor_total', 'valor_medio', 'contratos_unicos']\n",
        "    monthly_data['valor_total_milhoes'] = monthly_data['valor_total'] / 1_000_000\n",
        "    monthly_data = monthly_data.reset_index()\n",
        "    \n",
        "    # Gr√°fico de evolu√ß√£o temporal\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=1,\n",
        "        subplot_titles=('Volume de Contratos por M√™s', 'Valor Total por M√™s (R$ Milh√µes)'),\n",
        "        vertical_spacing=0.12\n",
        "    )\n",
        "    \n",
        "    # Volume de contratos\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=monthly_data['mes_ano'],\n",
        "            y=monthly_data['total_contratos'],\n",
        "            mode='lines+markers',\n",
        "            name='Contratos',\n",
        "            line=dict(color='#1f77b4', width=3),\n",
        "            marker=dict(size=6)\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "    \n",
        "    # Valor total\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=monthly_data['mes_ano'],\n",
        "            y=monthly_data['valor_total_milhoes'],\n",
        "            mode='lines+markers',\n",
        "            name='Valor (R$ M)',\n",
        "            line=dict(color='#ff7f0e', width=3),\n",
        "            marker=dict(size=6),\n",
        "            fill='tonexty'\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=\"üìà Evolu√ß√£o Temporal das Contrata√ß√µes P√∫blicas\",\n",
        "        height=600,\n",
        "        showlegend=False\n",
        "    )\n",
        "    \n",
        "    fig.update_xaxes(title_text=\"M√™s/Ano\", row=2, col=1)\n",
        "    fig.update_yaxes(title_text=\"N√∫mero de Contratos\", row=1, col=1)\n",
        "    fig.update_yaxes(title_text=\"Valor (R$ Milh√µes)\", row=2, col=1)\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    # Estat√≠sticas temporais\n",
        "    print(\"üìä ESTAT√çSTICAS TEMPORAIS:\")\n",
        "    print(f\"  üìÖ Meses analisados: {len(monthly_data)}\")\n",
        "    print(f\"  üìà M√©dia de contratos/m√™s: {monthly_data['total_contratos'].mean():,.0f}\")\n",
        "    print(f\"  üí∞ M√©dia de valor/m√™s: R$ {monthly_data['valor_total_milhoes'].mean():,.1f} milh√µes\")\n",
        "    \n",
        "    # M√™s com mais contratos\n",
        "    mes_maior_volume = monthly_data.loc[monthly_data['total_contratos'].idxmax()]\n",
        "    print(f\"  üîù Maior volume: {mes_maior_volume['mes_ano']} ({mes_maior_volume['total_contratos']:,} contratos)\")\n",
        "    \n",
        "    # M√™s com maior valor\n",
        "    mes_maior_valor = monthly_data.loc[monthly_data['valor_total_milhoes'].idxmax()]\n",
        "    print(f\"  üíé Maior valor: {mes_maior_valor['mes_ano']} (R$ {mes_maior_valor['valor_total_milhoes']:,.1f} milh√µes)\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dados de data ou valor n√£o dispon√≠veis para an√°lise temporal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analysis_geographic"
      },
      "source": [
        "## üó∫Ô∏è An√°lise Geogr√°fica\n",
        "\n",
        "Distribui√ß√£o das contrata√ß√µes por estado e regi√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geographic_analysis"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "if 'uf' in df_clean.columns and 'valor_contrato' in df_clean.columns:\n",
        "    # An√°lise por UF\n",
        "    uf_analysis = df_clean.groupby('uf').agg({\n",
        "        'valor_contrato': ['count', 'sum', 'mean'],\n",
        "        'numeroControlePncpCompra': 'nunique'\n",
        "    }).round(2)\n",
        "    \n",
        "    uf_analysis.columns = ['total_contratos', 'valor_total', 'valor_medio', 'contratos_unicos']\n",
        "    uf_analysis['valor_total_milhoes'] = uf_analysis['valor_total'] / 1_000_000\n",
        "    uf_analysis = uf_analysis.reset_index().sort_values('valor_total_milhoes', ascending=False)\n",
        "    \n",
        "    # Mapa coropl√©tico (usando c√≥digos de UF)\n",
        "    fig_map = px.choropleth(\n",
        "        uf_analysis.head(15),  # Top 15 estados\n",
        "        locations='uf',\n",
        "        color='valor_total_milhoes',\n",
        "        hover_name='uf',\n",
        "        hover_data={'total_contratos': True, 'valor_medio': ':,.0f'},\n",
        "        title=\"üí∞ Valor Total de Contratos por Estado (R$ Milh√µes)\",\n",
        "        color_continuous_scale=\"Viridis\",\n",
        "        locationmode=\"geojson-id\"  # Usar se tiver GeoJSON\n",
        "    )\n",
        "    \n",
        "    # Se n√£o conseguir fazer mapa, fazer gr√°fico de barras\n",
        "    try:\n",
        "        fig_map.show()\n",
        "    except:\n",
        "        # Fallback para gr√°fico de barras\n",
        "        fig_bar = px.bar(\n",
        "            uf_analysis.head(15),\n",
        "            x='uf',\n",
        "            y='valor_total_milhoes',\n",
        "            title=\"üí∞ Valor Total de Contratos por Estado (R$ Milh√µes)\",\n",
        "            labels={'valor_total_milhoes': 'Valor (R$ Milh√µes)', 'uf': 'Estado'},\n",
        "            color='valor_total_milhoes',\n",
        "            color_continuous_scale=\"Viridis\"\n",
        "        )\n",
        "        fig_bar.update_layout(showlegend=False, height=500)\n",
        "        fig_bar.show()\n",
        "    \n",
        "    # Gr√°fico de dispers√£o: Volume vs Valor\n",
        "    fig_scatter = px.scatter(\n",
        "        uf_analysis,\n",
        "        x='total_contratos',\n",
        "        y='valor_total_milhoes',\n",
        "        size='valor_medio',\n",
        "        text='uf',\n",
        "        title=\"üìä Volume vs Valor Total por Estado\",\n",
        "        labels={\n",
        "            'total_contratos': 'N√∫mero de Contratos',\n",
        "            'valor_total_milhoes': 'Valor Total (R$ Milh√µes)',\n",
        "            'valor_medio': 'Valor M√©dio'\n",
        "        },\n",
        "        color='valor_medio',\n",
        "        color_continuous_scale=\"Plasma\"\n",
        "    )\n",
        "    \n",
        "    fig_scatter.update_traces(textposition='top center')\n",
        "    fig_scatter.update_layout(height=500)\n",
        "    fig_scatter.show()\n",
        "    \n",
        "    # Ranking dos estados\n",
        "    print(\"üèÜ RANKING DOS ESTADOS:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Top 10 por Valor Total:\")\n",
        "    for i, row in uf_analysis.head(10).iterrows():\n",
        "        print(f\"  {i+1:2d}. {row['uf']:2s} - R$ {row['valor_total_milhoes']:8.1f}M ({row['total_contratos']:,} contratos)\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dados geogr√°ficos n√£o dispon√≠veis para an√°lise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analysis_suppliers"
      },
      "source": [
        "## üè¢ An√°lise de Fornecedores\n",
        "\n",
        "Identifica√ß√£o dos principais fornecedores e padr√µes de concentra√ß√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suppliers_analysis"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Encontrar coluna de fornecedor\n",
        "fornecedor_col = None\n",
        "for col in ['nomeRazaoSocialFornecedor', 'fornecedor_nome', 'supplier_name']:\n",
        "    if col in df_clean.columns:\n",
        "        fornecedor_col = col\n",
        "        break\n",
        "\n",
        "if fornecedor_col and 'valor_contrato' in df_clean.columns:\n",
        "    # An√°lise dos fornecedores\n",
        "    fornecedores = df_clean.groupby(fornecedor_col).agg({\n",
        "        'valor_contrato': ['count', 'sum', 'mean'],\n",
        "        'numeroControlePncpCompra': 'nunique'\n",
        "    }).round(2)\n",
        "    \n",
        "    fornecedores.columns = ['total_contratos', 'valor_total', 'valor_medio', 'contratos_unicos']\n",
        "    fornecedores['valor_total_milhoes'] = fornecedores['valor_total'] / 1_000_000\n",
        "    \n",
        "    # Calcular m√©tricas de concentra√ß√£o\n",
        "    fornecedores['participacao_valor'] = (fornecedores['valor_total'] / fornecedores['valor_total'].sum()) * 100\n",
        "    fornecedores['participacao_volume'] = (fornecedores['total_contratos'] / fornecedores['total_contratos'].sum()) * 100\n",
        "    \n",
        "    fornecedores = fornecedores.reset_index().sort_values('valor_total_milhoes', ascending=False)\n",
        "    \n",
        "    # Top fornecedores por valor\n",
        "    top_fornecedores = fornecedores.head(20)\n",
        "    \n",
        "    fig_fornecedores = px.bar(\n",
        "        top_fornecedores.head(15),\n",
        "        x='valor_total_milhoes',\n",
        "        y=fornecedor_col,\n",
        "        orientation='h',\n",
        "        title=\"üè¢ Top 15 Fornecedores por Valor Total\",\n",
        "        labels={'valor_total_milhoes': 'Valor Total (R$ Milh√µes)'},\n",
        "        color='total_contratos',\n",
        "        color_continuous_scale=\"Blues\"\n",
        "    )\n",
        "    \n",
        "    fig_fornecedores.update_layout(height=600, yaxis={'categoryorder': 'total ascending'})\n",
        "    fig_fornecedores.show()\n",
        "    \n",
        "    # An√°lise de concentra√ß√£o\n",
        "    print(\"üìä AN√ÅLISE DE CONCENTRA√á√ÉO DE FORNECEDORES:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Top 10 concentram quanto?\n",
        "    top10_valor = fornecedores.head(10)['participacao_valor'].sum()\n",
        "    top10_volume = fornecedores.head(10)['participacao_volume'].sum()\n",
        "    \n",
        "    print(f\"üîù Top 10 fornecedores concentram:\")\n",
        "    print(f\"   üí∞ {top10_valor:.1f}% do valor total\")\n",
        "    print(f\"   üìä {top10_volume:.1f}% do volume de contratos\")\n",
        "    \n",
        "    # √çndice de concentra√ß√£o HHI (simplificado)\n",
        "    hhi_valor = (fornecedores['participacao_valor'] ** 2).sum()\n",
        "    print(f\"\\nüìà √çndice HHI (concentra√ß√£o de valor): {hhi_valor:.0f}\")\n",
        "    if hhi_valor > 2500:\n",
        "        print(\"   üî¥ Alta concentra√ß√£o (>2500)\")\n",
        "    elif hhi_valor > 1500:\n",
        "        print(\"   üü° Concentra√ß√£o moderada (1500-2500)\")\n",
        "    else:\n",
        "        print(\"   üü¢ Baixa concentra√ß√£o (<1500)\")\n",
        "    \n",
        "    # Fornecedores com muitos contratos (poss√≠vel padr√£o suspeito)\n",
        "    fornecedores_frequentes = fornecedores[fornecedores['total_contratos'] >= 10].sort_values('total_contratos', ascending=False)\n",
        "    \n",
        "    if len(fornecedores_frequentes) > 0:\n",
        "        print(f\"\\n‚ö†Ô∏è Fornecedores com ‚â•10 contratos: {len(fornecedores_frequentes)}\")\n",
        "        print(\"   Top 5 mais frequentes:\")\n",
        "        for i, row in fornecedores_frequentes.head(5).iterrows():\n",
        "            nome = row[fornecedor_col][:40] + \"...\" if len(row[fornecedor_col]) > 40 else row[fornecedor_col]\n",
        "            print(f\"   {i+1}. {nome} ({row['total_contratos']} contratos, R$ {row['valor_total_milhoes']:.1f}M)\")\n",
        "    \n",
        "    # Distribui√ß√£o de valores por fornecedor\n",
        "    fig_dist = px.histogram(\n",
        "        fornecedores,\n",
        "        x='valor_total_milhoes',\n",
        "        nbins=50,\n",
        "        title=\"üìà Distribui√ß√£o de Valores por Fornecedor\",\n",
        "        labels={'valor_total_milhoes': 'Valor Total (R$ Milh√µes)', 'count': 'N√∫mero de Fornecedores'}\n",
        "    )\n",
        "    fig_dist.update_layout(height=400)\n",
        "    fig_dist.show()\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dados de fornecedores n√£o dispon√≠veis para an√°lise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analysis_values"
      },
      "source": [
        "## üí∞ An√°lise de Valores\n",
        "\n",
        "Distribui√ß√£o e padr√µes nos valores dos contratos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "values_analysis"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "if 'valor_contrato' in df_clean.columns:\n",
        "    # Estat√≠sticas descritivas\n",
        "    print(\"üí∞ ESTAT√çSTICAS DE VALORES DOS CONTRATOS:\")\n",
        "    print(\"=\" * 45)\n",
        "    \n",
        "    valores = df_clean['valor_contrato']\n",
        "    \n",
        "    print(f\"üìä Total de contratos: {len(valores):,}\")\n",
        "    print(f\"üíé Valor total: R$ {valores.sum():,.0f} ({valores.sum()/1_000_000:.1f} milh√µes)\")\n",
        "    print(f\"üìà Valor m√©dio: R$ {valores.mean():,.0f}\")\n",
        "    print(f\"üìä Valor mediano: R$ {valores.median():,.0f}\")\n",
        "    print(f\"üîù Valor m√°ximo: R$ {valores.max():,.0f}\")\n",
        "    print(f\"üîª Valor m√≠nimo: R$ {valores.min():,.0f}\")\n",
        "    print(f\"üìè Desvio padr√£o: R$ {valores.std():,.0f}\")\n",
        "    \n",
        "    # Percentis\n",
        "    percentis = [50, 75, 90, 95, 99]\n",
        "    print(f\"\\nüìä Percentis:\")\n",
        "    for p in percentis:\n",
        "        valor_p = valores.quantile(p/100)\n",
        "        print(f\"   P{p}: R$ {valor_p:,.0f}\")\n",
        "    \n",
        "    # Distribui√ß√£o por categorias de valor\n",
        "    if 'categoria_valor' in df_clean.columns:\n",
        "        cat_analysis = df_clean.groupby('categoria_valor').agg({\n",
        "            'valor_contrato': ['count', 'sum'],\n",
        "        })\n",
        "        cat_analysis.columns = ['quantidade', 'valor_total']\n",
        "        cat_analysis['percentual_quantidade'] = (cat_analysis['quantidade'] / cat_analysis['quantidade'].sum()) * 100\n",
        "        cat_analysis['percentual_valor'] = (cat_analysis['valor_total'] / cat_analysis['valor_total'].sum()) * 100\n",
        "        cat_analysis = cat_analysis.reset_index()\n",
        "        \n",
        "        # Gr√°fico de categorias\n",
        "        fig_cat = make_subplots(\n",
        "            rows=1, cols=2,\n",
        "            subplot_titles=('Distribui√ß√£o por Quantidade', 'Distribui√ß√£o por Valor'),\n",
        "            specs=[[{'type': 'domain'}, {'type': 'domain'}]]\n",
        "        )\n",
        "        \n",
        "        fig_cat.add_trace(\n",
        "            go.Pie(\n",
        "                labels=cat_analysis['categoria_valor'],\n",
        "                values=cat_analysis['percentual_quantidade'],\n",
        "                name=\"Quantidade\"\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "        \n",
        "        fig_cat.add_trace(\n",
        "            go.Pie(\n",
        "                labels=cat_analysis['categoria_valor'],\n",
        "                values=cat_analysis['percentual_valor'],\n",
        "                name=\"Valor\"\n",
        "            ),\n",
        "            row=1, col=2\n",
        "        )\n",
        "        \n",
        "        fig_cat.update_layout(\n",
        "            title=\"üí∞ Distribui√ß√£o de Contratos por Categoria de Valor\",\n",
        "            height=500\n",
        "        )\n",
        "        fig_cat.show()\n",
        "        \n",
        "        print(f\"\\nüìä Distribui√ß√£o por categorias:\")\n",
        "        for _, row in cat_analysis.iterrows():\n",
        "            print(f\"   {row['categoria_valor']}: {row['quantidade']:,} contratos ({row['percentual_quantidade']:.1f}%) - {row['percentual_valor']:.1f}% do valor\")\n",
        "    \n",
        "    # Histograma de valores (log scale para melhor visualiza√ß√£o)\n",
        "    fig_hist = px.histogram(\n",
        "        df_clean[df_clean['valor_contrato'] > 0],\n",
        "        x='valor_contrato',\n",
        "        nbins=50,\n",
        "        title=\"üìà Distribui√ß√£o de Valores dos Contratos (Escala Logar√≠tmica)\",\n",
        "        labels={'valor_contrato': 'Valor do Contrato (R$)', 'count': 'N√∫mero de Contratos'}\n",
        "    )\n",
        "    fig_hist.update_xaxes(type=\"log\")\n",
        "    fig_hist.update_layout(height=400)\n",
        "    fig_hist.show()\n",
        "    \n",
        "    # Contratos de alto valor (top 1%)\n",
        "    threshold_top1 = valores.quantile(0.99)\n",
        "    high_value_contracts = df_clean[df_clean['valor_contrato'] >= threshold_top1]\n",
        "    \n",
        "    print(f\"\\nüîù CONTRATOS DE ALTO VALOR (Top 1%):\")\n",
        "    print(f\"   Limiar: R$ {threshold_top1:,.0f}\")\n",
        "    print(f\"   Quantidade: {len(high_value_contracts):,} contratos\")\n",
        "    print(f\"   Valor total: R$ {high_value_contracts['valor_contrato'].sum():,.0f} ({high_value_contracts['valor_contrato'].sum()/1_000_000:.1f} milh√µes)\")\n",
        "    print(f\"   Concentra√ß√£o: {(high_value_contracts['valor_contrato'].sum() / valores.sum()) * 100:.1f}% do valor total em 1% dos contratos\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dados de valores n√£o dispon√≠veis para an√°lise\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suspicious_patterns"
      },
      "source": [
        "## üö® Detec√ß√£o de Padr√µes Suspeitos\n",
        "\n",
        "Identifica√ß√£o de poss√≠veis irregularidades usando algoritmos de detec√ß√£o de anomalias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fraud_detection"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def detect_suspicious_patterns(df):\n",
        "    \"\"\"Detecta padr√µes suspeitos nos contratos.\"\"\"\n",
        "    \n",
        "    print(\"üö® DETEC√á√ÉO DE PADR√ïES SUSPEITOS:\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    suspicious_contracts = []\n",
        "    \n",
        "    if 'valor_contrato' in df.columns:\n",
        "        # 1. Valores muito altos (outliers)\n",
        "        q99 = df['valor_contrato'].quantile(0.99)\n",
        "        high_value = df[df['valor_contrato'] > q99]\n",
        "        \n",
        "        print(f\"üîç 1. Contratos de valor muito alto (>P99):\")\n",
        "        print(f\"   üìä Threshold: R$ {q99:,.0f}\")\n",
        "        print(f\"   üî¢ Quantidade: {len(high_value):,} contratos\")\n",
        "        print(f\"   üí∞ Valor total: R$ {high_value['valor_contrato'].sum()/1_000_000:.1f} milh√µes\")\n",
        "        \n",
        "        suspicious_contracts.extend(high_value.index.tolist())\n",
        "        \n",
        "        # 2. Valores redondos suspeitos (m√∫ltiplos de 10.000, 50.000, 100.000)\n",
        "        round_values = df[\n",
        "            (df['valor_contrato'] % 10000 == 0) & \n",
        "            (df['valor_contrato'] >= 100000)\n",
        "        ]\n",
        "        \n",
        "        print(f\"\\nüîç 2. Valores redondos suspeitos:\")\n",
        "        print(f\"   üî¢ Quantidade: {len(round_values):,} contratos\")\n",
        "        print(f\"   üìä Percentual: {(len(round_values)/len(df))*100:.2f}% do total\")\n",
        "        \n",
        "        suspicious_contracts.extend(round_values.index.tolist())\n",
        "    \n",
        "    # 3. Fornecedores com muitos contratos\n",
        "    if fornecedor_col in df.columns:\n",
        "        supplier_counts = df[fornecedor_col].value_counts()\n",
        "        frequent_suppliers = supplier_counts[supplier_counts >= 5].index\n",
        "        \n",
        "        frequent_contracts = df[df[fornecedor_col].isin(frequent_suppliers)]\n",
        "        \n",
        "        print(f\"\\nüîç 3. Fornecedores muito frequentes (‚â•5 contratos):\")\n",
        "        print(f\"   üè¢ Fornecedores: {len(frequent_suppliers):,}\")\n",
        "        print(f\"   üî¢ Contratos: {len(frequent_contracts):,}\")\n",
        "        print(f\"   üìä Percentual: {(len(frequent_contracts)/len(df))*100:.1f}% do total\")\n",
        "        \n",
        "        suspicious_contracts.extend(frequent_contracts.index.tolist())\n",
        "    \n",
        "    # 4. An√°lise temporal - contratos em fins de semana\n",
        "    if 'data_assinatura' in df.columns:\n",
        "        df_temp = df.copy()\n",
        "        df_temp['dia_semana'] = pd.to_datetime(df_temp['data_assinatura']).dt.dayofweek\n",
        "        weekend_contracts = df_temp[df_temp['dia_semana'].isin([5, 6])]  # S√°bado e Domingo\n",
        "        \n",
        "        print(f\"\\nüîç 4. Contratos assinados em fins de semana:\")\n",
        "        print(f\"   üî¢ Quantidade: {len(weekend_contracts):,} contratos\")\n",
        "        print(f\"   üìä Percentual: {(len(weekend_contracts)/len(df))*100:.2f}% do total\")\n",
        "        \n",
        "        suspicious_contracts.extend(weekend_contracts.index.tolist())\n",
        "    \n",
        "    # Consolidar contratos suspeitos (remover duplicatas)\n",
        "    unique_suspicious = list(set(suspicious_contracts))\n",
        "    suspicious_df = df.loc[unique_suspicious]\n",
        "    \n",
        "    print(f\"\\nüìã RESUMO DE SUSPEI√á√ïES:\")\n",
        "    print(f\"   üö® Total de contratos suspeitos: {len(suspicious_df):,}\")\n",
        "    print(f\"   üìä Percentual do dataset: {(len(suspicious_df)/len(df))*100:.1f}%\")\n",
        "    \n",
        "    if 'valor_contrato' in suspicious_df.columns:\n",
        "        suspicious_value = suspicious_df['valor_contrato'].sum()\n",
        "        total_value = df['valor_contrato'].sum()\n",
        "        print(f\"   üí∞ Valor dos suspeitos: R$ {suspicious_value/1_000_000:.1f} milh√µes\")\n",
        "        print(f\"   üìà Concentra√ß√£o: {(suspicious_value/total_value)*100:.1f}% do valor total\")\n",
        "    \n",
        "    return suspicious_df\n",
        "\n",
        "# Executar detec√ß√£o de padr√µes suspeitos\n",
        "if len(df_clean) > 0:\n",
        "    suspicious_contracts = detect_suspicious_patterns(df_clean)\n",
        "    \n",
        "    # Mostrar alguns exemplos de contratos suspeitos\n",
        "    if len(suspicious_contracts) > 0:\n",
        "        print(f\"\\nüîç EXEMPLOS DE CONTRATOS SUSPEITOS:\")\n",
        "        print(\"-\" * 40)\n",
        "        \n",
        "        # Mostrar top 10 por valor\n",
        "        if 'valor_contrato' in suspicious_contracts.columns:\n",
        "            top_suspicious = suspicious_contracts.nlargest(10, 'valor_contrato')\n",
        "            \n",
        "            for i, (idx, row) in enumerate(top_suspicious.iterrows()):\n",
        "                valor = row['valor_contrato']\n",
        "                data = row.get('data_assinatura', 'N/A')\n",
        "                fornecedor = row.get(fornecedor_col, 'N/A')[:50] + \"...\" if fornecedor_col and len(str(row.get(fornecedor_col, ''))) > 50 else row.get(fornecedor_col, 'N/A')\n",
        "                \n",
        "                print(f\"  {i+1:2d}. R$ {valor:>12,.0f} | {data} | {fornecedor}\")\n",
        "        \n",
        "        # Visualiza√ß√£o da distribui√ß√£o de suspei√ß√µes\n",
        "        if 'valor_contrato' in suspicious_contracts.columns:\n",
        "            fig_suspicious = px.scatter(\n",
        "                suspicious_contracts.sample(min(1000, len(suspicious_contracts))),\n",
        "                x='data_assinatura' if 'data_assinatura' in suspicious_contracts.columns else range(len(suspicious_contracts)),\n",
        "                y='valor_contrato',\n",
        "                title=\"üö® Contratos Suspeitos - Distribui√ß√£o Temporal vs Valor\",\n",
        "                labels={'valor_contrato': 'Valor (R$)', 'data_assinatura': 'Data'},\n",
        "                color='valor_contrato',\n",
        "                color_continuous_scale=\"Reds\",\n",
        "                hover_data=[fornecedor_col] if fornecedor_col else None\n",
        "            )\n",
        "            fig_suspicious.update_layout(height=500)\n",
        "            fig_suspicious.show()\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Dataset vazio - n√£o √© poss√≠vel detectar padr√µes suspeitos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "export_data"
      },
      "source": [
        "## üíæ Exporta√ß√£o de Dados\n",
        "\n",
        "Exporte os dados analisados para uso em outras ferramentas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "export_results"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def export_analysis_results():\n",
        "    \"\"\"Exporta os resultados da an√°lise.\"\"\"\n",
        "    \n",
        "    print(\"üíæ EXPORTA√á√ÉO DE DADOS:\")\n",
        "    print(\"=\" * 25)\n",
        "    \n",
        "    exports = []\n",
        "    \n",
        "    # 1. Dataset principal limpo\n",
        "    if len(df_clean) > 0:\n",
        "        df_clean.to_csv('contratos_pncp_limpos.csv', index=False)\n",
        "        exports.append(f\"üìä contratos_pncp_limpos.csv ({len(df_clean):,} registros)\")\n",
        "    \n",
        "    # 2. Contratos suspeitos\n",
        "    if 'suspicious_contracts' in locals() and len(suspicious_contracts) > 0:\n",
        "        suspicious_contracts.to_csv('contratos_suspeitos.csv', index=False)\n",
        "        exports.append(f\"üö® contratos_suspeitos.csv ({len(suspicious_contracts):,} registros)\")\n",
        "    \n",
        "    # 3. An√°lise mensal\n",
        "    if 'monthly_data' in locals():\n",
        "        monthly_data.to_csv('analise_mensal.csv', index=False)\n",
        "        exports.append(f\"üìÖ analise_mensal.csv ({len(monthly_data)} meses)\")\n",
        "    \n",
        "    # 4. An√°lise por UF\n",
        "    if 'uf_analysis' in locals():\n",
        "        uf_analysis.to_csv('analise_por_uf.csv', index=False)\n",
        "        exports.append(f\"üó∫Ô∏è analise_por_uf.csv ({len(uf_analysis)} estados)\")\n",
        "    \n",
        "    # 5. Top fornecedores\n",
        "    if 'fornecedores' in locals():\n",
        "        fornecedores.head(100).to_csv('top_fornecedores.csv', index=False)\n",
        "        exports.append(f\"üè¢ top_fornecedores.csv (top 100)\")\n",
        "    \n",
        "    # Mostrar arquivos exportados\n",
        "    print(\"‚úÖ Arquivos exportados:\")\n",
        "    for export in exports:\n",
        "        print(f\"   {export}\")\n",
        "    \n",
        "    if not exports:\n",
        "        print(\"‚ö†Ô∏è Nenhum dado dispon√≠vel para exporta√ß√£o\")\n",
        "    \n",
        "    # Instru√ß√µes para download\n",
        "    if exports:\n",
        "        print(f\"\\nüì• Para baixar os arquivos no Colab:\")\n",
        "        print(\"   1. Clique no √≠cone de pasta üìÅ no menu lateral\")\n",
        "        print(\"   2. Encontre os arquivos .csv gerados\")\n",
        "        print(\"   3. Clique com bot√£o direito ‚Üí Download\")\n",
        "        print(\"\\nüìã Ou use o c√≥digo abaixo para download autom√°tico:\")\n",
        "        print(\"```python\")\n",
        "        print(\"from google.colab import files\")\n",
        "        for export in exports:\n",
        "            filename = export.split(' ')[1]\n",
        "            print(f\"files.download('{filename}')\")\n",
        "        print(\"```\")\n",
        "\n",
        "# Executar exporta√ß√£o\n",
        "export_analysis_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusions"
      },
      "source": [
        "## üìù Conclus√µes e Pr√≥ximos Passos\n",
        "\n",
        "### üéØ O que foi analisado:\n",
        "\n",
        "1. **üìä An√°lise Temporal**: Evolu√ß√£o das contrata√ß√µes ao longo do tempo\n",
        "2. **üó∫Ô∏è An√°lise Geogr√°fica**: Distribui√ß√£o por estados e regi√µes\n",
        "3. **üè¢ An√°lise de Fornecedores**: Concentra√ß√£o e padr√µes de contrata√ß√£o\n",
        "4. **üí∞ An√°lise de Valores**: Distribui√ß√£o e outliers nos valores\n",
        "5. **üö® Detec√ß√£o de Anomalias**: Identifica√ß√£o de padr√µes suspeitos\n",
        "\n",
        "### üîç Poss√≠veis an√°lises adicionais:\n",
        "\n",
        "- **An√°lise de Redes**: Relacionamentos entre √≥rg√£os e fornecedores\n",
        "- **An√°lise de Texto**: Processamento dos objetos dos contratos\n",
        "- **Machine Learning**: Modelos preditivos de risco\n",
        "- **An√°lise Setorial**: Compara√ß√£o entre diferentes tipos de contrata√ß√£o\n",
        "- **An√°lise de Efici√™ncia**: Compara√ß√£o de pre√ßos por categoria\n",
        "\n",
        "### üìö Recursos adicionais:\n",
        "\n",
        "- **Projeto Baliza**: [https://github.com/franklinbaldo/baliza](https://github.com/franklinbaldo/baliza)\n",
        "- **PNCP**: [https://pncp.gov.br](https://pncp.gov.br)\n",
        "- **Internet Archive**: Dados preservados permanentemente\n",
        "- **Documenta√ß√£o**: Veja o reposit√≥rio para mais detalhes\n",
        "\n",
        "### ü§ù Como contribuir:\n",
        "\n",
        "1. **Fork** o projeto Baliza no GitHub\n",
        "2. **Melhore** os algoritmos de detec√ß√£o\n",
        "3. **Adicione** novas an√°lises\n",
        "4. **Compartilhe** suas descobertas\n",
        "5. **Cite** este trabalho em pesquisas acad√™micas\n",
        "\n",
        "---\n",
        "\n",
        "**‚≠ê Se este notebook foi √∫til, d√™ uma estrela no [reposit√≥rio Baliza](https://github.com/franklinbaldo/baliza)!**\n",
        "\n",
        "**üìß D√∫vidas ou sugest√µes? Abra uma [issue](https://github.com/franklinbaldo/baliza/issues) no GitHub.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "final_summary"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Resumo final da an√°lise\n",
        "print(\"üéØ RESUMO FINAL DA AN√ÅLISE\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "if len(df_clean) > 0:\n",
        "    print(f\"üìä Dataset analisado: {len(df_clean):,} contratos\")\n",
        "    \n",
        "    if 'valor_contrato' in df_clean.columns:\n",
        "        total_value = df_clean['valor_contrato'].sum() / 1_000_000\n",
        "        print(f\"üí∞ Valor total: R$ {total_value:,.1f} milh√µes\")\n",
        "    \n",
        "    if 'data_assinatura' in df_clean.columns:\n",
        "        date_range = f\"{df_clean['data_assinatura'].min().strftime('%Y-%m')} a {df_clean['data_assinatura'].max().strftime('%Y-%m')}\"\n",
        "        print(f\"üìÖ Per√≠odo: {date_range}\")\n",
        "    \n",
        "    if 'suspicious_contracts' in locals():\n",
        "        suspicion_rate = (len(suspicious_contracts) / len(df_clean)) * 100\n",
        "        print(f\"üö® Taxa de suspei√ß√£o: {suspicion_rate:.1f}%\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ An√°lise conclu√≠da com sucesso!\")\n",
        "    print(f\"üìÅ Arquivos exportados dispon√≠veis para download\")\n",
        "    print(f\"üîÑ Execute novamente para analisar dados mais recentes\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è An√°lise n√£o p√¥de ser conclu√≠da - dados n√£o dispon√≠veis\")\n",
        "    print(\"üîÑ Tente executar novamente ou verifique a conex√£o\")\n",
        "\n",
        "print(\"\\nüöÄ Obrigado por usar o Baliza Analytics!\")\n",
        "print(\"‚≠ê Considere dar uma estrela no projeto: https://github.com/franklinbaldo/baliza\")"
      ]
    }
  ]
}